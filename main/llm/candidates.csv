pid,title,year,hop,sim,src,source,abstract,authors
2897817729,Triple Context-Based Knowledge Graph Embedding,2018,0,83.80707550048828,bm25,recall,"Knowledge graph embedding aims to represent entities and relations of a knowledge graph in continuous vector spaces. It has increasingly drawn attention for its ability to encode semantics in low dimensional vectors as well as its outstanding performance on many applications, such as question answering systems and information retrieval tasks. Existing methods often handle each triple independently, without considering context information of a triple in the knowledge graph, such an information can be useful for inference of new knowledge. Moreover, the relations and paths between an entity pair also provide information for inference. In this paper, we define a novel context-dependent knowledge graph representation model named triple-context-based knowledge embedding, which is based on the notion of  triple context  used for embedding entities and relations. For each triple, the triple context is composed of two kinds of graph structured information: one is a set of neighboring entities along with their outgoing relations, the other is a set of relation paths which contain a pair of target entities. Our embedding method is designed to utilize the triple context of each triple while learning embeddings of entities and relations. The method is evaluated on multiple tasks in the paper. Experimental results reveal that our method achieves significant improvements over the state-of-the-art methods.","[{'name': 'Huan Gao', 'org': 'Computer Science and Engineering Institute, Southeast University, Nanjing, China', 'id': 2989101449}, {'name': 'Jun Shi', 'org': 'Computer Science and Engineering Institute, Southeast University, Nanjing, China', 'id': 2721042959}, {'name': 'Guilin Qi', 'org': 'Computer Science and Engineering Institute, Southeast University, Nanjing, China', 'id': 2178685138}, {'name': 'Meng Wang', 'org': 'Computer Science and Engineering Institute, Southeast University, Nanjing, China', 'id': 2300598665}]"
2767271448,Knowledge Graph Embedding with Triple Context,2017,0,78.07847595214844,bm25,recall,"Knowledge graph embedding, which aims to represent entities and relations in vector spaces, has shown outstanding performance on a few knowledge graph completion tasks. Most existing methods are based on the assumption that a knowledge graph is a set of separate triples, ignoring rich graph features, i.e., structural information in the graph. In this paper, we take advantages of structures in knowledge graphs, especially local structures around a triple, which we refer to as triple context. We then propose a Triple-Context-based knowledge Embedding model (TCE). For each triple, two kinds of structure information are considered as its context in the graph; one is the outgoing relations and neighboring entities of an entity and the other is relation paths between a pair of entities, both of which reflect various aspects of the triple. Triples along with their contexts are represented in a unified framework, in which way structural information in triple contexts can be embodied. The experimental results show that our model outperforms the state-of-the-art methods for link prediction.","[{'name': 'Jun Shi', 'org': '(Southeast University, Nanjing, China)', 'id': 2721042959}, {'name': 'Huan Gao', 'org': '(Southeast University, Nanjing, China)', 'id': 2989101449}, {'name': 'Guilin Qi', 'org': '(Southeast University, Nanjing, China)', 'id': 2178685138}, {'name': 'Zhangquan Zhou', 'org': '(Southeast University, Nanjing, China)', 'id': 2657194247}]"
2976497980,TripleNet: Triple Attention Network for Multi-Turn Response Selection in Retrieval-based Chatbots,2019,0,77.10042572021484,bm25,recall,"We consider the importance of different utterances in the context for selecting the response usually depends on the current query. In this paper, we propose the model TripleNet to fully model the task with the triple   instead of   in previous works. The heart of TripleNet is a novel attention mechanism named triple attention to model the relationships within the triple at four levels. The new mechanism updates the representation for each element based on the attention with the other two concurrently and symmetrically. We match the triple   centered on the response from char to context level for prediction. Experimental results on two large-scale multi-turn response selection datasets show that the proposed model can significantly outperform the state-of-the-art methods. TripleNet source code is available at this https URL","[{'name': 'Wentao Ma', 'id': 2758072514}, {'name': 'Yiming Cui', 'id': 2687376174}, {'name': 'Nan Shao', 'id': 2976664180}, {'name': 'Su He', 'id': 2975193543}, {'name': 'Wei-Nan Zhang', 'id': 2119756314}, {'name': 'Ting Liu', 'id': 2916645153}, {'name': 'Shijin Wang', 'id': 2496586547}, {'name': 'Guoping Hu', 'id': 2496894573}]"
2137304183,Context-aware applications: from the laboratory to the marketplace,1997,0,73.25810241699219,bm25,recall,"Current hardware developments are making mobile computing increasingly attractive. An important class of mobile applications are context-aware applications: applications that change their behaviour according to the useru0027s present context-their location, who they are with, what the time of day is, and so on. This article is about software design for context-aware applications. Currently most such applications have been crafted by experts in research laboratories. Our aim is to factor out a simple class of context-aware applications and make the creation of these as easy as, say, creating Web pages.","[{'name': 'P.J. Brown', 'org': 'Kent University, Canterbury, UK', 'id': 2598795831}, {'name': 'J.D. Bovey', 'id': 2974448624}, {'name': 'Xian Chen', 'id': 2574198784}]"
2973224900,Attention-based context-aware sequential recommendation model,2020,0,72.85833740234375,bm25,recall,"Abstract   Recurrent neural networks (RNN) based recommendation algorithms have been introduced recently as sequence information plays an increasingly important role when modeling user preferences. However, these methods have numerous limitations: they usually give undue importance to sequential changes and place insufficient emphasis on the correlation between adjacent items; additionally, they typically ignore the impacts of context information. To address these issues, we propose an attention-based context-aware sequential recommendation model using Gated Recurrent Unit (GRU), abbreviated as ACA-GRU. First, we consider the impact of context information on recommendations and classify them into four categories, including input context, correlation context, static interest context, and transition context. Then, by redefining the update and reset gate of the GRU unit, we calculate the global sequential state transition of the RNN determined by these contexts, to model the dynamics of user interest. Finally, by leveraging the attention mechanism in the correlation context, the model is able to distinguish the importance of each item in the rating sequence. The impact of outliers that are less informative or less predictive decreases or is ignored. Experimental results indicate that ACA-GRU outperforms state-of-the-art context-aware models as well as sequence recommendation algorithms, demonstrating the effectiveness of the proposed model.","[{'name': 'Weihua Yuan', 'org': 'School of Information Science and Technology, Shandong Normal University, Jinan, SD, 250014, China', 'id': 2769931492}, {'name': 'Hong Wang', 'org': 'School of Information Science and Technology, Shandong Normal University, Jinan, SD, 250014, China', 'id': 2718872510}, {'name': 'Xiaomei Yu', 'org': 'School of Information Science and Technology, Shandong Normal University, Jinan, SD, 250014, China', 'id': 2793905068}, {'name': 'Nan Liu', 'org': 'School of Computer Science and Technology, Shandong Jianzhu University, Jinan, SD, 250101, China', 'id': 2973162281}, {'name': 'Zhenghao Li', 'org': 'School of Information Science and Technology, Shandong Normal University, Jinan, SD, 250014, China', 'id': 2973110495}]"
2963970108,Context-Aware Authentication: State-of-the-Art Evaluation and Adaption to the IIoT,2019,0,71.36361694335938,bm25,recall,"Authentication is an important and non-trivial topic for the security of the tremendously growing industrial Internet of Things. Classical authentication methods often do not meet the requirements of IoT networks, where computing power and bandwidth are usually constrained. This overview paper therefore turns its attention to context-aware authentication, a method that uses features of a shared or otherwise known context to mutually authenticate devices. First the idea of context-aware authentication and the state of the art in research is introduced. The work done so far is then evaluated, with a focus on the examined context features and authentication mechanisms. Afterwards it is discussed how context-awareness can be transferred from user-centric towards machine-to-machine authentication in the industrial IoT. The specific requirements are discussed together with use-cases for Smart Logistics and Industry 4.0.","[{'name': 'Moritz Loske', 'org': 'Fraunhofer IIS, Nuremberg, Germany', 'id': 2942410000}, {'name': 'Lukas Rothe', 'org': 'Fraunhofer IIS, Nuremberg, Germany', 'id': 2911707895}, {'name': 'Dominik G. Gertler', 'org': 'Ostbayerische Technische Hochschule Amberg-Weiden, Weiden i.d.OPf., Germany', 'id': 2912315538}]"
2979739834,Learning Visual Relationship and Context-Aware Attention for Image Captioning,2020,0,70.79586029052734,bm25,recall,"Abstract   Image captioning which automatically generates natural language descriptions for images has attracted lots of research attentions and there have been substantial progresses with attention based captioning methods. However, most attention-based image captioning methods focus on extracting visual information in regions of interest for sentence generation and usually ignore the relational reasoning among those regions of interest in an image. Moreover, these methods do not take into account previously attended regions which can be used to guide the subsequent attention selection. In this paper, we propose a novel method to implicitly model the relationship among regions of interest in an image with a graph neural network, as well as a novel context-aware attention mechanism to guide attention selection by fully memorizing previously attended visual content. Compared with the existing attention-based image captioning methods, ours can not only learn relation-aware visual representations for image captioning, but also consider historical context information on previous attention. We perform extensive experiments on two public benchmark datasets: MS COCO and Flickr30K, and the experimental results indicate that our proposed method is able to outperform various state-of-the-art methods in terms of the widely used evaluation metrics.","[{'name': 'Junbo Wang', 'org': 'University of Chinese Academy of Sciences (UCAS), China', 'id': 2781582583}, {'name': 'Wei Wang', 'org': 'University of Chinese Academy of Sciences (UCAS), China', 'id': 2637477271}, {'name': 'Liang Wang', 'org': 'Center for Research on Intelligent Perception and Computing (CRIPAC), National Laboratory of Pattern Recognition (NLPR), Institute of Automation, Chinese Academy of Sciences (CASIA) China', 'id': 2226151461}, {'name': 'Zhiyong Wang', 'org': 'School of Information Technologies, The University of Sydney, Australia#TAB#', 'id': 2343019993}, {'name': 'David Dagan Feng', 'org': 'School of Information Technologies, The University of Sydney, Australia#TAB#', 'id': 2131084071}, {'name': 'Tieniu Tan', 'org': 'Center for Research on Intelligent Perception and Computing (CRIPAC), National Laboratory of Pattern Recognition (NLPR), Institute of Automation, Chinese Academy of Sciences (CASIA) China', 'id': 2120394816}]"
2158715331,Mnemonic Context Effect in Two Cultures: Attention to Memory Representations?,2007,0,70.56204986572266,bm25,recall,"In two experiments we demonstrate a substantial cross-cultural difference in a mnemonic context effect, whereby a magnitude estimate of a simple stimulus such as a line or circle is biased toward the center of the distribution of previously seen instances of the same class. In support of the hypothesis that Asians are more likely than Americans to disperse their attention to both the target stimulus and its mnemonic context, this effect was consistently larger for Japanese than for Americans. Moreover, the cultural difference was attenuated by an experimentally induced belief in class homogeneity that augmented the context effect itself in both cultures. More important, these belief effects happened in the absence of any objective change in stimulus distribution. Implications for sociocultural shaping of cognition are discussed.","[{'name': 'Sean Duffy', 'org': 'Department of Psychology, Rutgers University', 'id': 2105568984}, {'name': 'Shinobu Kitayama', 'org': 'Department of Psychology University of Michigan', 'id': 1975555326}]"
2956118103,Context-Aware Co-attention Neural Network for Service Recommendations,2019,0,70.4848403930664,bm25,recall,"Context-aware recommender systems are able to produce more accurate recommendations by harnessing contextual information, such as consuming time and location. Further, user reviews as an important information resource, providing valuable information about usersu0027 preferences, itemsu0027 aspects, and implicit contextual features, could be used to enhance the embeddings of users, items, and contexts. However, few works attempt to incorporate these two types of information, i.e., contexts and reviews, into their models. Recent state-of-the-art context-aware methods only characterize relations between two types of entities among users, items and contexts, which may be insufficient, as the final prediction is closely related to all the three types of entities. In this paper, we propose a novel model, named Context-aware Co-Attention Neural Network (CCANN), to dynamically infer relations between contexts and users/items, and subsequently to model the degree of matching between usersu0027 contextual preferences and itemsu0027 context-aware aspects via co-attention mechanism. To better leverage the information from reviews, we propose an embedding method, named Entity2Vec, to jointly learn embeddings of different entities (users, items and contexts) with words in a textual review. Experimental results, on three datasets composed of millions of review records crawled from TripAdvisor, demonstrate that our CCANN significantly outperforms state-of-the-art recommendation methods, and Entity2Vec can further boost the modelu0027s performance.","[{'name': 'Lei Li', 'org': 'Hong Kong Baptist University', 'id': 2809426687}, {'name': 'Ruihai Dong', 'org': 'university College Dublin', 'id': 2122125241}, {'name': 'Li Chen', 'org': 'Hong Kong Baptist University', 'id': 2444561585}]"
2084947233,"Context-aware systems: the 'right' information, at the 'right' time, in the 'right' place, in the 'right' way, to the 'right' person",2012,0,70.37396240234375,bm25,recall,"Based on the assumption that the scarce resource for many people in the world today is not information but human attention, the challenge for future human-centered computer systems is not to deliver more information ""to anyone, at anytime, and from anywhere,"" but to provide ""the u0027rightu0027 information, at the u0027rightu0027 time, in the u0027rightu0027 place, in the u0027rightu0027 way, to the u0027rightu0027 person.""   This article develops a multidimensional framework for context-aware systems to address this challenge, transcending existing frameworks that limited their concerns to particular aspects of context-awareness and paid little attention to potential pitfalls. The framework is based on insights derived from the development and assessment of a variety of different systems that we have developed over the last twenty years to explore different dimensions of context awareness.   Specific challenges, guidelines, and design trade-offs (promises and pitfalls) are derived from the framework for designing the next generation of context-aware systems. These systems will support advanced interactions for assisting humans (individuals and groups) to become more knowledgeable, more productive, and more creative by emphasizing context awareness as a fundamental design requirement.","[{'name': 'Gerhard Fischer', 'org': 'University of Colorado—Boulder', 'id': 2176357113}]"
1967127022,Context-aware filtering for collaborative web systems: adapting the awareness information to the user's context,2005,0,69.94595336914062,bm25,recall,"We propose a context-based filtering process which aims at adapting the awareness information delivered to mobile users by collaborative web systems. This filtering process relies on a model of context which integrates both a physical and an organizational dimensions and allows to represent the useru0027s current context as well as general profiles. These profiles are descriptions of useru0027s potential contexts and express the awareness information filtering rules to apply when the useru0027s current context matches one of them. These rules reflect the useru0027s preferences given a context. We describe how the filtering process performs in two steps, one for identifying the general profiles that apply, and a second for selecting the awareness information. We also discuss the patterns matching algorithms used in the filtering process to compare the contexts descriptions.","[{'name': 'Manuele Kirsch-Pinheiro', 'org': 'LSR Laboratory - IMAG, France', 'id': 2111662535}, {'name': 'Marlène Villanova-Oliver', 'org': 'LSR Laboratory - IMAG, France', 'id': 2003846454}, {'name': 'Jérôme Gensel', 'org': 'LSR Laboratory - IMAG, France', 'id': 1991503983}, {'name': 'Hervé Martin', 'org': 'LSR Laboratory - IMAG, France', 'id': 2462711942}]"
2923779212,Selective Attention for Context-aware Neural Machine Translation,2019,0,69.8919677734375,bm25,recall,"Despite the progress made in sentence-level NMT, current systems still fall short at achieving fluent, good quality translation for a full document. Recent works in context-aware NMT consider only a few previous sentences as context and may not scale to entire documents. To this end, we propose a novel and scalable top-down approach to hierarchical attention for context-aware NMT which uses sparse attention to selectively focus on relevant sentences in the document context and then attends to key words in those sentences. We also propose single-level attention approaches based on sentence or word-level information in the context. The document-level context representation, produced from these attention modules, is integrated into the encoder or decoder of the Transformer model depending on whether we use monolingual or bilingual context. Our experiments and evaluation on English-German datasets in different document MT settings show that our selective attention approach not only significantly outperforms context-agnostic baselines but also surpasses context-aware baselines in most cases.","[{'name': 'Sameen Maruf', 'id': 2767938850}, {'name': 'André F. T. Martins', 'id': 2121178374}, {'name': 'Gholamreza Haffari', 'id': 1432492132}]"
2106378965,Using context-aware crossover to improve the performance of GP,2006,0,69.82539367675781,bm25,recall,"This paper describes the use of a recently introduced crossover operator for GP, context-aware crossover. Given a randomly selected subtree from one parent, context-aware crossover will always find the best location to place the subtree in the other parent.We examine the performance of GP when context-aware crossover is used as an extra crossover operator, and show that standard crossover is far more destructive, and that performance is better when only context-aware crossover is used.There is still a place for standard crossover, however, and results suggest that using standard crossover in the initial part of the run and then switching to context-aware crossover yields the best performance.We show that, across a range of standard GP benchmark problems, context-aware crossover produces a higher best fitness as well as a higher mean fitness, and even manages to solve the 11-bit multiplexer problem without ADFs. Furthermore, the individuals produced this way are much smaller than standard GP, and far fewer individual evaluations are required, so GP achieves a higher fitness by evaluating fewer and smaller individuals.","[{'name': 'Hammad Majeed', 'org': 'University of Limerick\u2028Ireland', 'id': 2071058339}, {'name': 'Conor Ryan', 'org': 'University of Limerick\u2028Ireland', 'id': 2118252332}]"
1569889253,Using categorial Context-SHOIQ(D+) DL to migrate between the context-aware scenes,2006,0,69.76648712158203,bm25,recall,"An important issue in semantic web ontology application is how to improve ontological evolvement to fit the semantics of the unceasingly changing context. This paper presents a context-based formalism- Context-SHOIQ(D+) DL which is under the frame of SHOIQ(D+) DL, a kind of description logic, from the category theory point of view. The core part of the proposed formalism is a categorial context based on the SHOIQ(D+) DL, that captures and explicitly represents the information about contexts. Additionally, this paper presents some meta languages about reasoning and knowledge representation, finally discusses context-aware migration between different scenes with the categorial Context-SHOIQ(D+)DL.","[{'name': 'Ruliang Xiao', 'org': 'State-Key Lab. of Software Eng., Wuhan Univ., WuHan, China', 'id': 2193818956}, {'name': 'Shengqun Tang', 'org': 'State-Key Lab. of Software Eng., Wuhan Univ., WuHan, China', 'id': 2715642699}, {'name': 'Ling Li', 'org': 'State-Key Lab. of Software Eng., Wuhan Univ., WuHan, China', 'id': 2590483457}, {'name': 'Lina Fang', 'org': 'State-Key Lab. of Software Eng., Wuhan Univ., WuHan, China', 'id': 2159617063}, {'name': 'Youwei Xu', 'org': 'State-Key Lab. of Software Eng., Wuhan Univ., WuHan, China', 'id': 2100762296}, {'name': 'Yang Xu', 'org': 'State-Key Lab. of Software Eng., Wuhan Univ., WuHan, China', 'id': 2608216801}]"
2015756376,The role of attention in the affordance effect: can we afford to ignore it?,2012,0,69.6510238647461,bm25,recall,"It has been established that the task-irrelevant orientation of an object’s graspable handle produces a stimulus–response compatibility effect, resulting in faster reaction times when the location of the response corresponds to that of the object’s handle. There is ongoing debate whether to attribute this affordance effect to motoric or to attentional components. In an attempt to reconcile these two viewpoints, we employed a novel experimental approach for investigating the relationship between attention and affordance. Using 3-D positional sound, auditory spatial attention was manipulated in order to explore its effects on affordance. Subjects were presented images of everyday graspable objects and had to respond bimanually (left or right) whether the object (featuring a leftward or rightward handle) was presented upright or upside-down. Prior to each affording object, sound localization cues were manipulated so as to orient auditory attention to the left, or to the right of the interaural axis (control). We obtained a peculiar pattern of results, which not only appears to provide support for an attention-shift account of affordance but does so in a cross-modal context.","[{'name': 'Kiril Kostov', 'org': 'New Bulgarian University', 'id': 2483209758}, {'name': 'Armina Janyan', 'org': 'New Bulgarian University', 'id': 117228001}]"
1867403257,The Dilated Triple,2010,0,69.54215240478516,bm25,recall,"The basic unit of meaning on the Semantic Web is the RDF statement, or triple, which combines a distinct subject, predicate and object to make a definite assertion about the world. A set of triples constitutes a graph, to which they give a collective meaning. It is upon this simple foundation that the rich, complex knowledge structures of the Semantic Web are built. Yet the very expressiveness of RDF, by inviting comparison with real-world knowledge, highlights a fundamental shortcoming, in that RDF is limited to statements of absolute fact, independent of the context in which a statement is asserted. This is in stark contrast with the thoroughly context-sensitive nature of human thought. The model presented here provides a particularly simple means of contextualizing an RDF triple by associating it with related statements in the same graph. This approach, in combination with a notion of graph similarity, is sufficient to select only those statements from an RDF graph which are subjectively most relevant to the context of the requesting process.","[{'name': 'Marko A. Rodriguez', 'org': 'Los\xa0Alamos National Laboratory', 'id': 2131672109}, {'name': 'Alberto Pepe', 'org': 'University of California at Los Angeles', 'id': 2042229455}, {'name': 'Joshua Shinavier', 'org': 'Knowledge Reef Systems Inc.', 'id': 183065786}]"
1526648238,The Semantic Binary Relationship Model of information,1984,0,69.39051055908203,bm25,recall,"The Semantic Binary Relationship Model (SBRM) is a first-order formalism which combines an organisationally simple basis (i.e. binary relationships) with the capabilities of semantic networks and logical integrity and deduction rules. The aim is to permit the efficient modelling of practical enterprises In a DBMS context, whilst accommodating the requirements of knowledge-based systems. The theoretical foundations of the SBRM are described, with particular attention to inheritance hierarchies and rule representation. The low-level unit of SBRM information is the triple. A 4Mbyte associatively-accessed triple store is being constructed, and will form the heart of a smart information machine based on the SBRM.","[{'name': 'M. Azmoodeh', 'org': 'Univ. of Essex,Colchester,England', 'id': 1925195417}, {'name': 'S. H. Lavington', 'org': 'University of Manchester, Manchester, England', 'id': 100025731}, {'name': 'M. Standring', 'org': 'University of Manchester, Manchester, England', 'id': 2974222202}]"
2118112512,The Cartesian approach to context,2010,0,69.01443481445312,bm25,recall,"We present a new approach for context-oriented programming in which the context is represented by a set of (dimension, value) pairs. This tuple parameterizes the environment, and it can be referred to either as a single entity or as a composed entity, parts of which can independently be accessed. The context is also an index into any programmable entity, in our model the hyperdatons, which are in turn, arbitrary-dimensional arrays of arbitrary extent.   The context may have privileged dimensions and one such dimension is time, which has as well a physical interpretation. The importance of this dimension relies on the fact that its proper handling will allow the control of software evolution, of systems, and of system instances or views; partial changes or updates to specific parts of a system; and synchronous communications between heterogenous components or even systems. In fact, it is our tool to create synchronous Cartesian systems, essential for context-aware distributed systems.   The implementation of a Cartesian distributed system may rely on the behavior of several subsystems, all running on an internal clock necessarily infinitely faster than the external one, since a bunch of tasks in a subsystem, corresponds to one tick of the system. These subsystems all run with respect to a shared context called an aether, which facilitates communication by broadcasting between systems at possibly different levels. The aether in this case is an active context.","[{'name': 'John Plaice', 'org': 'The Univ. of New South Wales (Australia)', 'id': 2075546996}, {'name': 'Blanca Mancilla', 'org': 'The Univ. of New South Wales (Australia)', 'id': 2125621221}]"
1997848731,A Generic Context Interpreter for Pervasive Context-Aware Systems,2011,0,68.91265106201172,bm25,recall,"Developing pervasive context-aware systems to construct smart space applications has attracted much attention from researchers in recent decade. Although many different kinds of context-aware computing paradigms were built of late years, it is still a challenge for researchers to extend an existing system to different application domains and interoperate with other service systems due to heterogeneity among systems This paper proposes a generic context interpreter to overcome the dependency between context and hardware devices. The proposed generic context interpreter contains two modules: the context interpreter generator and the generic interpreter. The context interpreter generator imports sensor data from sensor devices as an XML schema and produces interpretation scripts instead of interpretation widgets. The generic interpreter generates the semantic context for context-aware applications. A context editor is also designed by employing schema matching algorithms for supporting context mapping between devices and context model.","[{'name': 'Been-Chian Chien', 'org': 'National University of Tainan Taiwan', 'id': 2025972543}, {'name': 'Shiang-Yi He', 'org': 'National University of Tainan Taiwan', 'id': 2789936063}]"
1595298913,Designing the context matching engine for evaluating and selecting context information sources,2005,0,68.46089935302734,bm25,recall,"The easy creation of context-aware services requires the support of management facilities that provide ways to more easily acquire, represent and distribute context information. This paper claims that the quality level of a context-aware service determines the context information to be obtained. On the other hand, using context data produced by unsteady sources may affect the usersu0027 satisfaction. In this perspective, we introduce the Context Matching Engine that trades off the cost, the user preferences and the quality of the available context information in order to discover the best context sources for each customized context-aware service. According to the proposed approach, there is no need for the services to know beforehand the context providers to retrieve information, but the evaluation and the quality-aware selection of the context information on context request are envisioned. Finally, it allows services to be ported easily to environments with different set of context sources.","[{'name': 'Maria Chantzara', 'org': 'Computer Networks Laboratory, School of Electrical & Computer Engineering, National Technical University of Athens (NTUA), Athens, Greece', 'id': 2028224364}, {'name': 'Miltiades Anagnostou', 'org': 'Computer Networks Laboratory, School of Electrical & Computer Engineering, National Technical University of Athens (NTUA), Athens, Greece', 'id': 2241819371}]"
1985951810,There is more to context than location,1999,0,68.21803283691406,bm25,recall,"Abstract   Context is a key issue in interaction between human and computer, describing the surrounding facts that add meaning. In mobile computing location is usually used to approximate context and to implement context-aware applications. We propose that ultra-mobile computing, characterized by devices that are operational and operated while on the move (e.g. PDAs, mobile phones, wearable computers), can significantly benefit from a wider notion of context. To structure the field we introduce a working model for context, discuss mechanisms to acquire context beyond location, and application of context-awareness in ultra-mobile computing. We investigate the utility of sensors for context-awareness and present two prototypical implementations — a light-sensitive display and an orientation-aware PDA interface. The concept is then extended to a model for sensor fusion to enable more sophisticated context recognition. Based on an implementation of the model an experiment is described and the feasibility of the approach is demonstrated. Further, we explore fusion of sensors for acquisition of information on more sophisticated contexts.","[{'name': 'Albrecht Schmidt', 'org': 'Telecooperation Office (TecO), University of Karlsruhe, Vincenz-Priessnitz-Str. 1, 76131 Karlsruhe, Germany', 'id': 2688824889}, {'name': 'Michael Beigl', 'org': 'Telecooperation Office (TecO), University of Karlsruhe, Vincenz-Priessnitz-Str. 1, 76131 Karlsruhe, Germany', 'id': 673846798}, {'name': 'Hans-Werner Gellersen', 'org': 'Telecooperation Office (TecO), University of Karlsruhe, Vincenz-Priessnitz-Str. 1, 76131 Karlsruhe, Germany', 'id': 2158882570}]"
2783417290,The Ordered-triple Theory of Language: Its History and the Current Context,2017,0,68.02293395996094,bm25,recall,"In this paper, we recall the historical perspectives of the Ordered-Triple Theory of Language (OTT) whose authors are Materna, Pala and Svoboda. The Ordered-Triple Theory, as the title suggests captures three fundamental components of a language system, i.e. syntax, semantics and pragmatics, and is fully comparable with similar linguistic theories. It became a starting point for further interconnection of logic, linguistics and informatics thanks to the intensive mutual cooperation of Pala and Materna at the newly established Faculty of Informatics from 1995. We show the subsequent milestones related to OTT and its realisation by means of the transparent intensional logic (TIL) in relation to the natural language processing (primarily Czech).","[{'name': 'Aleš Horák', 'id': 1831577790}, {'name': 'Karel Pala', 'id': 1534150975}]"
2012745463,Enabling Context-Aware Agents to Understand Semantic Resources on The WWWand The Semantic Web,2004,0,67.247314453125,bm25,recall,"Six years after Tim Berners-Lee and his colleagues drew the vision of the Semantic Web (SW) in 1998, the SW is very likely to take off in the near future based on a set of specifications such as the Resource Description Framework (RDF) and the Web Ontology Language (OWL). As a natural result, people will see the coexistence of the WWW and the SW for a certain long time. Under this situation, how to bridge the gap between the WWW and the SW will become an inevitable issue. In this paper, we present a context-aware approach on enabling agents to understand semantic resources on the two webs. The basic idea of this approach is to structure user-centred contextual information to facilitate agent-based (inter)operations on the network. Based on this idea, we design a Knowledge Interoperation Reference Model (KIRM) to address the interoperation issue at the global level. To demonstrate how agents understand semantic resources in a context-aware manner in real practices, we develop a news aggregation system based on RDF Site Summary / Really Simple Syndication (RSS) using agents. Considering the fact that RSS format set is a combination of XML and RDF, the success of agent understanding of RSS content under specific semantic contexts shows the possibility of extending and applying the context-aware approach in other semantic-based applications on both the WWW and the SW in the future.","[{'name': 'Weihong Huang', 'org': 'The University of Hull, UK#TAB#', 'id': 2693708713}, {'name': 'David Webster', 'org': 'The University of Hull, UK#TAB#', 'id': 2145303870}]"
339021734,How to Identify the Relevant Elements of “Context” in Context-Aware Information Systems?,2014,0,67.19999694824219,bm25,recall,"Context-awareness is a feature of more and more applications, which adds further requirements to be taken into account in the implementation process. Though accepted approaches for software development exist, no accepted way for the inclusion of context has been established yet. An essential part of developing context based systems is to analyze and conceptualize the elements of the specific context required for the application under development, including their dependencies and mechanism of use. This activity of context modeling forms an important part of the system’s specification, since it identifies relevant aspects of the application environment in a representation adequate for the modeling purpose. Within this paper we aim at closing this gap by introducing an approach for context modeling for the utilization in context-aware applications, providing a structure guiding through the process and illustrating it by examples as a reference for further projects.","[{'name': 'Kurt Sandkuhl', 'org': 'University of Rostock#TAB#', 'id': 2805948534}, {'name': 'Ulrike Borchardt', 'org': 'University of Rostock#TAB#', 'id': 1916008951}]"
1542346294,A genetic context interpreter for context-aware systems in pervasive computing environments,2010,0,67.1748275756836,bm25,recall,"Developing context-aware applications in pervasive computing environments has attracted much attention from researchers in recent decade Although dozens of context-aware computing paradigms were built these years, it is difficult for the present systems to extend the application domains and interoperate with other service systems due to the problem of heterogeneity among systems In this paper, we propose and construct a generic context interpreter to overcome the dependence problem between context and hardware devices based on the proposed context-aware (CADBA) architecture The idea of the context generic interpreter imports sensor data from sensor devices as an XML schema Instead of interpretation widgets, interpretation scripts are produced by a context generator and a generic context interpreter is used to provide the semantic context for context-aware applications A context editor is also designed by employing schema matching schemes for supporting intelligent context mapping between devices and context model.","[{'name': 'Been-Chian Chien', 'org': 'Department of Computer Science and Information Engineering, National University of Tainan, Tainan, Taiwan, R.O.C#TAB#', 'id': 2025972543}, {'name': 'Shiang-Yi He', 'org': 'Department of Computer Science and Information Engineering, National University of Tainan, Tainan, Taiwan, R.O.C#TAB#', 'id': 2789936063}]"
1484959214,An investigation into a universal context model to support context-aware applications,2006,0,66.76506805419922,bm25,recall,"If a mobile device is to offer rich context-aware behaviour it must have a good knowledge of the world around us This paper explores the concept of universal context model, able to represent any form of context information and therefore be an enabler to the full spectrum of context-aware applications It explores how such a model may accurately represent – as far as practically possible – the multitude of different objects we encounter in our surrounding environment and their many states and interrelationships Three key propositions are that the context model should be of an object-oriented nature, that location is most appropriately and flexibly represented as a relationship between two objects rather than being considered as a special type of object unto itself, and finally, that objects may be coupled with observer-dependent validity rules that determine if the object is visible within the model.","[{'name': 'Jason Pascoe', 'org': 'Information Systems Department, University of Minho, Guimarães, Portugal#TAB#', 'id': 2303880464}, {'name': 'Helena Rodrigues', 'org': 'Information Systems Department, University of Minho, Guimarães, Portugal#TAB#', 'id': 2117989789}, {'name': 'César Ariza', 'org': 'Information Systems Department, University of Minho, Guimarães, Portugal#TAB#', 'id': 2333644741}]"
2074809891,Unifying metric approach to the triple parity,2002,0,66.68645477294922,bm25,recall,"The even-odd parity problem is a tough one for neural networks to handle because they assume a finite dimensional vector space. Typically, the size of the neural network increases as the size of the problem increases. The triple parity problem is even tougher. In this paper, a method is proposed for supervised and unsupervised learning to classify bit strings of arbitrary length in terms of their triple parity: The learner is modeled by two formal concepts, transformation system and stability optimization. Even though a small set of short examples were used in the training stage, all bit strings of any length were classified correctly in the online recognition stage. The proposed learner has successfully learned to devise a way by means of metric calculations to classify bit strings of any length according to their triple parity. The system was able to acquire the concept of counting, dividing, and then taking the remainder, by autonomously evolving a set of string-editing rules along with their appropriate weights to solve the difficult problem.","[{'name': 'Tony Y. T. Chan', 'org': 'The University of Aizu, Aizu-Wakamatsu City, Fukushima Prefecture, Japan#TAB#', 'id': 2306880745}]"
2160792416,A generic approach for on-the-fly adding of context-aware features to existing websites,2011,0,66.56871795654297,bm25,recall,"More and more, mobile devices act as personal information managers and are able to obtain rich contextual information on the useru0027s environment. Mobile, context-aware web applications can exploit this information to better address the needs of mobile users. Currently, such websites are either developed separately from their associated desktop-oriented version, or both versions are created simultaneously by employing methodologies that support multi-platform context-aware websites, requiring an extensive engineering effort. While these approaches provide a solution for developing new websites, they go past the plethora of existing websites. To address this issue, we present an approach for enhancing existing websites on-the-fly with context-aware features. We first discuss the requirements for such an adaptation process, and identify applicable adaptation methods to realize context-aware features. Next, we explain our generic approach, which is grounded in the use of semantic information extracted from existing websites. Finally, we present a concrete application of our approach that is based on the SCOUT framework for mobile and context-aware application development.","[{'name': 'William Van Woensel', 'org': 'Vrije Universiteit Brussel; Brussels Belgium', 'id': 2060419097}, {'name': 'Sven Casteleyn', 'org': 'Universitat Politecnica de Valencia, Valencia (Spain)#TAB#', 'id': 2161364025}, {'name': 'Olga De Troyer', 'org': 'Vrije Universiteit Brussel; Brussels Belgium', 'id': 685300706}]"
2287271353,A robust extension to the triple plane pressure mode matching method by filtering convective perturbations,2016,0,66.52720642089844,bm25,recall,Time-periodic computational fluid dynamics simulations are widely used to investigate turbomachinery components. The triple plane pressure mode matching method developed by Ovenden and Rienstra extracts the acoustic part in such simulations. Experience shows that this method is subject to significant errors when the amplitude of pseudo-sound is high compared to sound. Pseudo-sounds are unsteady pressure fluctuations with a convective character. The presented extension to the triple plane pressure improves the splitting between acoustics and the rest of the unsteady flow field. The method is simple: (i) the acoustic eigenmodes are analytically determined for a uniform mean flow as in the original triple plane pressure mode matching method; (ii) the suggested model for convective pressure perturbations uses the convective wavenumber as axial wavenumber and the same orthogonal radial shape functions as for the acoustic modes. The reliability is demonstrated on the simulation data of a low-pressure fan. As ac...,"[{'name': 'Attila Wohlbrandt', 'org': 'German Aerospace Center, Institute of Propulsion Technology, Engine Acoustics Department, Berlin, Germany', 'id': 1807438715}, {'name': 'Christian Weckmüller', 'org': 'German Aerospace Center, Institute of Propulsion Technology, Engine Acoustics Department, Berlin, Germany', 'id': 1985893551}, {'name': 'Sébastien Guérin', 'org': 'German Aerospace Center, Institute of Propulsion Technology, Engine Acoustics Department, Berlin, Germany', 'id': 1998627252}]"
2762006853,Identifying the Relationships Between the Visualization Context and Representation Components to Enable Recommendations for Designing New Visualizations,2017,0,66.51580047607422,bm25,recall,"In this paper we address the question of the relationships between visualization challenges and the representation components that provide solutions to these challenges. Our approach involves extracting such relationships through an identification of the context and the components of a significant number of representations and a comparison of the result to existing theoretical studies. To make such an identification possible, we rely on a characterization of the representation context based on a thoughtful aggregation of existing characterizations of the data type, the tasks and the context of use of the representations. We illustrate our approach on a use-case with examples of a relationships extraction and of a comparison of that relationships to the theory. We believe that the establishment of such relationships makes it possible to understand the mechanisms behind the representations, in order to build a representation design recommendation tool. Such a tool will enable us to recommend the components to use in a representation, given a visualization challenge to address.","[{'name': 'Alma Cantu', 'org': 'Lab-STICC_IMTA_CID_IHSEV', 'id': 2516900866}, {'name': 'Olivier Grisvard', 'org': 'Lab-STICC_IMTA_CID_IHSEV', 'id': 232656587}, {'name': 'Thierry Duval', 'org': 'Lab-STICC_IMTA_CID_IHSEV', 'id': 2935193209}, {'name': 'Gilles Coppin', 'org': 'Lab-STICC_IMTA_CID_IHSEV', 'id': 1445098211}]"
2086705444,Keynote: Context-aware computing in the era of crowd sensing from personal and space context to social and community context,2013,0,66.47319030761719,bm25,recall,"Since the seminal work of Schilit and Theimer on context-awareness in 1994, great research progress has been made in context-aware computing field. Due to limited deployment scale of sensors and devices, in early years context-aware computing focused mainly on understanding and exploiting personal context in single smart spaces. As a result of the recent explosion of sensor-equipped mobile phones, the phenomenal growth of Internet and social network services, the broader use of the Global Positioning System (GPS) in all types of public transportation, and the extensive deployment of sensor network and WiFi in both indoor and outdoor environments, the digital footprints left by people while interacting with cyber-physical spaces are accumulating with an unprecedented speed and scale. The technology trend towards crowd sensing is creating new challenges and opportunities for context-aware computing - with huge amount, large scale, multi-modal, different granularity, diverse quality of data from various data sources. In this talk, I will present a new research direction called “social and community intelligence (SCI)” as a natural extension of context-aware computing in the era of crowd sensing, with emphasis on extracting community and society level context; in particular I will introduce our work in mining large scale taxi GPS data, mobile phone data and social media data for enabling innovative applications in smart cities. Finally I will briefly summarize the difference between traditional context-aware computing and SCI in terms of data acquisition, modeling, inference, storage and context inferred.","[{'name': 'Daqing Zhang', 'org': 'CNRS SAMOVAR, Institut Mines-TELECOM/TELECOM SudParis, Evry 91011, France', 'id': 2156097516}]"
2916273528,The MOM of context-aware systems: A survey,2019,0,66.40438842773438,bm25,recall,"Abstract   Context-aware computing enriches the capabilities of intelligent devices complemented with smart applications and helps establish smart ecosystems in fields such as Ambient Intelligence, Internet of Things, Mobile Computing, and Pervasive and Ubiquitous Computing. Though the literature has many surveys that outline existing systems, it still remains critical to elucidate the basics of actually building an effective context-aware ecosystem. We outline the basic components required and essential for the same. We believe that a context-aware ecosystem becomes effective when these components are designed and implemented effectively. We call it the MOM of context-aware systems: generic and effective context Modeling, an efficient context Organization, and a robust context Middleware. Context modeling affords a syntax to the raw pieces of relevant information, the organization mechanism furnishes semantic import to the information and relationships, and the middleware compiles and integrates the information, enabling sharing of context. We discuss various context-aware ecosystems and middleware from the literature and highlight how the three building components function in each case. This paper will benefit newcomers to the field who are looking to learn about and build context-aware ecosystems.","[{'name': 'Preeja Pradeep', 'org': 'Amrita School of Engineering, Amritapuri Amrita Vishwa Vidyapeetham, India', 'id': 2115234459}, {'name': 'Shivsubramani Krishnamoorthy', 'org': 'Amrita School of Engineering, Amritapuri, Amrita Vishwa Vidyapeetham, India', 'id': 2122989739}]"
2902445348,Context-Aware Attention LSTM Network for Flood Prediction,2018,0,66.33617401123047,bm25,recall,"To minimize the negative impacts brought by floods, researchers from pattern recognition community utilize artificial intelligence based methods to solve the problem of flood prediction. Inspired by the significant power of Long Short-Term Memory (LSTM) networks in modeling the dynamics and dependencies of sequential data, we intend to utilize LSTM networks to predict sequential flow rate values based on a set of collected flood factors. Since not all factors are informative for flood prediction and the irrelevant factors often bring a lot of noise, we need to pay more attention to the informative ones. However, original LSTM doesnu0027t have strong attention capability. Hence we propose an context-aware attention LSTM (CA-LSTM) network for flood prediction, which is capable to selectively focus on informative factors. During training, the local context-aware attention model is constructed by learning probability distributions between flow rate and hidden output of each LSTM cell. During testing, the learned local attention model assign weights to adjust relations between input factors and predictions at all steps of LSTM network. We conduct experiments on a flood dataset with several comparative methods to demonstrate high accuracy of the proposed method and the effectiveness of the proposed context-aware attention model.","[{'name': 'Yirui wu', 'org': 'College of Computer and Information, Hohai University , Nanjing , China', 'id': 2136821634}, {'name': 'Zhaoyang Liu', 'org': 'Nat. Key Lab. for Novel Software Technol., Nanjing Univ., Nanjing, China', 'id': 2891785468}, {'name': 'Weigang Xu', 'org': 'College of Computer and Information, Hohai University , Nanjing , China', 'id': 2903207436}, {'name': 'Jun Feng', 'org': 'College of Computer and Information, Hohai University , Nanjing , China', 'id': 2890972743}, {'name': 'Shivakumara Palaiahnakote', 'org': '(Faculty of Computer Science & Information Technology, University of Malaya, Kuala Lumpur, Malaysia)', 'id': 191983659}, {'name': 'Tong Lu', 'org': 'Nat. Key Lab. for Novel Software Technol., Nanjing Univ., Nanjing, China', 'id': 2106442809}]"
163775510,Evolving context-unaware to context-aware model using the ESC ontology,2012,0,66.3158950805664,bm25,recall,This paper presents a process for transforming a context-unaware model into a context-aware based on the Entity Situation Context ontology.,"[{'name': 'Hélio Martins', 'org': 'GECAD - Knowledge Engineering and Decision Support Research Group, School of Engineering, Polytechnic of Porto, Porto, Portugal#TAB#', 'id': 2174783891}, {'name': 'Nuno Silva', 'org': 'GECAD - Knowledge Engineering and Decision Support Research Group, School of Engineering, Polytechnic of Porto, Porto, Portugal#TAB#', 'id': 2117742911}]"
2122591003,To Select the Service in Context Aware Systems Using Concept Similarity Mechanism,2008,0,66.31248474121094,bm25,recall,"As the most important component of pervasive computing in mobile business, context-aware system gets more and more attention from the researchers. One of the basic technologies used to implement the contextsu0027 description and reasoning in context-aware systems is ontology which has the big advantage at knowledge presenting and sharing. However, the shortage of the existing methods with ontology is obvious that most of them are predefined which makes them too fixed to provide the flexible services. In this paper, we provide CS_SRM, a totally new method to provide the flexible service recommendations based on the similarity computing of the semantic meanings in the given concepts which are corresponding to the different contexts. At last the simulating experiments prove its effectiveness.","[{'name': 'Juan Yang', 'org': 'Fac. of Comput. & Inf. Sci., Southwest Univ., Chongqing', 'id': 2720523721}, {'name': 'Yun Bai', 'id': 2710164230}, {'name': 'Fang Wang', 'id': 2633086021}, {'name': 'Yu hui Qiu', 'id': 2228236579}]"
2883034792,Unrest News Amount Prediction with Context-Aware Attention LSTM,2018,0,66.19315338134766,bm25,recall,"Accurately predicting social unrest events is crucial to improve public security. Currently, with the large scale news event datasets available such as GDELT, we can use the amount of unrest news to estimate the risk of instability which is particularly helpful in resource allocation and policy making. Thus in this paper we propose a context-aware attention based long short-term memory (LSTM) prediction framework named CA-LSTM to accurately predict the amount of unrest news of each country or state in the future. Specifically, we first use LSTM to learn the hidden representation from the raw time series data, and then we employ a temporal attention mechanism to learn the importance weight of each time slot. Finally, a fully connected layer is adopted to predict the future unrest news amount by combining the context information and the time series embedding vectors. We conduct extensive experiments on the GDELT data of the United States, and the results demonstrate the effectiveness of the proposed framework.","[{'name': 'Xiuling Wang', 'org': 'Beihang University', 'id': 2883723643}, {'name': 'Hao Chen', 'org': 'Beihang University', 'id': 2883099580}, {'name': 'Zhoujun Li', 'org': 'Beihang University', 'id': 2133880114}, {'name': 'Zhonghua Zhao', 'org': 'National Computer Network Emergency Response Technical Team, Coordination Center of China', 'id': 2883299802}]"
2971885210,Context-Aware Multi-View Attention Networks for Emotion Cause Extraction,2019,0,65.78880310058594,bm25,recall,"Emotion cause extraction aims at automatically identifying cause clauses for a certain emotion expressed in a document. It is an important task in emotion analysis since it helps form a deeper understanding of emotion text. Detecting potential causes of user emotion in online contents is beneficial to public opinion monitoring, government decision-making, and other security-related applications. Existing studies treat this task as a binary clause-level classification problem, which considers each clause separately and omits the context information of clauses. Moreover, previous work only models emotion-dependent linguistic representations of clauses but ignores emotion-independent features in clauses including cause indicators. To address the above two issues, we formalize this task as a sequence labeling problem and propose the COntext-aware Multi-View attention networks (COMV) for emotion cause extraction. Our proposed model integrates context information and learns multi-view clause representations. Experimental results show that our model outperforms existing state-of-the-art methods.","[{'name': 'Xinglin Xiao', 'org': 'State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences#TAB#', 'id': 2972043008}, {'name': 'Penghui Wei', 'org': 'State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences#TAB#', 'id': 2798631538}, {'name': 'Wenji Mao', 'org': 'State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences#TAB#', 'id': 2164388523}, {'name': 'Lei Wang', 'org': 'State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences#TAB#', 'id': 2722664324}]"
2949595813,Context-aware attention network for image recognition,2019,0,65.77833557128906,bm25,recall,"Existing recognition methods based on deep learning have achieved impressive performance. However, most of these algorithms do not fully utilize the contexts and discriminative parts, which limit the recognition performance. In this paper, we propose a context-aware attention network that imitates the human visual attention mechanism. The proposed network mainly consists of a context learning module and an attention transfer module. Firstly, we design the context learning module that carries on contextual information transmission along four directions: left, right, top and down to capture valuable contexts. Second, the attention transfer module is proposed to generate attention maps that contain different attention regions, benefiting for extracting discriminative features. Specially, the attention maps are generated through multiple glimpses. In each glimpse, we generate the corresponding attention map and apply it to the next glimpse. This means that our attention is shifting constantly, and the shift is not random but is closely related to the last attention. Finally, we consider all located attention regions to achieve accurate image recognition. Experimental results show that our method achieves state-of-the-art performance with 97.68% accuracy, 82.42% accuracy, 80.32% accuracy and 86.12% accuracy on CIFAR-10, CIFAR-100, Caltech-256 and CUB-200, respectively.","[{'name': 'Jiaxu Leng', 'org': 'School of Computer Science and Technology, University of Chinese Academy of Sciences, Beijing, China', 'id': 2913571430}, {'name': 'Ying Liu', 'org': 'School of Computer Science and Technology, University of Chinese Academy of Sciences, Beijing, China', 'id': 2625756337}, {'name': 'Shang Chen', 'org': 'School of Information and Communication, Guilin University of Electronic Technology,Guilin,China', 'id': 2951804531}]"
2083109525,Maturity is also about the capability to conform the process to the right context,2010,0,65.74720764160156,bm25,recall,"Organizations, their businesses and contexts are multi-dimensional, diverse, and very complex today. Hence, creating homogenous process models for managing them may not always be an optimal solution. Instead, organizations should be able to tailor their processes to the formality level required for the context at hand. In this paper, we claim that the organizational maturity is not only about how organizations are capable to manage their processes. It is also about how capable they are in adapting them to specific contexts and business needs. We also suggest Context-Driven Process Orchestration Method (CoDPOM), based on the concept of practice choreography and process orchestration. The CoDPOMu0027s role is to aid software practitioners in identifying process needs and in recognizing waste which, in turn, would aid them in adapting their software processes to specific contexts, business needs and formality levels.","[{'name': 'Mira Kajko-Mattsson', 'org': '((Royal Institute of Technology, Stockholm, Sweden))', 'id': 2083522566}]"
2897464384,Multi-Scale Context Attention Network for Image Retrieval,2018,0,65.27690887451172,bm25,recall,"Recent attempts on the Convolutional Neural Network (CNN) based image retrieval usually adopt the output of a specific convolutional or fully connected layer as feature representation. Though superior representation capability has yielded better retrieval performance, the scale variation and clutter distracting remain to be two challenging problems in CNN based image retrieval. In this work, we propose a Multi-Scale Context Attention Network (MSCAN) to generate global descriptors, which is able to selectively focus on the informative regions with the assistance of multi-scale context information. We model the multi-scale context information by an improved Long Short-Term Memory (LSTM) network across different layers. As such, the proposed global descriptor is equipped with the scale aware attention capability. Experimental results show that our proposed method can effectively capture the informative regions in images and retain reliable attention responses when encountering scale variation and clutter distracting. Moreover, we compare the performance of the proposed scheme with the state-of-the-art global descriptors, and extensive results verify that the proposed MSCAN can achieve superior performance on several image retrieval benchmarks.","[{'name': 'Yihang Lou', 'org': 'Peking University Beijing China', 'id': 2593951942}, {'name': 'Yan Bai', 'org': 'Peking University Beijing China', 'id': 2618550700}, {'name': 'Shiqi Wang', 'org': 'City University of Hong Kong, Hong Kong, Hong Kong;', 'id': 2134010418}, {'name': 'Ling-Yu Duan', 'org': 'Peking University Beijing China', 'id': 2160793492}]"
2963652649,Context-Aware Self-Attention Networks,2019,0,65.2747573852539,bm25,recall,"Self-attention model has shown its flexibility in parallel computation and the effectiveness on modeling both long- and short-term dependencies. However, it calculates the dependencies between representations without considering the contextual information, which has proven useful for modeling dependencies among neural representations in various natural language tasks. In this work, we focus on improving self-attention networks through capturing the richness of context. To maintain the simplicity and flexibility of the self-attention networks, we propose to contextualize the transformations of the query and key layers, which are used to calculate the relevance between elements. Specifically, we leverage the internal representations that embed both global and deep contexts, thus avoid relying on external resources. Experimental results on WMT14 English⇒German and WMT17 Chinese⇒English translation tasks demonstrate the effectiveness and universality of the proposed methods. Furthermore, we conducted extensive analyses to quantify how the context vectors participate in the self-attention model.","[{'name': 'Baosong Yang', 'org': 'University of Macau', 'id': 2738084213}, {'name': 'Jian Li', 'org': 'The Chinese Univ. of Hong Kong', 'id': 2963099804}, {'name': 'Derek F. Wong', 'org': '(Natural Language Processing & Portuguese & Chinese Machine Translation Lab, Department of Computer and Information Science, University of Macau)', 'id': 2277077263}, {'name': 'Lidia S. Chao', 'org': 'University of Macau', 'id': 2133931021}, {'name': 'Xing Wang', 'org': 'Tencent AI Lab,', 'id': 2442797510}, {'name': 'Zhaopeng Tu', 'org': 'Tencent AI Lab,', 'id': 2126985900}]"
2889924266,Image captioning with triple-attention and stack parallel LSTM,2018,0,63.556358337402344,bm25,recall,"Abstract   Image captioning aims to describe the content of images with a sentence. It is a natural way for people to express their understanding, but a challenging and important task from the view of image understanding. In this paper, we propose two innovations to improve the performance of such a sequence learning problem. First, we give a new attention method named triple attention (TA-LSTM) which can leverage the image context information at every stage of LSTM. Then, we redesign the structure of basic LSTM, in which not only the stacked LSTM but also the paralleled LSTM are adopted, called as PS-LSTM. In this structure, we not only use the stack LSTM but also use the parallel LSTM to achieve the improvement of the performance compared with the normal LSTM. Through this structure, the proposed model can ensemble more parameters on single model and has ensemble ability itself. Through numerical experiments, on the public available MSCOCO dataset, our final TA-PS-LSTM model achieves comparable performance with some state-of-the-art methods.","[{'name': 'Xinxin Zhu', 'org': 'Information Security Center, State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing 100876, China', 'id': 2800343163}, {'name': 'Lixiang Li', 'org': 'Information Security Center, State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing 100876, China', 'id': 2162752493}, {'name': 'Jing Liu', 'org': 'National Laboratory of Pattern Recognition Institute of Automation, Chinese Academy of Sciences, Beijing, China', 'id': 2150154469}, {'name': 'Ziyi Li', 'org': 'Beijing Technology and Business University, Beijing 100048, China', 'id': 2890292319}, {'name': 'Haipeng Peng', 'org': 'Information Security Center, State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing 100876, China', 'id': 2171906865}, {'name': 'Xinxin Niu', 'org': 'Information Security Center, State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing 100876, China', 'id': 2641456794}]"
2911997761,Semantic Text Matching for Long-Form Documents,2019,0,63.352481842041016,bm25,recall,"Semantic text matching is one of the most important research problems in many domains, including, but not limited to, information retrieval, question answering, and recommendation. Among the different types of semantic text matching, long-document-to-long-document text matching has many applications, but has rarely been studied. Most existing approaches for semantic text matching have limited success in this setting, due to their inability to capture and distill the main ideas and topics from long-form text.    In this paper, we propose a novel Siamese multi-depth attention-based hierarchical recurrent neural network (SMASH RNN) that learns the long-form semantics, and enables long-form document based semantic text matching. In addition to word information, SMASH RNN is using the document structure to improve the representation of long-form documents. Specifically, SMASH RNN synthesizes information from different document structure levels, including paragraphs, sentences, and words. An attention-based hierarchical RNN derives a representation for each document structure level. Then, the representations learned from the different levels are aggregated to learn a more comprehensive semantic representation of the entire document. For semantic text matching, a Siamese structure couples the representations of a pair of documents, and infers a probabilistic score as their similarity.    We conduct an extensive empirical evaluation of SMASH RNN with three practical applications, including email attachment suggestion, related article recommendation, and citation recommendation. Experimental results on public data sets demonstrate that SMASH RNN significantly outperforms competitive baseline methods across various classification and ranking scenarios in the context of semantic matching of long-form documents.","[{'name': 'Jyun-Yu Jiang', 'org': 'University of California, Los Angeles, USA', 'id': 2746889226}, {'name': 'Mingyang Zhang', 'org': 'Google; USA', 'id': 2223566458}, {'name': 'Cheng Li', 'org': 'Google; USA', 'id': 2674810995}, {'name': 'Michael Bendersky', 'org': 'Google; USA', 'id': 2112702096}, {'name': 'Nadav Golbandi', 'org': 'Google; USA', 'id': 2642611369}, {'name': 'Marc Najork', 'org': 'Google; USA', 'id': 2477457921}]"
2034339864,Semantic Similarity of an Object as a Function of the Context (SSOFC) in a Heterogeneous Environment,2003,0,62.83367156982422,bm25,recall,"The relationship of Semantic Similarity of an Object as a Function of the Context (SSOFC) being the key factor in data integration is investigated. The SSOFC is a context-based system, which exploits the context of an object by utilizing the semantic similarity involved, in order to reconcile bottleneck conflicts (semantic) standing in the way of interoperability acquisition in heterogeneous systems. SSOFC is further re-enforced with the agents to equip architectural intelligence and facilitate the cooperative tasks, such as the versatility to pass, share, communicate, liaise, and negotiate the information among the architectural components in a human way. The SSOFC operates in semantic and schematic spaces that are linked with a projection facilitated by cooperative agents. In the Semantic Space, the semantic proximity (semPro) through its first component context captures the real world semantics from the local heterogeneous sources. Meanwhile, in Structural Space, the schema correspondences are paramount in order to capture structural similarities in an algebraic or mathematical formalism for reasoning and manipulation on the computer.","[{'name': 'Mbale Jameson', 'org': 'Department of Computer Science and Engineering, Harbin Institute of Technology, Harbin 150001, China', 'id': 2152093902}, {'name': 'Xu Xiao Fei', 'org': 'Department of Computer Science and Engineering, Harbin Institute of Technology, Harbin 150001, China', 'id': 2152111224}, {'name': 'Deng Sheng Chun', 'org': 'Department of Computer Science and Engineering, Harbin Institute of Technology, Harbin 150001, China', 'id': 2111568096}]"
2086229070,"On the Service Discovery Using Context-Awareness, Semantic Matching and Behavioural Compatibility",2012,0,62.08296203613281,bm25,recall,"Context-awareness enables a new class of applications in mobile and pervasive computing, providing relevant information to users. Service discovery mechanisms need to overcome the heterogeneity of applications and devices, and provide services with compatible capabilities to user requirements. One of the main challenges in service-oriented computing is to provide semantic representation instead of only a syntactic one. In addition, the advantage of using protocol compatibility is that the services selected not only match at the signature and semantic levels, but also at the behavioural level. In this paper, we first define a model to formalise context-aware services. Then, we describe a process to discover services based on semantic matching and protocol compatibility. Finally, we present a prototype tool that implements our approach.","[{'name': 'Javier Cubo', 'org': 'Dept. of Comput. Sci., Univ. of Malaga, Málaga, Spain', 'id': 1992643095}, {'name': 'Ernesto Pimentel', 'org': 'Dept. of Comput. Sci., Univ. of Malaga, Málaga, Spain', 'id': 2156988947}]"
2888258301,Viable Systems Model in Triple-Agile Context,2018,0,61.85614776611328,bm25,recall,"This paper reports on the results of the research regarding the Triple-Agile concept that has been introduced for supporting agile SMEs with cloud services agilely. The Triple-Agile concept implies three aspects of agility: agility of SME processes, agility of transition to cloud services, and agility of cloud service provision. The paper proposes using a viable system model, in general, and Viable Enterprise Bus design principles, in particular, to reflect services in small and medium sized enterprise ecosystems where both service providers and service consumers are SMEs. The use of a viable system model offers an opportunity to better understand relationships between services and thus may help to improve agility of service provision. The viable system model is applied to a triple-agile ecosystem from two viewpoints: the viewpoint of service and business relationship maturity and the viewpoint of service functions.","[{'name': 'Marite Kirikova', 'org': 'Riga Technical University,', 'id': 1952080939}, {'name': 'Ligita Businska', 'org': 'Riga Technical University,', 'id': 2045080054}, {'name': 'Andrejs Dubrovskis', 'org': 'Datorzinibu Centrs', 'id': 2888202364}, {'name': 'Edgars Salna', 'org': 'Datorzinibu Centrs', 'id': 2742818582}]"
2984023690,Utterance-to-Utterance Interactive Matching Network for Multi-Turn Response Selection in Retrieval-Based Chatbots,2019,0,61.837955474853516,bm25,recall,"This paper proposes an utterance-to-utterance interactive matching network (U2U-IMN) for multi-turn response selection in retrieval-based chatbots. Different from previous methods following context-to-response matching or utterance-to-response matching frameworks, this model treats both contexts and responses as sequences of utterances when calculating the matching degrees between them. For a context-response pair, the U2U-IMN model first encodes each utterance separately using recurrent and self-attention layers. Then, a global and bidirectional interaction between the context and the response is conducted using the attention mechanism to collect the matching information between them. The distances between context and response utterances are employed as a prior component when calculating the attention weights. Finally, sentence-level aggregation and context-response-level aggregation are executed in turn to obtain the feature vector for matching degree prediction. Experiments on four public datasets showed that our proposed method outperformed baseline methods on all metrics, achieving a new state-of-the-art performance and demonstrating compatibility across domains for multi-turn response selection.","[{'name': 'Jia-Chen Gu', 'id': 2902814249}, {'name': 'Zhen-Hua Ling', 'id': 2156045219}, {'name': 'Quan Liu', 'id': 2252532840}]"
1541882473,Triple space computing: adding semantics to space-based computing,2006,0,61.53165054321289,bm25,recall,"Triple Space Computing (TSC) is a very simple and powerful paradigm that inherits the communication model from Tuple Space Computing and projects it in the context of the Semantic Web In this paper, we propose Triple Space Computing as a new communication and coordination framework for Semantic Web and Semantic Web Services We identify the value added by TSC and propose the overall architecture of TSC and the interactions among different components.","[{'name': 'Johannes Riemer', 'org': 'Institute of Computer Languages, Space-Based Computing Group, Vienna University of Technology, Vienna, Austria#TAB#', 'id': 2058843837}, {'name': 'Francisco Martin-Recuerda', 'org': 'Digital Enterprise Res. Inst., Univ. of Innsbruck, Innsbruck, Austria', 'id': 237345795}, {'name': 'Ying Ding', 'org': 'Electronic WebService GmbH, Innsbruck, Austria#TAB#', 'id': 2161065209}, {'name': 'Martin Murth', 'org': 'Institute of Computer Languages, Space-Based Computing Group, Vienna University of Technology, Vienna, Austria#TAB#', 'id': 1638853903}, {'name': 'Brahmananda Sapkota', 'org': 'Digital Enterprise Research Institute National, University of Ireland, Galway, Galway, Ireland', 'id': 2398426297}, {'name': 'Reto Krummenacher', 'org': 'Digital Enterprise Res. Inst., Univ. of Innsbruck, Innsbruck, Austria', 'id': 43234139}, {'name': 'Omair Shafiq', 'org': 'Digital Enterprise Res. Inst., Univ. of Innsbruck, Innsbruck, Austria', 'id': 2043561648}, {'name': 'Dieter Fensel', 'org': 'Electronic WebService GmbH, Innsbruck, Austria#TAB#', 'id': 2303458062}, {'name': 'Eva Kühn', 'org': 'Institute of Computer Languages, Space-Based Computing Group, Vienna University of Technology, Vienna, Austria#TAB#', 'id': 2165770595}]"
2802775969,Triple Space Computing : Adding Semantics to Space-Based Computing,2006,0,61.53165054321289,bm25,recall,"Triple Space Computing (TSC) is a very simple and powerful paradigm that inherits the communication model from Tuple Space Computing and projects it in the context of the Semantic Web. In this paper, we propose Triple Space Computing as a new communication and coordination framework for Semantic Web and Semantic Web Services. We identify the value added by TSC and propose the overall architecture of TSC and the interactions among different components.","[{'name': 'Johannes Riemer', 'id': 2058843837}, {'name': 'Francisco Martin-Recuerda', 'id': 237345795}, {'name': 'Ying Ding', 'id': 2161065209}, {'name': 'Martin Murth', 'id': 1638853903}, {'name': 'Brahmananda Sapkota', 'id': 2398426297}, {'name': 'Reto Krummenacher', 'id': 43234139}, {'name': 'Omair Shafiq', 'id': 2043561648}, {'name': 'Dieter Fensel', 'id': 2303458062}, {'name': 'Eva Kühn', 'id': 2165770595}]"
2574533737,Integration of Dependency Analysis with Semantic Analysis Referring to the Context,2005,0,61.48158264160156,bm25,recall,"This paper describes how to perform syntactic parsing and semantic analysis using the contextual information as a language understanding component in a dialog system. Although syntactic parsing and semantic analysis are often conducted independently of each other, correct parsing of a sentence often requires the semantic information on the input and/or the contextual information prior to the input. We therefore merge syntactic parsing with semantic analysis, which enables syntactic parsing to take advantage of the semantic content of an input and its contextual information. To use contextual information, the semantic representation of an input should have a comparable form to the semantic content of the preceding context. Accordingly, we employ a framework for semantic representations that achieves such comparison. We take dialogs of hotel search and reservation for example, and demonstrate the effectiveness of the proposed method. The experimental results confirm that the proposed system achieves high accuracy in parsing and generation of semantic representations.","[{'name': 'Yuki Ikegaya', 'id': 2656660535}, {'name': 'Yasuhiro Noguchi', 'id': 2106205453}, {'name': 'Satoru Kogure', 'id': 1235342959}, {'name': 'Tatsuhiro Konishi', 'id': 2078232270}, {'name': 'Makoto Kondo', 'id': 2110759166}, {'name': 'Hideki Aso', 'id': 2916900769}, {'name': 'Akira Takagi', 'id': 2939180700}, {'name': 'Yukihiro Ito', 'id': 2906135580}]"
2914447188,Multi-Scale Context Attention Network for Stereo Matching,2019,0,61.45289993286133,bm25,recall,"Recently, many works for stereo matching with convolutional neural networks have gained satisfactory performance. However, it is still an urgent challenge to deal with ill-posed regions and improve details in disparity maps. To address these problems, we propose a multi-scale context attention network with three main modules: atrous spatial pyramid pooling attention, richer convolutional features, and attention mechanism. First, we propose an atrous spatial pyramid pooling attention module to capture context information by the aggregating context in different scales, meanwhile take advantage of the attention mechanism to selectively emphasize informative features and suppress fewer ones. Then, the richer convolutional module is proposed to bring useful detail information for the network. Additionally, attention mechanism is used to pick out informative features for disparity refinement sub-network. Furthermore, we design a point-specific loss function strategy to perform online hard point mining, which helps the network to improve the accuracy of disparity maps. The experiments on the FlyingThings3D and KITTI 2015 benchmark demonstrate that the proposed method can achieve state-of-the-art performance.","[{'name': 'Haiwei Sang', 'org': 'College of Computer Science and Technology, GuiZhou University, Guiyang, China', 'id': 2912721892}, {'name': 'Quanhong Wang', 'org': 'School of Electronic and Computer Engineering, Shenzhen Graduate School of Peking University, Shenzhen, China', 'id': 2911925010}, {'name': 'Yong Zhao', 'org': 'College of Computer Science and Technology, GuiZhou University, Guiyang, China', 'id': 2911494692}]"
759934534,A Platform for Matching Context in Real Time,2015,0,60.477935791015625,bm25,recall,"Context-awareness is a key feature of Ambient Intelligence and future intelligent systems. In order to achieve context-aware behavior, applications must be able to detect context information, recognize situations and correctly decide on context-aware action. The representation of context information and the manner in which context is detected are central issues. Based on our previous work in which we used graphs to represent context and graph matching to detect situations, in this paper we present a platform that completely handles context matching, and does so in real time, in the background, by deferring matching to a component that acts incrementally, relying on previous matching results. The platform has been implemented and tested on an AAL-inspired scenario.","[{'name': 'Andrei Olaru', 'org': 'University Politehnica of Bucharest  \xa0', 'id': 2005140788}, {'name': 'Adina Magda Florea', 'org': 'University Politehnica of Bucharest  \xa0', 'id': 1895218794}]"
44696785,"Context as a system, product as a component, and the relationship as experience",2013,0,60.42626953125,bm25,recall,"Currently, User Experience Design (UXD) is spotlighted as one of the most topical areas in design. It is an umbrella term that explains all aspects of a useru0027s experience with a given context, including the interface, graphic design, industrial design, and interaction (Merholz P. , 2007). Particularly, the notion of UXD is rooted in human factors and ergonomics that focus on physical, cognitive and emotional interaction between human users, machines and a contextual environment. In the industrial design field, the idea of UXD is not a new but an ancient concept that has been discussed in different terms such as ergonomics, anthropometrics, and affordance, etc., and whose main focus is a positive and rich experience. The current development of SNS (Social Networking Services) and smartphone technology, however, has created possibilities for new types of user experience design. Sander (Sanders, 2002) mentions this possibility as new design space where ""designers will transform from being designers of ""stuff"" (e.g., products, communication pieces, etc.) to being the builders of scaffolds for experiencing."", and where industrial designers will now confront different challenges to discover and develop new types of products with different interface designs for novel user experience. For example, tablet computers like the Apple iPad already have changed the activity of computing from a static environment to almost everywhere. Based on the theoretical framework that ""a context as a system, a product as a component, and the relationship between them as an experience"", we propose three main research questions. These questions are 1) how a current professional UX designer in practice has redefined UX design themselves, 2) what specific actions are performed and 3) what supports they provide for their client. Through careful in-depth interviews with seven professional UX designers in experience-centric design firms, including IDEO and Adaptive Path etc., in US and Canada, we propose several critical notions and foundational references for UX designers.","[{'name': 'WonJoon Chung', 'org': 'School of Industrial Design, Carleton University, Ottawa, ON, Canada#TAB#', 'id': 2099160806}, {'name': 'Sara Fortier', 'org': 'School of Industrial Design, Carleton University, Ottawa, ON, Canada#TAB#', 'id': 2274683024}]"
2123407189,Circular context-based semantic matching to identify web service composition,2008,0,59.96194839477539,bm25,recall,"This paper provides initial analysis in identifying possible Web services composition using context-based semantic matching. Context-based semantic matching allows service composition to be expanded beyond simple term matching and reduces erroneous compositions. A common method of context extraction is used to compare two types of service description, textual and WSDL. The approach is unique since it provides the Web service designer with an explicit numeric estimation of the extent to which a composition ""makes sense."" Motivation for the work is displayed with examples from Web services in the field of business.","[{'name': 'Aviv Segev', 'org': 'National Chengchi University, Taipei City, Taiwan', 'id': 2023330778}]"
1911479129,"TRIPLE - A Query, Inference, and Transformation Language for the Semantic Web",2002,0,59.63985061645508,bm25,recall,"This paper presents TRIPLE, a layered and modular rule language for the Semantic Web [1]. TRIPLE is based on Horn logic and borrows many basic features from F-Logic [11] but is especially designed for querying and transforming RDF models [20].TRIPLE can be viewed as a successor of SiLRI (Simple Logic-based RDF Interpreter [5]). One of the most important differences to F-Logic and SiLRI is that TRIPLE does not have a fixed semantics for object-oriented features like classes and inheritance. Its layered architecture allows such features to be easily defined for different object-oriented and other data models like UML, Topic Maps, or RDF Schema [19]. Description logics extensions of RDF (Schema) like OIL [17] and DAML+OIL [3] that cannot be fully handled by Horn logic are provided as modules that interact with a description logic classifier, e.g. FaCT [9], resulting in a hybrid rule language. This paper sketches syntax and semantics of TRIPLE.","[{'name': 'Michael Sintek', 'org': 'Stanford University Database Group', 'id': 2246443285}, {'name': 'Stefan Decker', 'org': 'Stanford University Database Group', 'id': 2182667553}]"
2294230846,A Bayesian Model of the Effect of Object Context on Visual Attention,2012,0,59.635921478271484,bm25,recall,"A Bayesian Model of the Effect of Object Context on Visual Attention Ben Allison (ballison@inf.ed.ac.uk) Frank Keller (keller@inf.ed.ac.uk) Moreno I. Coco (mcoco@inf.ed.ac.uk) Institute for Language, Cognition and Computation School of Informatics, University of Edinburgh 10 Crichton Street, Edinburgh EH8 9AB, UK Abstract Research in visual cognition has demonstrated that scene un- derstanding is influenced by the contextual properties of ob- jects, and a number of computational models have been pro- posed that capture specific context effects. However, a general model that predicts the fit of an arbitrary object with the con- text established by the rest of the scene is until now lacking. In this paper, we explain the contextual fit of objects in visual scenes using Bayesian topic models, which we induce from a database of annotated images. We evaluate our models firstly on synthetic object intrusion data, and then on eye-tracking data from a spot-the-difference task and from an object naming experiment. For the synthetic data, we find that our models are able to detect object intrusions accurately. For the eye-tracking data, we show that context scores derived from our models are associated with fixation latencies on target objects. Keywords: visual attention; object context; Bayesian model- ing; eye-tracking data. Introduction Real-world objects are often related to each other and typ- ically form a coherent scene. For example, a toothbrush is likely to occur with a tube of toothpaste, a mirror, a sink; it is unlikely to occur with a sauce pan, a salt shaker, a cooker. For a given object, it is therefore possible to deter- mine whether it is in context in a scene (toothbrush in bath- room), or out of context (toothbrush in kitchen). Experimen- tal evidence shows that context information facilitates human object recognition (Bar, 2004). In visual search tasks, eye fix- ations are targeted towards contextually appropriate regions (Torralba et al., 2006), and out-of-context objects attract fixa- tions earlier than in-context objects (Underwood et al., 2008). In computer vision, being able to detect out of context ob- jects is useful for object labeling. The local detectors stan- dardly used for this task only consider the visual features of the pixels within the bounding box of the object of inter- est (Felzenszwalb et al., 2010). Local detectors are therefore prone to confusing objects that are visually similar (e.g., fork and toothbrush). This problem can be addressed by comb- ing a local detectors with a model of object context, i.e., a model that determines which objects occur together. While this approach has been shown to increase object labeling performance (Choi et al., 2010; Galleguillos et al., 2008), the context models used are simple, typically relying on co- occurrence statistics over object labels. Furthermore, the con- text models used in computer vision are not designed to cap- ture human performance (e.g., in visual search). Therefore, these models have not been evaluated on tasks such as detect- ing out-of-context objects. In this paper, we present a new model of object context based on a more complex notion of object label co-occurrence that makes use of latent (i.e., unlabeled and unobserved) scene types: the Latent Scene Type model. This model al- lows us to exploit the common structure of scenes in order to estimate reliable parameters even for infrequently occurring objects. We investigate two model variants: the first is La- tent Dirichlet Allocation (LDA, Blei et al. 2003), a standard model of word-topic co-occurrence, which we use to capture object-scene type co-occurrence. The second model variant is formulated as a Bayesian mixture of multinomials, which assumes one latent scene type per scene (rather than one per object, as in LDA). We test both model variants on the task of producing con- text judgments for objects in scenes. We first use a synthetic data set for evaluation (in this data, context objects have been artificially inserted). In the second evaluation study, we use our model to mimic the data from an eye tracking experi- ment in which human participants had to spot out-of-context objects. Finally, we demonstrate that our model can predict fixation latencies in an object naming experiment which in- cluded out-of-context objects. Related Work To our knowledge, ours is the first model to attempt to quan- tify the degree of fit between arbitrary objects in a scene, and to correlate the predictions of such a model with human be- havior in scene viewing tasks. However, a number of mod- els have been proposed to capture context effects on visual attention; a prominent example is the Contextual Guidance Model (CGM, Torralba et al. 2006), which combines bottom- up saliency with global scene information (scene gist, Oliva u0026 Torralba 2006). The model is trained on a set of images in which the target objects are labeled; from this data a prob- ability distribution of typical positions of objects is learned. This distribution is conditioned on the scene gist, essentially a coarse-grained representation of global image features. Gist is a latent variable in the model, comparable to scene type in our approach. The CGM has been evaluated on eye-tracking data from visual search experiments, and can successfully predict the scene-type-specific search behavior that partici- pants exhibit. However, the model is not specifically designed to detect out-of-context objects, and has not been evaluated on tasks that require an estimate of the contextual fit of an object.","[{'name': 'Ben Allison', 'org': 'University of Edinburgh,', 'id': 2113757755}, {'name': 'Frank Keller', 'org': 'School of Informatics', 'id': 2102014928}, {'name': 'Moreno I. Coco', 'org': 'School of Philosophy, Psychology and Language Sciences', 'id': 2082706272}]"
2971639707,Dynamic Context Correspondence Network for Semantic Alignment,2019,0,59.614322662353516,bm25,recall,"Establishing semantic correspondence is a core problem in computer vision and remains challenging due to large intra-class variations and lack of annotated data. In this paper, we aim to incorporate global semantic context in a flexible manner to overcome the limitations of prior work that relies on local semantic representations. To this end, we first propose a context-aware semantic representation that incorporates spatial layout for robust matching against local ambiguities. We then develop a novel dynamic fusion strategy based on attention mechanism to weave the advantages of both local and context features by integrating semantic cues from multiple scales. We instantiate our strategy by designing an end-to-end learnable deep network, named as Dynamic Context Correspondence Network (DCCNet). To train the network, we adopt a multi-auxiliary task loss to improve the efficiency of our weakly-supervised learning procedure. Our approach achieves superior or competitive performance over previous methods on several challenging datasets, including PF-Pascal, PF-Willow, and TSS, demonstrating its effectiveness and generality.","[{'name': 'Shuaiyi Huang', 'id': 2972143333}, {'name': 'Qiuyue Wang', 'id': 2971574722}, {'name': 'Songyang Zhang', 'id': 2740040960}, {'name': 'Shipeng Yan', 'id': 2904082395}, {'name': 'Xuming He', 'org': 'Shanghaitech University', 'id': 2235845892}]"
2794680376,An Introduction to Triple Graph Grammars as an Implementation of the Delta-Lens Framework,2018,0,59.11336135864258,bm25,recall,"Triple Graph Grammars (TGGs) provide a rule-based means of specifying a consistency relation over two graph languages, with correspondences between elements in the two different languages represented explicitly as a third “traceability” graph. Many useful tools can be derived automatically from a TGG including incrementally working synchronisers, which are able to realise forward and backward change propagation without incurring unnecessary information loss. TGGs are typically introduced based on the algebraic graph transformation framework, which is not particularly accessible to many members of the bidirectional transformation (bx) community, who are often more familiar with some variant of the lens framework as a theoretical foundation for bx.","[{'name': 'Anthony Anjorin', 'org': 'University of Paderborn#TAB#', 'id': 1842396648}]"
40880267,Focusing attention for observational learning: the importance of context,1989,0,59.07716751098633,bm25,recall,"A significant component of human observational learning is the ability to focus attention toward important or relevant input features. Amechanism with this capability can serve as an inductive bias to facilitate learning in both humans and machines. Past attempts to model attentional focus for human learning have postulated a single salience value for each feature, such that features with greater salience command more attention. These models, however, assume that the featureu0027s salience is not dependent on context, whereas studies of human attention show sensitivity to context. This paper presents a mechanism for contextually focused attention in observational learning.","[{'name': 'Joel Martin', 'org': 'Georgia Inst of Tech, Atlanta, GA', 'id': 2415739347}]"
2126546372,The Context Driven Component Supporting the Context Adaptation and the Content Extension,2006,0,58.83073425292969,bm25,recall,"The context aware applications should focus on the Context adaptation, where the context change is reflected in the application, and the Content extension, where a new content of context is added without rebuilding the whole application. This paper defines Context Driven Component, which implements behaviors required by a context. An application is developed through composing the context driven components. It supports the context adaptation through replacing components or the content extension through adding components implementing behaviors relevant to the extended contents. The development using the context driven components will be analyzed in the following respects; the scale of context, the vertical decomposition compared to the existing way, and the implementation in Ubicomp.","[{'name': 'Hoijin Yoon', 'id': 2170958576}, {'name': 'Byoungju Choi', 'org': 'Ewha Womans University', 'id': 2128219450}]"
1497325947,Integrating emotions in the TRIPLE ECA model,2009,0,58.799129486083984,bm25,recall,"This paper presents the introduction of emotion-based mechanisms in the TRIPLE ECA model. TRIPLE is a hybrid cognitive model consisting of three interacting modules – the reasoning, the connectionist, and the emotion engines – running in parallel. The interplay between these three modules is discussed in the paper with a focus on the role and implementation of the emotion engine which is based on the FAtiMA agent architecture. The influence of emotions in TRIPLE is related to the volume of the working memory, the speed of the inference mechanisms, the interaction between the reasoning and the connectionist engine, and the connectionist engine itself. Emotions will increase the most important cognitive aspects of the model like context sensitivity, rich experiential episodic knowledge and anticipatory mechanisms.","[{'name': 'Kiril Kiryazov', 'org': 'Central and Eastern European Center for Cognitive Science, New Bulgarian University, Sofia, Bulgaria', 'id': 1925204402}, {'name': 'Maurice Grinberg', 'org': 'Central and Eastern European Center for Cognitive Science, New Bulgarian University, Sofia, Bulgaria', 'id': 2102721305}]"
2169376108,Consumer acceptance of service bundles: An empirical investigation in the context of broadband triple play,2012,0,58.78289794921875,bm25,recall,"Although offering bundled services promises firms potential synergies in supply and increased revenues, the realized benefits of such a strategy are highly contingent on consumer acceptance of the bundles. Borrowing from TAM, Information Integration Theory, and the customer value concept, we developed a comprehensive model for consumer acceptance of service bundles, which is divided into four general construct types: service characteristics, usefulness/ease of use, attitude, and behavioral intention. Twelve hypotheses were derived and empirically tested in the context of broadband triple play, the bundled offering of broadband Internet access, Internet telephony, and Internet TV. Based on questionnaire responses from 214 study participants and using PLS for analysis, we found overall support for our research model. We concluded by discussing the academic and managerial value of our research, both in terms of advanced knowledge of service bundle acceptance and the adoption of triple play.","[{'name': 'Oliver Schilke', 'org': 'University of California, Los Angeles, USA', 'id': 2339538494}, {'name': 'Bernd W. Wirtz', 'org': 'German University of Administrative Sciences , Speyer, Germany', 'id': 1013916586}]"
2793302268,EdgeStereo: A Context Integrated Residual Pyramid Network for Stereo Matching.,2018,0,58.66743087768555,bm25,recall,"Recently convolutional neural network (CNN) promotes the development of stereo matching greatly. Especially those end-to-end stereo methods achieve best performance. However less attention is paid on encoding context information, simplifying two-stage disparity learning pipeline and improving details in disparity maps. Differently we focus on these problems. Firstly, we propose an one-stage context pyramid based residual pyramid network (CP-RPN) for disparity estimation, in which a context pyramid is embedded to encode multi-scale context clues explicitly. Next, we design a CNN based multi-task learning network called EdgeStereo to recover missing details in disparity maps, utilizing mid-level features from edge detection task. In EdgeStereo, CP-RPN is integrated with a proposed edge detector HED$_\beta$ based on two-fold multi-task interactions. The end-to-end EdgeStereo outputs the edge map and disparity map directly from a stereo pair without any post-processing or regularization. We discover that edge detection task and stereo matching task can help each other in our EdgeStereo framework. Comprehensive experiments on stereo benchmarks such as Scene Flow and KITTI 2015 show that our method achieves state-of-the-art performance.","[{'name': 'Xiao Song', 'id': 2793010977}, {'name': 'Xu Zhao', 'id': 2527288379}, {'name': 'Hanwen Hu', 'id': 2791632150}, {'name': 'Liangji Fang', 'id': 2918908022}]"
2137185953,Retrieved context and the discovery of semantic structure,2007,0,58.66473388671875,bm25,recall,"Semantic memory refers to our knowledge of facts and relationships between concepts. A successful semantic memory depends on inferring relationships between items that are not explicitly taught. Recent mathematical modeling of episodic memory argues that episodic recall relies on retrieval of a gradually-changing representation of temporal context. We show that retrieved context enables the development of a global memory space that reflects relationships between all items that have been previously learned. When newly-learned information is integrated into this structure, it is placed in some relationship to all other items, even if that relationship has not been explicitly learned. We demonstrate this effect for global semantic structures shaped topologically as a ring, and as a two-dimensional sheet. We also examined the utility of this learning algorithm for learning a more realistic semantic space by training it on a large pool of synonym pairs. Retrieved context enabled the model to ""infer"" relationships between synonym pairs that had not yet been presented.","[{'name': 'Vinayak Rao', 'org': 'Syracuse University, Department of Psychology, Syracuse, NY and Gatsby Computational Neuroscience Unit, University College London#TAB#', 'id': 2110299510}, {'name': 'Marc Howard', 'org': 'Syracuse University Department of Psychology Syracuse NY', 'id': 2120301528}]"
2397686012,The Correct Expressions of Reverse Triple I Methods for Fuzzy Reasoning,2009,0,58.26865005493164,bm25,recall,"Correct expressions of the reverse and α-reverse triple I methods for fuzzy reasoning are established in new manners. Aiming at the existing different formulas of the reverse and α-reverse triple I methods based on Łukasiewicz implication I L , we discuss their relations and correct some of them. Further, the α-reverse triple I method is extended to a new form, called α(u,v)-reverse triple I method, which can contain the reverse triple I method as its particular case. This is another improved point to the existing formulas.","[{'name': 'Hua-wen Liu', 'org': 'SHANDONG UNIVERSITY', 'id': 2807674279}]"
2049837673,Round addition DFA for microcontroller implemented the triple DES,2013,0,57.94575119018555,bm25,recall,"This article presents a method of round addition attack on triple DES block ciphers using differential fault analysis(DFA). For single DES, the secret key can be easily extracted using one correct ciphertext and two faulty ciphertexts. Even for triple DES, it is shown that the secret key can also extracted, similarly to single DES.","[{'name': 'Hideki Yoshikawa', 'org': 'Fac. of Eng., Tohoku Gakuin Univ., Tagajo, Japan', 'id': 2152165368}, {'name': 'Masahiro Kaminaga', 'org': 'Fac. of Eng., Tohoku Gakuin Univ., Tagajo, Japan', 'id': 1818698955}, {'name': 'Arimitsu Shikoda', 'org': 'Fac. of Eng., Tohoku Gakuin Univ., Tagajo, Japan', 'id': 1269865608}, {'name': 'Toshinori Suzuki', 'org': 'Fac. of Eng., Tohoku Gakuin Univ., Tagajo, Japan', 'id': 2935751900}]"
2778998603,Integrating Knowledge from Latent and Explicit Features for Triple Scoring - Team Radicchio's Triple Scorer at WSDM Cup 2017.,2017,0,57.43689727783203,bm25,recall,"The objective of the triple scoring task in WSDM Cup 2017 is to compute relevance scores for knowledge-base triples of type-like relations. For example, consider Julius Caesar who has had various professions, including Politician and Author. For two given triples (Julius Caesar, profession, Politician) and (Julius Caesar, profession, Author), the former triple is likely to have a higher relevance score (also called ""triple score"") because Julius Caesar was well-known as a politician and not as an author. Accurate prediction of such triple scores greatly benefits real-world applications, such as information retrieval or knowledge base query. In these scenarios, being able to rank all relations (Profession/Nationality) can help improve the user experience. We propose a triple scoring model which integrates knowledge from both latent features and explicit features via an ensemble approach. The latent features consist of representations for a person learned by using a word2vec model and representations for profession/nationality values extracted from a pre-trained GloVe embedding model. In addition, we extract explicit features for person entities from the Freebase knowledge base. Experimental results show that the proposed method performs competitively at WSDM Cup 2017, ranking at the third place with an accuracy of 79.72% for predicting within two places of the ground truth score.","[{'name': 'Liang-Wei Chen', 'id': 2777307779}, {'name': 'Bhargav Mangipudi', 'id': 2224645229}, {'name': 'Jayachandu Bandlamudi', 'id': 2776968805}, {'name': 'Richa Sehgal', 'id': 2780964707}, {'name': 'Yun Hao', 'id': 2778124030}, {'name': 'Meng Jiang', 'id': 2115305989}, {'name': 'Huan Gui', 'org': 'University of Illinois at Urbana Champaign;', 'id': 2096153351}]"
2064550979,The Cycle Switching Graph of the Steiner Triple Systems of Order 19 is Connected,2011,0,55.10845947265625,bm25,recall,Switching is a local transformation that when applied to a combinatorial object gives another object with the same parameters. It is here shown that the cycle switching graph of the 11 084 874 829 isomorphism classes of Steiner triple systems of order 19 as well as the cycle switching graph of the 1 348 410 350 618 155 344 199 680 000 labeled such designs are connected. In addition to giving an understanding of the multitude of Steiner triple systems—at least for order 19 but perhaps also generally—this work also presents an algorithm for testing connectedness of large implicit graphs and brings forward a benchmark instance for such algorithms.,"[{'name': 'Petteri Kaski', 'org': 'University of Helsinki, Department of Computer Science, Helsinki Institute for Information Technology (HIIT), P. O. Box 68, 00014, Helsinki, Finland#TAB#', 'id': 2115817740}, {'name': 'Veli Mäkinen', 'org': 'University of Helsinki, Department of Computer Science, Helsinki Institute for Information Technology (HIIT), P. O. Box 68, 00014, Helsinki, Finland#TAB#', 'id': 2026327678}, {'name': 'Patric R. J. Östergård', 'org': 'Aalto University, Department of Communications and Networking, P. O. Box 13000, 00076, Aalto, Finland#TAB#', 'id': 273669035}]"
2033310787,Using TRIPLE for business agents on the Semantic Web,2003,0,55.06809997558594,bm25,recall,"Abstract   This paper presents TRIPLE [Sintek and Decker, First International Semantic Web Conference, 2002], a modular rule language for the Semantic Web [Weaving the Web, The Original Design and Ultimate Destiny of the World Wide Web by Its Inventor, 1999], and its usage for business agents. TRIPLE is based on Horn logic [Foundations of Logic Programming, 1984] and borrows many basic features from F-Logic [J. ACM 42 (1995) 741] but is especially designed for querying and transforming RDF models [ http://www.w3.org/RDF/ ]. TRIPLE can be viewed as a successor of SiLRI (Simple Logic-based RDF Interpreter [QL’98—The Query Languages Workshop, 1998]). One of the most important differences to F-Logic and SiLRI is that TRIPLE does not have fixed semantics for object-oriented features like classes and inheritance. Its modular architecture allows such features to be easily defined for different object-oriented and other data models like UML, Topic Maps, or RDF Schema [ http://www.w3.org/TR/2000/CR-rdf-schema-20000327/ ]. Description logics extensions of RDF (Schema) like OIL [ http://www.ontoknowledge.org/oil/ ] and DAML+OIL [ http://www.daml.org/2001/03/daml+oil-index.html ] that cannot be fully handled by Horn logic are provided as modules that interact with a description logic classifier, e.g. FaCT [ http://www.cs.man.ac.uk/~horrocks/FaCT/ ], resulting in a hybrid rule language. This paper sketches syntax and semantics of TRIPLE and shows how it can be used to declaratively specify the behavior of (business) agents.","[{'name': 'Michael Sintek', 'org': 'DFKI GmbH, Kaiserslautern, Germany', 'id': 2246443285}, {'name': 'Stefan Decker', 'org': 'Information Sciences Institute (ISI), Los Angeles, USA', 'id': 2182667553}]"
2963906588,The matroid structure of representative triple sets and triple-closure computation,2018,0,54.775230407714844,bm25,recall,"Abstract   The closure    cl   (  R  )     of a consistent set    R    of triples (rooted binary trees on three leaves) provides essential information about tree-like relations that are shown by any supertree that displays all triples in    R   . In this contribution, we are concerned with representative triple sets, that is, subsets      R    ′      of    R    with    cl   (    R    ′    )   =  cl   (  R  )    . In this case,      R    ′      still contains all information on the tree structure implied by    R   , although      R    ′      might be significantly smaller. We show that representative triple sets that are minimal w.r.t. inclusion form the basis of a matroid. This in turn implies that minimal representative triple sets also have minimum cardinality. In particular, the matroid structure can be used to show that minimum representative triple sets can be computed in polynomial time with a simple greedy approach. For a given triple set    R    that “identifies” a tree, we provide an exact value for the cardinality of its minimum representative triple sets. In addition, we utilize the latter results to provide a novel and efficient method to compute the closure    cl   (  R  )     of a consistent triple set    R    that improves the time complexity    O   (   |  R  |      |    L    R    |     4    )     of the currently fastest known method proposed by Bryant and Steel (1995). In particular, if a minimum representative triple set for    R    is given, it can be shown that the time complexity to compute    cl   (  R  )     can be improved by a factor up to     |  R  |    |    L    R    |    . As it turns out, collections of quartets (unrooted binary trees on four leaves) do not provide a matroid structure, in general.","[{'name': 'Carsten R. Seemann', 'org': 'Department of Mathematics and Computer Science, University of Greifswald, Walther-Rathenau-Straße 47, 17487 Greifswald, Germany', 'id': 2793781852}, {'name': 'Marc Hellmuth', 'org': 'Department of Mathematics and Computer Science, University of Greifswald, Walther-Rathenau-Straße 47, 17487 Greifswald, Germany', 'id': 2093537256}]"
2726984384,The Matroid Structure of Representative Triple Sets and Triple-Closure Computation,2017,0,54.431461334228516,bm25,recall,"The closure $\textrm{cl}(R)$ of a consistent set $R$ of triples (rooted binary trees on three leaves) provides essential information about tree-like relations that are shown by any supertree that displays all triples in $R$. In this contribution, we are concerned with representative triple sets, that is, subsets $Ru0027$ of $R$ with $\textrm{cl}(Ru0027) = \textrm{cl}(R)$. In this case, $Ru0027$ still contains all information on the tree structure implied by $R$, although $Ru0027$ might be significantly smaller. We show that representative triple sets that are minimal w.r.t.\ inclusion form the basis of a matroid. This in turn implies that minimal representative triple sets also have minimum cardinality. In particular, the matroid structure can be used to show that minimum representative triple sets can be computed in polynomial time with a simple greedy approach. For a given triple set $R$ that ""identifies"" a tree, we provide an exact value for the cardinality of its minimum representative triple sets. In addition, we utilize the latter results to provide a novel and efficient method to compute the closure $\textrm{cl}(R)$ of a consistent triple set $R$ that improves the time complexity $\mathcal{O}(|R||L_R|^4)$ of the currently fastest known method proposed by Bryant and Steel (1995). In particular, if a minimum representative triple set for $R$ is given, it can be shown that the time complexity to compute $\textrm{cl}(R)$ can be improved by a factor up to $|R||L_R|$. As it turns out, collections of quartets (unrooted binary trees on four leaves) do not provide a matroid structure, in general.","[{'name': 'Marc Hellmuth', 'id': 2093537256}, {'name': 'Carsten R. Seemann', 'id': 2793781852}]"
59436587,Differences + triple spaces = active triple spaces,2007,0,53.83768844604492,bm25,recall,"As the Semantic Web (SW) is being automatically populated with large number of RDF triples scalability issues related to wide scale reasoning occur. We believe these difficulties are due to the use of global reasoning engines, which carry all the load of collecting and handling all relevant triples, and they can be alleviated by distributing the load of the reasoning amongst the meaningful entities represented by the triples themselves. Therefore, as an application of a knowledge representation model based on Differences and on top of the triple space computing model, we introduce Active Triple Spaces, triple spaces managing triples acting as differences, i.e. processes subscribing to active queries and presenting their result as a new triple. Active triples allow the caching of the result of each new query, as well as its rapid update by subscription mechanisms.","[{'name': 'Vlad Tanasescu', 'org': 'Knowledge Media Inst., Open Univ., Milton Keynes, UK', 'id': 1205235974}]"
1574893070,The intersection spectrum of Skolem sequences and its applications to λ-fold cyclic triple systems,2012,0,53.31995391845703,bm25,recall,"Abstract   A Skolem sequence of order    n    is a sequence      S    n    =   (    s    1    ,    s    2    ,  …  ,    s    2  n    )     of    2  n    integers containing each of the integers    1  ,  2  ,  …  ,  n    exactly twice, such that two occurrences of the integer    j  ∈   {  1  ,  2  ,  …  ,  n  }     are separated by exactly    j  −  1    integers. We prove that the necessary conditions are sufficient for existence of two Skolem sequences of order    n    with    0  ,  1  ,  2  ,  …  ,  n  −  3    and    n    pairs in the same positions. Further, we apply this result to the fine structure of cyclic two-, three-, and four-fold triple systems, and also to the fine structure of    λ   -fold directed triple systems and    λ   -fold Mendelsohn triple systems.","[{'name': 'Nabil Shalaby', 'org': 'Department of Mathematics and Statistics, Memorial University of Newfoundland, St. John’s, Newfoundland, Canada A1C 5S7', 'id': 2070248959}, {'name': 'Daniela Silvesan', 'org': 'Department of Mathematics and Statistics, Memorial University of Newfoundland, St. John’s, Newfoundland, Canada A1C 5S7', 'id': 2517855328}]"
2132290458,The triangle chromatic index of Steiner triple systems,2001,0,53.04615020751953,bm25,recall,"In a Steiner triple system of order v, STS(v), a set of three lines inter­ secting pairwise in three distinct points is called a triangle. A set of lines containing no triangle is called triangle-free. The minimum number of triangle-free sets required to partition the lines of a Steiner triple system S, is called the triangle chromatic index of S. We prove that for all ad­ missible v, there exists an STS(v) with triangle chromatic index at most 8V3v. In addition, by showing that the projective geometry PG( n, 3) may be partitioned into O( 6 n / 5 ) caps, we prove that the STS( v) formed from the points and lines of the affine geometry AG(n, 3) has triangle chromatic index at most Av s , where s = loge 6/(3 loge 5) ~ 0.326186, and A is a constant. We also determine the values of the index for STS( v) with v ::; 13.","[{'name': 'Mike J. Grannell', 'org': 'Open University)', 'id': 2036224287}, {'name': 'Terry S. Griggs', 'id': 1997275168}, {'name': 'Ray Hill', 'id': 2103963589}]"
2135748114,Triple jump acceleration for the EM algorithm,2005,0,52.88608169555664,bm25,recall,"This paper presents the triple jump framework for accelerating the EM algorithm and other bound optimization methods. The idea is to extrapolate the third search point based on the previous two search points found by regular EM. As the convergence rate of regular EM becomes slower, the distance of the triple jump is longer, and thus provide higher speedup for data sets where EM converges slowly. Experimental results show that the triple jump framework significantly outperforms EM and other acceleration methods of EM for a variety of probabilistic models, especially when the data set is sparse. The results also show that the triple jump framework is particularly effective for cluster models.","[{'name': 'Han-Shen Huang', 'org': 'Inst. of Inf. Sci., Acad. Sinica, Taipei, Taiwan', 'id': 2615569815}, {'name': 'Bou-Ho Yang', 'org': 'Inst. of Inf. Sci., Acad. Sinica, Taipei, Taiwan', 'id': 2222052760}, {'name': 'Chun-Nan Hsu', 'org': 'Inst. of Inf. Sci., Acad. Sinica, Taipei, Taiwan', 'id': 2171329927}]"
2061267683,"Narrating the Triple Helix concept in ""weak"" regions: lessons from Sweden",2004,0,52.48982238769531,bm25,recall,"This paper critically examines the positive narrative surrounding the Triple Helix concept as a model for development in all kinds of regions. We claim that existing and problematic structural preconditions should be taken into consideration when applying the Triple Helix concept in weak regions. Empirically, we base our paper on two longitudinal case studies in Sweden, where government are trying to break the negative trends in weak regions by initiating Triple Helix-like programs. However, due to poor preconditions, such initiatives tend to fail. Thus, a negative narrative can be related about Triple Helix cooperation when applied in weak regions.","[{'name': 'Christian Jensen', 'org': 'University of Gothenburg', 'id': 2294662629}, {'name': 'Bjorn Tragardh', 'org': 'University of Gothenburg', 'id': 2142375672}]"
2077524756,The evolution of South Korea's innovation system: moving towards the triple helix model?,2015,0,52.477333068847656,bm25,recall,"The South Koreau0027s innovation system has been transformed in tandem with rapid economic growth over the last three decades. In order to explore the evolution process of the innovation system in Korea, this study examines the trends and patterns in collaboration activities among the triple helix actors, such as university, industry, and government (UIG), using co-patent data. The triple helix framework is employed to analyze innovation dynamics within the networks of the bi- and trilateral relations embedded in patent collaborations. The analyses focus on how the triple helix dynamics have been shaped and transformed in the course of development of the innovation system. The results reveal that collaboration activities among UIG largely increased across three developmental phases from 1980 to 2012. In the early periods, strategic Ru0026D alliances between industry and government sector were set up to strengthen enterprisesu0027 innovation capabilities. When the Korean large conglomerates, Chaebols, became a dominant driver of domestic innovation activities, the primary agents of the collaborations shifted from industry-government to industry-university. The network analysis shows that university-industry collaboration is the strongest within the triple helix in recent years, followed by industry-government relations and then UIG relations. The tripartite collaboration has emerged with the rise of entrepreneur universities, but its network has rather been weak and inactive. While Korea has experienced a transition from statist model to a triple helix, the full-fledged triple helix model has not been established yet.","[{'name': 'Jungwon Yoon', 'org': 'Graduate School of Technology Management, Sogang University, Seoul, South Korea', 'id': 2294057589}]"
1970982189,A direct method to construct triple systems,1974,0,52.105010986328125,bm25,recall,"Abstract   A triple system is a balanced incomplete block design D(v, k, λ, b, r) with k = 3. Although it has been shown that triple systems exist for all values of the parameters satisfying the necessary conditions:      λ(ν − 1) ≡ 0 (  mod 2  ), λν(ν − 1) ≡ 0 (  mod 6  ),      direct methods (nonrecursive) of construction are not available in general. In this paper we give a direct method to construct a triple system for all values of the parameters satisfying the necessary conditions.","[{'name': 'Frank K. Hwang', 'org': 'Bell Telephone Laboratories, Incorporated, Murray Hill, New Jersey 07974 USA', 'id': 2274428464}, {'name': 'Shen Lin', 'org': 'Bell Telephone Laboratories, Incorporated, Murray Hill, New Jersey 07974 USA', 'id': 2662109248}]"
997568610,Extending Model to Model Transformation Results from Triple Graph Grammars to Multiple Models,2015,0,52.041770935058594,bm25,recall,"Triple graph grammars are a formally well-founded and widely used technique for model transformation. Due to their formal foundation several transformation approaches and analysis methods exists. However, triple graphs are restricted to represent two models at a time. In this paper we describe how the formalism of triple graphs can be generalised to enable a representation of multiple models and relations. We show that basic results from triple graph grammars can also be extended. The results in this paper provide a foundation for the generalisation of other results in model transformation, integration and synchronisation to multiple models.","[{'name': 'Frank Trollmann', 'org': 'Faculty of Electrical Engineering and Computer Science, DAI-Labor, TU-Berlin, Berlin, Germany', 'id': 1904263758}, {'name': 'Sahin Albayrak', 'org': 'Faculty of Electrical Engineering and Computer Science, DAI-Labor, TU-Berlin, Berlin, Germany', 'id': 1919884716}]"
2759045830,Connecting Semantic Mediawiki to different Triple Stores Using RDF2Go.,2010,0,51.95861053466797,bm25,recall,"This article describes a generic triple store connector for the popular Semantic MediaWiki software to be used with different triple stores like Jena or Sesame. Using RDF2Go as an abstraction layer it is possible to easily exchange triple stores. This ongoing work is part of the opendrugwiki project, a semantic wiki for distributed pharmaceutical research groups.","[{'name': 'Manfred Schied', 'id': 2757311243}, {'name': 'Anton Köstlbacher', 'id': 2760618336}, {'name': 'Christian Wolff', 'id': 2126127755}]"
2034185615,On the existence of hyper-L triple-loop networks,2006,0,51.9244270324707,bm25,recall,"Aguilo-Gost [New dense families of triple loop Networks, Discrete Math. 197/198 (1999) 15-27] has presented a new type of hyper-L tiles and used it to derive a new dense family of triple-loop networks. While Aguilo-Gostu0027s hyper-L tile seems to be a promising tool for studying the triple-loop networks, we need to verify that the hyper-L tile producing good result is indeed the MDD of some triple-loop network. In this paper, we give necessary and sufficient conditions for the existence of Aguilo-Gostu0027s hyper-L triple-loop networks and we correct some flaws in [F. Aguilo-Gost, New dense families of triple loop networks, Discrete Math. 197/198 (1999) 15-27].","[{'name': 'Chiuyuan Chen', 'org': 'Department of Applied Mathematics, National Chiao Tung University, Hsinchu 300, Taiwan#TAB#', 'id': 2122726335}, {'name': 'Chih-Shin Hung', 'org': 'Department of Applied Mathematics, National Chiao Tung University, Hsinchu 300, Taiwan#TAB#', 'id': 2933573605}, {'name': 'Wen-Shiang Tang', 'org': 'Department of Applied Mathematics, National Chiao Tung University, Hsinchu 300, Taiwan#TAB#', 'id': 2640062645}]"
2748988962,The triple-pair construction for weighted w-pushdown automata,2017,0,51.86458969116211,bm25,recall,"Let S be a complete star-omega semiring and Sigma be an alphabet. For a weighted omega-pushdown automaton P with stateset 1...n, n greater or equal to 1, we show that there exists a mixed algebraic system over a complete semiring-semimodule pair ((S u003e)^nxn, (S u003e)^n) such that the behavior ||P|| of P is a component of a solution of this system. In case the basic semiring is the Boolean semiring or the semiring of natural numbers (augmented with infinity), we show that there exists a mixed context-free grammar that generates ||P||. The construction of the mixed context-free grammar from P is a generalization of the well known triple construction and is called now triple-pair construction for omega-pushdown automata.","[{'name': 'Manfred Droste', 'org': 'University of Leipzig >  >  >  >', 'id': 2129076433}, {'name': 'Zoltán Ésik', 'org': 'Univ. of Szeged', 'id': 2021889967}, {'name': 'Werner Kuich', 'org': 'Vienna University of Technology.', 'id': 2043849746}]"
2808811079,Stochastic Parametrization of the Richardson Triple,2019,0,51.72296905517578,bm25,recall,"A Richardson triple is an ideal fluid flow map \(g_{t/{\epsilon },t,{\epsilon }t} = h_{t/{\epsilon }}k_t l_{{\epsilon }t}\) composed of three smooth maps with separated time scales: slow, intermediate and fast, corresponding to the big, little and lesser whorls in Richardson’s well-known metaphor for turbulence. Under homogenization, as \(\lim {\epsilon }\rightarrow 0\), the composition \(h_{t/{\epsilon }}k_t \) of the fast flow and the intermediate flow is known to be describable as a single stochastic flow \({\mathsf d}_tg\). The interaction of the homogenized stochastic flow \({\mathsf d}_tg\) with the slow flow of the big whorl is obtained by going into its non-inertial moving reference frame, via the composition of maps \(({\mathsf d}_tg)l_{{\epsilon }t}\). This procedure parameterizes the interactions of the three flow components of the Richardson triple as a single stochastic fluid flow in a moving reference frame. The Kelvin circulation theorem for the stochastic dynamics of the Richardson triple reveals the interactions among its three components. Namely, (1) the velocity in the circulation integrand is kinematically swept by the large scales and (2) the velocity of the material circulation loop acquires additional stochastic Lie transport by the small scales. The stochastic dynamics of the composite homogenized flow is derived from a stochastic Hamilton’s principle and then recast into Lie–Poisson bracket form with a stochastic Hamiltonian. Several examples are given, including fluid flow with stochastically advected quantities and rigid body motion under gravity, i.e. the stochastic heavy top in a rotating frame.","[{'name': 'Darryl D. Holm', 'org': 'Mathematics Department, Imperial College, London, UK', 'id': 2141022835}]"
2070388595,THE TRIPLE POINT PARADOX FOR THE NONLINEAR WAVE SYSTEM,2007,0,51.70283889770508,bm25,recall,"We present numerical solutions of a two-dimensional Riemann problem for the non- linear wave system which is used to describe the Mach reflection of weak shock waves. Robust low order as well as high resolution finite volume schemes are employed to solve this equation formulated in self-similar variables. These, together with extreme local grid refinement, are used to resolve the solution in the neighborhood of an apparent but mathematically inadmissible shock triple point. Rather than observing three shocks meeting in a single standard triple point, we are able to detect a primary triple point containing an additional wave, a centered expansion fan, together with a se- quence of secondary triple points and tiny supersonic patches embedded within the subsonic region directly behind the Mach stem. An expansion fan originates at each triple point. It is our opinion that the structure observed here resolves the von Neumann triple point paradox for the nonlinear wave system. These solutions closely resemble the solutions obtained in (A. M. Tesdall and J. K. Hunter, SIAM J. Appl. Math., 63 (2002), pp. 42-61) for the unsteady transonic small disturbance equation.","[{'name': 'Allen M. Tesdall', 'org': 'University of Toronto,#TAB#', 'id': 585296031}, {'name': 'Richard Sanders', 'id': 2597906802}, {'name': 'Barbara L. Keyfitz', 'id': 655967850}]"
1979915563,Triple helix and regional development: a perspective from Oxfordshire in the UK,2010,0,51.454105377197266,bm25,recall,"This paper illustrates that distinctive patterns of regional development can be understood as resulting from the relative dominance of the three components in the triple helix model at any one time. This approach can be used to understand why high growth sectors, such as biotechnology, are concentrated at particular locations. Using the example of the biotechnology sector in Oxfordshire (UK), we examine how differences in formal (e.g. institutional arrangements) and informal networks are influenced by broader geographical, political, economic and social environments. These differences produce distinctive regional forms of the triple helix model. Oxfordshire is a national centre of the sector, having the key ingredients of a concentration of universities and government laboratories, heavily supported by government, and a growing number of biotech firms. The distinctive features of the Oxfordshire variant are that the role of Oxford University, a world centre for biomedical research, is secondary at the reg...","[{'name': 'Helen Lawton Smith', 'org': 'School of Management and Organizational Psychology, Birkbect , University of London , UK', 'id': 2286835470}, {'name': 'Sharmistha Bagchi-Sen', 'org': 'Department of Geography, State University of New York at Buffalo, USA', 'id': 250076939}]"
2275760912,On the Security of 2-Key Triple DES,2016,0,51.34467315673828,bm25,recall,"This paper reconsiders the security offered by two-key triple DES, an encryption technique that remains widely used despite recently being de-standardised by NIST. A generalization of the 1990 van Oorschot–Wiener attack is described, constituting the first advance in cryptanalysis of two-key triple DES since 1990. We give further attack enhancements that together imply that the widely used estimate that two-key triple DES provides 80 bits of security can no longer be regarded as conservative; the widely stated assertion that the scheme is secure as long as the key is changed regularly is also challenged. The main conclusion is that, whilst not completely broken, the margin of safety for two-key triple DES is slim, and efforts to replace it, at least with its three-key variant, and preferably with a more modern cipher such as AES, should be pursued with some urgency.","[{'name': 'Chris J. Mitchell', 'org': 'Information Security Group, Royal Holloway, University of London, Egham, U.K', 'id': 2132562382}]"
2080944261,The market triple,2014,0,51.24224853515625,bm25,recall,"It is a well known fact that at market equilibrium supply equals demand except for instance in North Korea and Europe during the Second World War. The above should be examined from a contemporary perspective (here and now) as well as all the accepted relevant terms, criteria and parameters. Basic terms such as value and market are redefined from this perspective and the organizer element is added. Thus a linear creation of demand and supply is expanded into a two-dimensional structure which provides the definition of a market triple. There are countless markets in the world around us, but only six market triples. Quite unique among the markets is the research market, our proposition for future developments. Copyright The Author(s) 2014","[{'name': 'Stanisław Walukiewicz', 'org': 'Polish Academy of Sciences', 'id': 2561590069}]"
2036348354,SELF-SIMILAR SOLUTIONS FOR THE TRIPLE POINT PARADOX IN GASDYNAMICS ∗,2008,0,51.20685577392578,bm25,recall,"We present numerical solutions of a two-dimensional Riemann problem for the com- pressible Euler equations that describes the Mach reflection of weak shock waves. High resolution finite volume schemes are used to solve the equations formulated in self-similar variables. We use extreme local grid refinement to resolve the solution in the neighborhood of an apparent but math- ematically inadmissible shock triple point. The solutions contain a complex structure: instead of three shocks meeting in a single standard triple point, there is a sequence of triple points and tiny supersonic patches behind the leading triple point, formed by the reflection of weak shocks and ex- pansion waves between the sonic line and the Mach shock. An expansion fan originates at each triple point, resolving the von Neumann triple point paradox.","[{'name': 'Allen M. Tesdall', 'id': 585296031}, {'name': 'Richard Sanders', 'id': 2597906802}, {'name': 'Barbara L. Keyfitz', 'id': 655967850}]"
2006725625,The number of common flowers of two STS(v)s and embeddable Steiner triple trades,2013,0,51.136383056640625,bm25,recall,"Abstract   A flower,      F    S     (  x  )    , around a point    x    in a Steiner triple system    D  =   (  V  ,  B  )     is the set of all triples in    B    which contain the point    x   , namely      F    D     (  x  )   =   {  b  ∈  B  ∣  x  ∈  b  }    . This paper determines the possible number of common flowers that two Steiner triple systems can have in common. For all admissible pairs     (  k  ,  v  )     where    k  ≤  v  −  6    we construct a pair of Steiner triple systems of order    v    where the flowers around    k    elements of    V    are identical in both Steiner triple systems, except for the pairs     (  2  ,  9  )    ,     (  3  ,  9  )     and     (  6  ,  13  )    . Equivalently this result shows that there is a Steiner triple trade of foundation    l  =  v  −  k    that can be embedded in a    S  T  S   (  v  )     for each admissible    v    and    6  ≤  l  ≤  v    except when     (  l  ,  v  )   =   (  6  ,  9  )   ,   (  7  ,  9  )     or     (  7  ,  13  )    .","[{'name': 'Emine Şule Yazıcı', 'org': 'Koç University, Rumelifeneri Yolu 34450, Sarıyer, İstanbul, Turkey', 'id': 2266042605}]"
23804303,The Boundary Layer Problem of Triple Deck Type,2000,0,50.829620361328125,bm25,recall,"We give the formulation of the Von Mises problem of the boundary layer of triple deck type. An original non-local condition appears. We prove the existence of a solution by studying a semi-discrete scheme in which we consider the pressure gradient as a parameter. We then obtain a solution in physical variables but the condition v(x, 0) = 0 is not proved. Besides, the numerical simulations give a surprising non uniqueness result with given pressure in the case of a break-away.","[{'name': 'Laurent Plantié', 'org': 'CERFACS', 'id': 2656660976}]"
1971276029,The Extended Alpha-triple I Algorithm Based on the Generalized Implication Operator,2006,0,50.711666107177734,bm25,recall,"In this paper, the classical implication operator is generalized, and then the definition of generalized implication operator on [0, 1] is proposed. Based on generalized implication operator, the extended alpha-triple I principle is presented by generalizing the alpha-triple I algorithm. By analyzing the essence of alpha-triple Fuzzy Modus Ponens (FMP) and alpha-triple Fuzzy Modus Tollens (FMT) principles, and based on the generalized implication operator, the generalized calculating formula of extended alpha-triple I algorithm is proposed. At the same time, the reversibility on the proposed alpha-triple I algorithm is discussed. It is proved that Compositional Rule of Inference (CRI) is a special case of extended alpha-triple I algorithm. Finally, two implication operations are proposed to validate the proposed generalized equation.","[{'name': 'Bingru Yang', 'org': 'School of Information Engineering, University of Science and Technology Beijing, Beijing, China#TAB#', 'id': 2670480566}, {'name': 'Zhangyan Xu', 'org': 'Aff1 Aff2#TAB#', 'id': 2693071741}, {'name': 'Wei Song', 'org': 'School of Information Engineering, University of Science and Technology Beijing, Beijing, China#TAB#', 'id': 2691755166}]"
1964390203,Mendelsohn directed triple systems,1999,0,50.7020378112793,bm25,recall,"Abstract   We introduce a class of ordered triple systems which are both Mendelsohn triple systems and directed triple systems. We call these  Mendelsohn directed triple systems  (MDTS( v , λ )), characterise them, and prove that they exist if and only if    λ(v−1)≡0    (  mod    3)   . This is the same spectrum as that of  regular  directed triple systems, of which they are a special case. We also prove that cyclic MDTS( v , λ ) exist if and only if    λ(v−1)≡0    (  mod    6)    . In so doing we simplify a known proof of the existence of cyclic directed triple systems. Finally, we enumerate some ‘small’ MDTS.","[{'name': 'Mike Grannell', 'org': 'Department of Pure Mathematics, The Open University, Walton Hall, Milton Keynes MK7 6AA, UK', 'id': 2036224287}, {'name': 'Terry S. Griggs', 'org': 'Department of Pure Mathematics, The Open University, Walton Hall, Milton Keynes MK7 6AA, UK', 'id': 1997275168}, {'name': 'Kathleen A. S. Quinn', 'org': 'Department of Pure Mathematics, The Open University, Walton Hall, Milton Keynes MK7 6AA, UK', 'id': 1988359362}]"
104920717,The Triple Schizophrenia of the Software Engineering Researcher.,2005,0,50.60606384277344,bm25,recall,"In this paper we question the problem of a software engineering researcher, who in his daily work, has to deal with researching, teaching and learning activities at the same time. Likewise, we suggest the Action Research as the way to disentagle from that triple schizophrenia.","[{'name': 'David Benavides', 'org': 'University of Seville#TAB#', 'id': 2124048338}, {'name': 'Antonio Ruiz Cortés', 'id': 2156297120}, {'name': 'Carlos Müller', 'id': 2233941481}, {'name': 'Pablo Trinidad Martín-Arroyo', 'id': 86256941}]"
2964116313,Convolutional 2D Knowledge Graph Embeddings,2018,1,,,citation,"Link prediction for knowledge graphs is the task of predicting missing relationships between entities. Previous work on link prediction has focused on shallow, fast models which can scale to large knowledge graphs. However, these models learn less expressive features than deep, multi-layer models - which potentially limits performance. In this work we introduce ConvE, a multi-layer convolutional network model for link prediction, and report state-of-the-art results for several established datasets. We also show that the model is highly parameter efficient, yielding the same performance as DistMult and R-GCN with 8x and 17x fewer parameters. Analysis of our model suggests that it is particularly effective at modelling nodes with high indegree - which are common in highly-connected, complex knowledge graphs such as Freebase and YAGO3. In addition, it has been noted that the WN18 and FB15k datasets suffer from test set leakage, due to inverse relations from the training set being present in the test set - however, the extent of this issue has so far not been quantified. We find this problem to be severe: a simple rule-based model can achieve state-of-the-art results on both WN18 and FB15k. To ensure that models are evaluated on datasets where simply exploiting inverse relations cannot yield competitive results, we investigate and validate several commonly used datasets - deriving robust variants where necessary. We then perform experiments on these robust datasets for our own and several previously proposed models, and find that ConvE achieves state-of-the-art Mean Reciprocal Rank across all datasets.","[{'name': 'Tim Dettmers', 'id': 2732476013}, {'name': 'Pasquale Minervini', 'id': 681779131}, {'name': 'Pontus Stenetorp', 'id': 43645529}, {'name': 'Sebastian Riedel', 'id': 1976791985}]"
2963432357,Complex embeddings for simple link prediction,2016,1,,,citation,"In statistical relational learning, the link prediction problem is key to automatically understand the structure of large knowledge bases. As in previous studies, we propose to solve this problem through latent factorization. However, here we make use of complex valued embeddings. The composition of complex embeddings can handle a large variety of binary relations, among them symmetric and antisymmetric relations. Compared to state-of-the-art models such as Neural Tensor Network and Holographic Embeddings, our approach based on complex embeddings is arguably simpler, as it only uses the Hermitian dot product, the complex counterpart of the standard dot product between real vectors. Our approach is scalable to large datasets as it remains linear in both space and time, while consistently outperforming alternative approaches on standard link prediction benchmarks.","[{'name': 'Théo Trouillon', 'org': ""Xerox Research Centre Europe, Meylan, France and Université Grenoble Alpes, Saint Martin d'Hères, France#TAB#"", 'id': 347299695}, {'name': 'Johannes Welbl', 'org': 'University College London \xa0London, United Kingdom', 'id': 2336861845}, {'name': 'Sebastian Riedel', 'org': 'University College London \xa0London, United Kingdom', 'id': 1976791985}, {'name': 'Éric Gaussier', 'org': ""Université Grenoble Alpes, Saint Martin d'Hères, France#TAB#"", 'id': 2815217814}, {'name': 'Guillaume Bouchard', 'org': 'University College London \xa0London, United Kingdom', 'id': 2336810427}]"
2962936385,Knowledge graph completion via complex tensor factorization,2017,1,,,citation,"In statistical relational learning, knowledge graph completion deals with automatically understanding the structure of large knowledge graphs--labeled directed graphs-- and predicting missing relationships--labeled edges. State-of-the-art embedding models propose different trade-offs between modeling expressiveness, and time and space complexity. We reconcile both expressiveness and complexity through the use of complex-valued embeddings and explore the link between such complex-valued embeddings and unitary diagonalization. We corroborate our approach theoretically and show that all real square matrices--thus all possible relation/adjacency matrices--are the real part of some unitarily diagonalizable matrix. This results opens the door to a lot of other applications of square matrices factorization. Our approach based on complex embeddings is arguably simple, as it only involves a Hermitian dot product, the complex counterpart of the standard dot product between real vectors, whereas other methods resort to more and more complicated composition functions to increase their expressiveness. The proposed complex embeddings are scalable to large data sets as it remains linear in both space and time, while consistently outperforming alternative approaches on standard link prediction benchmarks.","[{'name': 'Théo Trouillon', 'org': ""Univ. Grenoble Alpes, Saint Martin d'Hères, France#TAB#"", 'id': 347299695}, {'name': 'Christopher R. Dance', 'org': 'NAVER LABS Europe, Meylan, France#TAB#', 'id': 1991661564}, {'name': 'Éric Gaussier', 'org': ""Univ. Grenoble Alpes, Saint Martin d'Hères, France#TAB#"", 'id': 2815217814}, {'name': 'Johannes Welbl', 'org': 'University College London \xa0London, United Kingdom', 'id': 2336861845}, {'name': 'Sebastian Riedel', 'org': 'University College London \xa0London, United Kingdom', 'id': 1976791985}, {'name': 'Guillaume Bouchard', 'org': 'Bloomsbury AI, London, United Kingdom and University College London, London, United Kingdom#TAB#', 'id': 2336810427}]"
2951528779,Knowledge Graph Representation with Jointly Structural and Textual Encoding,2016,1,,,citation,"The objective of knowledge graph embedding is to encode both entities and relations of knowledge graphs into continuous low-dimensional vector spaces. Previously, most works focused on symbolic representation of knowledge graph with structure information, which can not handle new entities or entities with few facts well. In this paper, we propose a novel deep architecture to utilize both structural and textual information of entities. Specifically, we introduce three neural models to encode the valuable information from text description of entity, among which an attentive model can select related information as needed. Then, a gating mechanism is applied to integrate representations of structure and text into a unified architecture. Experiments show that our models outperform baseline by margin on link prediction and triplet classification tasks. Source codes of this paper will be available on Github.","[{'name': 'Jiacheng Xu', 'id': 2686029134}, {'name': 'Kan Chen', 'id': 2550991812}, {'name': 'Xipeng Qiu', 'id': 2115470192}, {'name': 'Xuanjing Huang', 'id': 2161482855}]"
2950133940,Distributed Representations of Words and Phrases and their Compositionality,2013,1,,,citation,"The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of ""Canada"" and ""Air"" cannot be easily combined to obtain ""Air Canada"". Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible.","[{'name': 'Tomas Mikolov', 'id': 292626543}, {'name': 'Ilya Sutskever', 'id': 215131072}, {'name': 'Kai Chen', 'id': 2146330397}, {'name': 'Greg Corrado', 'id': 1994222016}, {'name': 'Jeffrey Dean', 'id': 2429370538}]"
2890648394,Never-ending learning,2015,1,,,citation,"Whereas people learn many different types of knowledge from diverse experiences over many years, most current machine learning systems acquire just a single function or data model from just a single data set. We propose a never-ending learning paradigm for machine learning, to better reflect the more ambitious and encompassing type of learning performed by humans. As a case study, we describe the Never-Ending Language Learner (NELL), which achieves some of the desired properties of a never-ending learner, and we discuss lessons learned. NELL has been learning to read the web 24 hours/day since January 2010, and so far has acquired a knowledge base with over 80 million confidence-weighted beliefs (e.g., servedWith(tea, biscuits)), while learning continually to improve its reading competence over time. NELL has also learned to reason over its knowledge base to infer new beliefs from old ones, and is now beginning to extend its ontology by synthesizing new relational predicates. NELL can be tracked online at http://rtw.ml.cmu.edu, and followed on Twitter at @CMUNELL.","[{'name': 'T. Mitchell', 'org': 'Carnegie - Mellon University#TAB#', 'id': 2151014374}, {'name': 'W. Cohen', 'org': 'Carnegie - Mellon University#TAB#', 'id': 2115385359}, {'name': 'E. Hruschka', 'org': 'University of São Carlos, Brazil and Research carried out while at Carnegie Mellon University#TAB#', 'id': 2973522767}, {'name': 'P. Talukdar', 'org': 'Indian Institute of Science, India and Research carried out while at Carnegie Mellon University#TAB#', 'id': 2407474466}, {'name': 'J. Betteridge', 'org': 'Carnegie - Mellon University#TAB#', 'id': 2143543388}, {'name': 'A. Carlson', 'org': 'Google Inc. and Research carried out while at Carnegie Mellon University#TAB#', 'id': 2154786016}, {'name': 'B. Dalvi', 'org': 'Carnegie - Mellon University#TAB#', 'id': 2081006310}, {'name': 'M. Gardner', 'org': 'Carnegie - Mellon University#TAB#', 'id': 2133268498}, {'name': 'B. Kisiel', 'org': 'Carnegie - Mellon University#TAB#', 'id': 2494956587}, {'name': 'J. Krishnamurthy', 'org': 'Carnegie - Mellon University#TAB#', 'id': 2137416177}, {'name': 'N. Lao', 'org': 'Google Inc. and Research carried out while at Carnegie Mellon University#TAB#', 'id': 2145221253}, {'name': 'K. Mazaitis', 'org': 'Carnegie - Mellon University#TAB#', 'id': 2040177228}, {'name': 'T. Mohamed', 'org': 'Research carried out while at Carnegie Mellon University#TAB#', 'id': 2688623777}, {'name': 'N. Nakashole', 'org': 'Carnegie - Mellon University#TAB#', 'id': 2022819398}, {'name': 'E. Platanios', 'org': 'Carnegie - Mellon University#TAB#', 'id': 2011834717}, {'name': 'A. Ritter', 'org': 'Ohio State University and Research carried out while at Carnegie Mellon University#TAB#', 'id': 2154095546}, {'name': 'M. Samadi', 'org': 'Carnegie - Mellon University#TAB#', 'id': 2132903572}, {'name': 'B. Settles', 'org': 'Duolingo and Research carried out while at Carnegie Mellon University#TAB#', 'id': 2911267484}, {'name': 'R. Wang', 'org': 'Research carried out while at Carnegie Mellon University#TAB#', 'id': 2918522773}, {'name': 'D. Wijaya', 'org': 'Carnegie - Mellon University#TAB#', 'id': 2238690600}, {'name': 'A. Gupta', 'org': 'Carnegie - Mellon University#TAB#', 'id': 2099263982}, {'name': 'X. Chen', 'org': 'Carnegie - Mellon University#TAB#', 'id': 2883814010}, {'name': 'A. Saparov', 'org': 'Carnegie - Mellon University#TAB#', 'id': 2635299887}, {'name': 'M. Greaves', 'org': 'Alpine Data Labs and Research carried out while at Carnegie Mellon University#TAB#', 'id': 2588358636}, {'name': 'J. Welling', 'org': 'Pittsburgh Supercomputing Center,', 'id': 2808178753}]"
2740934577,CANE: Context-Aware Network Embedding for Relation Modeling,2017,1,,,citation,,"[{'name': 'Cunchao Tu', 'id': 2119971483}, {'name': 'Han Liu', 'id': 2741588858}, {'name': 'Zhiyuan Liu', 'id': 2580718499}, {'name': 'Maosong Sun', 'id': 2157167650}]"
2579831760,GAKE: Graph Aware Knowledge Embedding.,2016,1,,,citation,,"[{'name': 'Jun Feng', 'id': 2680159566}, {'name': 'Minlie Huang', 'id': 2162268045}, {'name': 'Yang Yang', 'id': 2673426936}, {'name': 'Xiaoyan Zhu', 'id': 2147746173}]"
2563063592,Jointly Embedding Knowledge Graphs and Logical Rules.,2016,1,,,citation,,"[{'name': 'Shu Guo', 'id': 2711486412}, {'name': 'Quan Wang', 'id': 2713436602}, {'name': 'Lihong Wang', 'id': 2562931221}, {'name': 'Bin Wang', 'id': 2690358303}, {'name': 'Li Guo', 'id': 2122010476}]"
2460319482,Compositional Learning of Embeddings for Relation Paths in Knowledge Base and Text,2016,1,,,citation,"Modeling relation paths has offered significant gains in embedding models for knowledge base (KB) completion. However, enumerating paths between two entities is very expensive, and existing approaches typically resort to approximation with a sampled subset. This problem is particularly acute when text is jointly modeled with KB relations and used to provide direct evidence for facts mentioned in it. In this paper, we propose the first exact dynamic programming algorithm which enables efficient incorporation of all relation paths of bounded length, while modeling both relation types and intermediate nodes in the compositional path representations. We conduct a theoretical analysis of the efficiency gain from the approach. Experiments on two datasets show that it addresses representational limitations in prior approaches and improves accuracy in KB completion.","[{'name': 'Kristina Toutanova', 'id': 1997665198}, {'name': 'Victoria Lin', 'id': 2714540748}, {'name': 'Wen-tau Yih', 'id': 2116578203}, {'name': 'Hoifung Poon', 'id': 2032387740}, {'name': 'Chris Quirk', 'id': 2165558247}]"
2283196293,Knowledge graph embedding by translating on hyperplanes,2014,1,,,citation,"We deal with embedding a large scale knowledge graph composed of entities and relations into a continuous vector space. TransE is a promising method proposed recently, which is very efficient while achieving state-of-the-art predictive performance. We discuss some mapping properties of relations which should be considered in embedding, such as reflexive, one-to-many, many-to-one, and many-to-many. We note that TransE does not do well in dealing with these properties. Some complex models are capable of preserving these mapping properties but sacrifice efficiency in the process. To make a good trade-off between model capacity and efficiency, in this paper we propose TransH which models a relation as a hyperplane together with a translation operation on it. In this way, we can well preserve the above mapping properties of relations with almost the same model complexity of TransE. Additionally, as a practical knowledge graph is often far from completed, how to construct negative examples to reduce false negative labels in training is very important. Utilizing the one-to-many/many-to-one mapping property of a relation, we propose a simple trick to reduce the possibility of false negative labeling. We conduct extensive experiments on link prediction, triplet classification and fact extraction on benchmark datasets like WordNet and Freebase. Experiments show TransH delivers significant improvements over TransE on predictive accuracy with comparable capability to scale up.","[{'name': 'Zhen Wang', 'org': 'Department of Information Science and Technology, Sun Yat-Sen University, Guangzhou, China#TAB#', 'id': 2573191577}, {'name': 'Jianwen Zhang', 'org': 'Microsoft Research Beijing China', 'id': 2212130774}, {'name': 'Jianlin Feng', 'org': 'Department of Information Science and Technology, Sun Yat-Sen University, Guangzhou, China#TAB#', 'id': 2619281632}, {'name': 'Zheng Chen', 'org': 'Microsoft Research Beijing China', 'id': 2425877144}]"
2250635077,Representing Text for Joint Embedding of Text and Knowledge Bases,2015,1,,,citation,"Models that learn to represent textual and knowledge base relations in the same continuous latent space are able to perform joint inferences among the two kinds of relations and obtain high accuracy on knowledge base completion (Riedel et al., 2013). In this paper we propose a model that captures the compositional structure of textual relations, and jointly optimizes entity, knowledge base, and textual relation representations. The proposed model significantly improves performance over a model that does not share parameters among textual relations with common sub-structure.","[{'name': 'Kristina Toutanova', 'id': 1997665198}, {'name': 'Danqi Chen', 'id': 2104844286}, {'name': 'Patrick Pantel', 'id': 2250462127}, {'name': 'Hoifung Poon', 'id': 2032387740}, {'name': 'Pallavi Choudhury', 'id': 2118255939}, {'name': 'Michael Gamon', 'id': 1896392369}]"
2250342289,Knowledge Graph Embedding via Dynamic Mapping Matrix,2015,1,,,citation,"Knowledge graphs are useful resources for numerous AI applications, but they are far from completeness. Previous work such as TransE, TransH and TransR/CTransR regard a relation as translation from head entity to tail entity and the CTransR achieves state-of-the-art performance. In this paper, we propose a more fine-grained model named TransD, which is an improvement of TransR/CTransR. In TransD, we use two vectors to represent a named symbol object (entity and relation). The first one represents the meaning of a(n) entity (relation), the other one is used to construct mapping matrix dynamically. Compared with TransR/CTransR, TransD not only considers the diversity of relations, but also entities. TransD has less parameters and has no matrix-vector multiplication operations, which makes it can be applied on large scale graphs. In Experiments, we evaluate our model on two typical tasks including triplets classification and link prediction. Evaluation results show that our approach outperforms state-of-the-art methods.","[{'name': 'Guoliang Ji', 'org': 'INSTITUTE OF AUTOMATION CHINESE ACADEMY OF SCIENCES', 'id': 2718547011}, {'name': 'Shizhu He', 'org': 'INSTITUTE OF AUTOMATION CHINESE ACADEMY OF SCIENCES', 'id': 2126153884}, {'name': 'Liheng Xu', 'org': 'INSTITUTE OF AUTOMATION CHINESE ACADEMY OF SCIENCES', 'id': 2103933660}, {'name': 'Kang Liu', 'org': 'INSTITUTE OF AUTOMATION CHINESE ACADEMY OF SCIENCES', 'id': 2130404924}, {'name': 'Jun Zhao', 'org': 'INSTITUTE OF AUTOMATION CHINESE ACADEMY OF SCIENCES', 'id': 2590483556}]"
2226877337,Type-Constrained Representation Learning in Knowledge Graphs,2015,1,,,citation,"Large knowledge graphs increasingly add value to various applications that require machines to recognize and understand queries and their semantics, as in search or question answering systems. Latent variable models have increasingly gained attention for the statistical modeling of knowledge graphs, showing promising results in tasks related to knowledge graph completion and cleaning. Besides storing facts about the world, schema-based knowledge graphs are backed by rich semantic descriptions of entities and relation-types that allow machines to understand the notion of things and their semantic relationships. In this work, we study how type-constraints can generally support the statistical modeling with latent variable models. More precisely, we integrated prior knowledge in form of type-constraints in various state of the art latent variable approaches. Our experimental results show that prior knowledge on relation-types significantly improves these models up to 77% in link-prediction tasks. The achieved improvements are especially prominent when a low model complexity is enforced, a crucial requirement when these models are applied to very large datasets. Unfortunately, type-constraints are neither always available nor always complete e.g., they can become fuzzy when entities lack proper typing. We show that in these cases, it can be beneficial to apply a local closed-world assumption that approximates the semantics of relation-types based on observations made in the data.","[{'name': 'Denis Krompaβ', 'org': 'Siemens AG Corporate Technology, Munich, Germany and Ludwig Maximilian University, Munich, Germany#TAB#', 'id': 2477706755}, {'name': 'Stephan Baier', 'org': 'Siemens Ag, Corporate Technology, Munich, Germany', 'id': 2776422836}, {'name': 'Volker Tresp', 'org': 'Siemens AG Corporate Technology, Munich, Germany and Ludwig Maximilian University, Munich, Germany#TAB#', 'id': 175204660}]"
2184957013,Learning entity and relation embeddings for knowledge graph completion,2015,1,,,citation,"Knowledge graph completion aims to perform link prediction between entities. In this paper, we consider the approach of knowledge graph embeddings. Recently, models such as TransE and TransH build entity and relation embeddings by regarding a relation as translation from head entity to tail entity. We note that these models simply put both entities and relations within the same semantic space. In fact, an entity may have multiple aspects and various relations may focus on different aspects of entities, which makes a common space insufficient for modeling. In this paper, we propose TransR to build entity and relation embeddings in separate entity space and relation spaces. Afterwards, we learn embeddings by first projecting entities from entity space to corresponding relation space and then building translations between projected entities. In experiments, we evaluate our models on three tasks including link prediction, triple classification and relational fact extraction. Experimental results show significant and consistent improvements compared to state-of-the-art baselines including TransE and TransH. The source code of this paper can be obtained from https://github.com/mrlyk423/relation_extraction.","[{'name': 'Yankai Lin', 'org': 'Department of Computer Science and Technology, State Key Lab on Intelligent Technology and Systems, National Lab for Information Science and Technology, Tsinghua University, Beijing, China#TAB#', 'id': 2163825132}, {'name': 'Zhiyuan Liu', 'org': 'Department of Computer Science and Technology, State Key Lab on Intelligent Technology and Systems, National Lab for Information Science and Technology, Tsinghua University, Beijing, China#TAB#', 'id': 2580718499}, {'name': 'Maosong Sun', 'org': 'Department of Computer Science and Technology, State Key Lab on Intelligent Technology and Systems, National Lab for Information Science and Technology, Tsinghua University, Beijing, China and Jia ...#TAB#', 'id': 2157167650}, {'name': 'Yang Liu', 'org': 'Samsung R&D Institute of China, Beijing, China#TAB#', 'id': 2704902424}, {'name': 'Xuan Zhu', 'org': 'Samsung R&D Institute of China, Beijing, China#TAB#', 'id': 2644490398}]"
2158781217,Reducing the Rank in Relational Factorization Models by Including Observable Patterns,2014,1,,,citation,"Tensor factorization has become a popular method for learning from multi-relational data. In this context, the rank of the factorization is an important parameter that determines runtime as well as generalization ability. To identify conditions under which factorization is an efficient approach for learning from relational data, we derive upper and lower bounds on the rank required to recover adjacency tensors. Based on our findings, we propose a novel additive tensor factorization model to learn from latent and observable patterns on multi-relational data and present a scalable algorithm for computing the factorization. We show experimentally both that the proposed additive model does improve the predictive performance over pure latent variable methods and that it also reduces the required rank — and therefore runtime and memory complexity — significantly.","[{'name': 'Maximilian Nickel', 'org': 'LCSL, Poggio Lab, Massachusetts Institute of Technology, Cambridge, MA and Istituto Italiano di Tecnologia, Genova, Italy#TAB#', 'id': 2152648595}, {'name': 'Xueyan Jiang', 'org': 'Ludwig Maximilian University, Munich, Germany and Siemens AG, Corporate Technology, Munich, Germany#TAB#', 'id': 2225431884}, {'name': 'Volker Tresp', 'org': 'Ludwig Maximilian University, Munich, Germany and Siemens AG, Corporate Technology, Munich, Germany#TAB#', 'id': 175204660}]"
2158028897,Knowledge Graph and Text Jointly Embedding,2014,1,,,citation,"We examine the embedding approach to reason new relational facts from a largescale knowledge graph and a text corpus. We propose a novel method of jointly embedding entities and words into the same continuous vector space. The embedding process attempts to preserve the relations between entities in the knowledge graph and the concurrences of words in the text corpus. Entity names and Wikipedia anchors are utilized to align the embeddings of entities and words in the same space. Large scale experiments on Freebase and a Wikipedia/NY Times corpus show that jointly embedding brings promising improvement in the accuracy of predicting facts, compared to separately embedding knowledge graphs and text. Particularly, jointly embedding enables the prediction of facts containing entities out of the knowledge graph, which cannot be handled by previous embedding methods. At the same time, concerning the quality of the word embeddings, experiments on the analogical reasoning task show that jointly embedding is comparable to or slightly better than word2vec (Skip-Gram).","[{'name': 'Zhen Wang', 'id': 2573191577}, {'name': 'Jianwen Zhang', 'id': 2212130774}, {'name': 'Jianlin Feng', 'id': 2619281632}, {'name': 'Zheng Chen', 'id': 2425877144}]"
2156954687,Learning Structured Embeddings of Knowledge Bases,2011,1,,,citation,,"[{'name': 'Antoine Bordes', 'id': 2160652726}, {'name': 'Jason Weston', 'id': 2981281612}, {'name': 'Ronan Collobert', 'id': 130200899}, {'name': 'Yoshua Bengio', 'id': 161269817}]"
2154851992,DeepWalk: online learning of social representations,2014,1,,,citation,"We present DeepWalk, a novel approach for learning latent representations of vertices in a network. These latent representations encode social relations in a continuous vector space, which is easily exploited by statistical models. DeepWalk generalizes recent advancements in language modeling and unsupervised feature learning (or deep learning) from sequences of words to graphs.   DeepWalk uses local information obtained from truncated random walks to learn latent representations by treating walks as the equivalent of sentences. We demonstrate DeepWalku0027s latent representations on several multi-label network classification tasks for social networks such as BlogCatalog, Flickr, and YouTube. Our results show that DeepWalk outperforms challenging baselines which are allowed a global view of the network, especially in the presence of missing information. DeepWalku0027s representations can provide F1 scores up to 10% higher than competing methods when labeled data is sparse. In some experiments, DeepWalku0027s representations are able to outperform all baseline methods while using 60% less training data.   DeepWalk is also scalable. It is an online learning algorithm which builds useful incremental results, and is trivially parallelizable. These qualities make it suitable for a broad class of real world applications such as network classification, and anomaly detection.","[{'name': 'Bryan Perozzi', 'org': 'Stony Brook University, Stony\xa0Brook, NY, USA', 'id': 1983756286}, {'name': 'Rami Al-Rfou', 'org': 'Stony Brook University, Stony\xa0Brook, NY, USA', 'id': 73721942}, {'name': 'Steven Skiena', 'org': 'Stony Brook University, Stony\xa0Brook, NY, USA', 'id': 2053543515}]"
2127795553,Translating Embeddings for Modeling Multi-relational Data,2013,1,,,citation,"We consider the problem of embedding entities and relationships of multi-relational data in low-dimensional vector spaces. Our objective is to propose a canonical model which is easy to train, contains a reduced number of parameters and can scale up to very large databases. Hence, we propose TransE, a method which models relationships by interpreting them as translations operating on the low-dimensional embeddings of the entities. Despite its simplicity, this assumption proves to be powerful since extensive experiments show that TransE significantly outperforms state-of-the-art methods in link prediction on two knowledge bases. Besides, it can be successfully trained on a large scale data set with 1M entities, 25k relationships and more than 17M training samples.","[{'name': 'Antoine Bordes', 'org': 'Université de Technologie de Compiègne - CNRS, Heudiasyc UMR 7253, Compiègne, France#TAB#', 'id': 2160652726}, {'name': 'Nicolas Usunier', 'org': 'Université de Technologie de Compiègne - CNRS, Heudiasyc UMR 7253, Compiègne, France#TAB#', 'id': 121890299}, {'name': 'Alberto Garcia-Duran', 'org': 'Université de Technologie de Compiègne - CNRS, Heudiasyc UMR 7253, Compiègne, France#TAB#', 'id': 2047865013}, {'name': 'Jason Weston', 'org': 'Google., New York, NY#TAB#', 'id': 2058584252}, {'name': 'Oksana Yakhnenko', 'org': 'Google., New York, NY#TAB#', 'id': 2000873150}]"
2127426251,Reasoning With Neural Tensor Networks for Knowledge Base Completion,2013,1,,,citation,"Knowledge bases are an important resource for question answering and other tasks but often suffer from incompleteness and lack of ability to reason over their discrete entities and relationships. In this paper we introduce an expressive neural tensor network suitable for reasoning over relationships between two entities. Previous work represented entities as either discrete atomic units or with a single entity vector representation. We show that performance can be improved when entities are represented as an average of their constituting word vectors. This allows sharing of statistical strength between, for instance, facts involving the ""Sumatran tiger"" and ""Bengal tiger."" Lastly, we demonstrate that all models improve when these word vectors are initialized with vectors learned from unsupervised large corpora. We assess the model by considering the problem of predicting additional true relations between entities given a subset of the knowledge base. Our model outperforms previous models and can classify unseen relationships in WordNet and FreeBase with an accuracy of 86.2% and 90.0%, respectively.","[{'name': 'Richard Socher', 'org': 'Computer Science Department, Stanford University, Stanford, CA', 'id': 1964982643}, {'name': 'Danqi Chen', 'org': 'Computer Science Department, Stanford University, Stanford, CA', 'id': 2104844286}, {'name': 'Christopher D Manning', 'org': 'Computer Science Department, Stanford University, Stanford, CA', 'id': 2149153931}, {'name': 'Andrew Ng', 'org': 'Computer Science Department, Stanford University, Stanford, CA', 'id': 2104401652}]"
2022166150,Yago: a core of semantic knowledge,2007,1,,,citation,"We present YAGO, a light-weight and extensible ontology with high coverage and quality. YAGO builds on entities and relations and currently contains more than 1 million entities and 5 million facts. This includes the Is-A hierarchy as well as non-taxonomic relations between entities (such as HASONEPRIZE). The facts have been automatically extracted from Wikipedia and unified with WordNet, using a carefully designed combination of rule-based and heuristic methods described in this paper. The resulting knowledge base is a major step beyond WordNet: in quality by adding knowledge about individuals like persons, organizations, products, etc. with their semantic relationships - and in quantity by increasing the number of facts by more than an order of magnitude. Our empirical evaluation of fact correctness shows an accuracy of about 95%. YAGO is based on a logically clean model, which is decidable, extensible, and compatible with RDFS. Finally, we show how YAGO can be further extended by state-of-the-art information extraction techniques.","[{'name': 'Fabian M. Suchanek', 'org': 'Max-Planck Institute for Computer Science', 'id': 69603646}, {'name': 'Gjergji Kasneci', 'org': 'Max-Planck Institute for Computer Science', 'id': 42507994}, {'name': 'Gerhard Weikum', 'org': 'Max-Planck Institute for Computer Science', 'id': 514836396}]"
2016753842,Knowledge vault: a web-scale approach to probabilistic knowledge fusion,2014,1,,,citation,"Recent years have witnessed a proliferation of large-scale knowledge bases, including Wikipedia, Freebase, YAGO, Microsoftu0027s Satori, and Googleu0027s Knowledge Graph. To increase the scale even further, we need to explore automatic methods for constructing knowledge bases. Previous approaches have primarily focused on text-based extraction, which can be very noisy. Here we introduce Knowledge Vault, a Web-scale probabilistic knowledge base that combines extractions from Web content (obtained via analysis of text, tabular data, page structure, and human annotations) with prior knowledge derived from existing knowledge repositories. We employ supervised machine learning methods for fusing these distinct information sources. The Knowledge Vault is substantially bigger than any previously published structured knowledge repository, and features a probabilistic inference system that computes calibrated probabilities of fact correctness. We report the results of multiple studies that explore the relative utility of the different information sources and extraction methods.","[{'name': 'Xin Dong', 'org': 'Google, Mountain View, CA, USA.', 'id': 2974162612}, {'name': 'Evgeniy Gabrilovich', 'org': 'Google, Mountain View, CA, USA.', 'id': 1804802447}, {'name': 'Geremy Heitz', 'org': 'Google, Mountain View, CA, USA.', 'id': 2000496673}, {'name': 'Wilko Horn', 'org': 'Google, Mountain View, CA, USA.', 'id': 2136244735}, {'name': 'Ni Lao', 'org': 'Google, Mountain View, CA, USA.', 'id': 2145221253}, {'name': 'Kevin Murphy', 'org': 'Google, Mountain View, CA, USA.', 'id': 2167731548}, {'name': 'Thomas Strohmann', 'org': 'Google, Mountain View, CA, USA.', 'id': 2574010033}, {'name': 'Shaohua Sun', 'org': 'Google, Mountain View, CA, USA.', 'id': 2124804123}, {'name': 'Wei Zhang', 'org': 'Google, Mountain View, CA, USA.', 'id': 2646486594}]"
1792926363,Connecting Language and Knowledge Bases with Embedding Models for Relation Extraction,2013,1,,,citation,"This paper proposes a novel approach for relation extraction from free text which is trained to jointly use information from the text and from existing knowledge. Our model is based on scoring functions that operate by learning low-dimensional embeddings of words, entities and relationships from a knowledge base. We empirically show on New York Times articles aligned with Freebase relations that our approach is able to efficiently use the extra information provided by a large subset of Freebase data (4M entities, 23k relationships) to improve over methods that rely on text features alone.","[{'name': 'Jason Weston', 'org': 'Google Inc.,', 'id': 2981281612}, {'name': 'Antoine Bordes', 'org': 'Laboratoire d\'Excellence ""Maîtrise des Systèmes de Systèmes Technologiques""', 'id': 2160652726}, {'name': 'Oksana Yakhnenko', 'org': 'Google Inc.,', 'id': 2000873150}, {'name': 'Nicolas Usunier', 'org': 'Laboratoire d\'Excellence ""Maîtrise des Systèmes de Systèmes Technologiques""', 'id': 121890299}]"
1756422141,Random Walk Inference and Learning in A Large Scale Knowledge Base,2011,1,,,citation,"We consider the problem of performing learning and inference in a large scale knowledge base containing imperfect knowledge with incomplete coverage. We show that a soft inference procedure based on a combination of constrained, weighted, random walks through the knowledge base graph can be used to reliably infer new beliefs for the knowledge base. More specifically, we show that the system can learn to infer different target relations by tuning the weights associated with random walks that follow different paths through the graph, using a version of the Path Ranking Algorithm (Lao and Cohen, 2010b). We apply this approach to a knowledge base of approximately 500,000 beliefs extracted imperfectly from the web by NELL, a never-ending language learner (Carlson et al., 2010). This new system improves significantly over NELLu0027s earlier Horn-clause learning and inference method: it obtains nearly double the precision at rank 100, and the new learning method is also applicable to many more inference tasks.","[{'name': 'Ni Lao', 'org': 'Carnegie Mellon University, Pittsburgh Pa', 'id': 2145221253}, {'name': 'Tom Mitchell', 'org': 'Carnegie Mellon University, Pittsburgh Pa', 'id': 2151014374}, {'name': 'William W. Cohen', 'org': 'Carnegie Mellon University, Pittsburgh Pa', 'id': 2115385359}]"
1426956448,Modeling Relation Paths for Representation Learning of Knowledge Bases,2015,1,,,citation,"Representation learning of knowledge bases aims to embed both entities and relations into a low-dimensional space. Most existing methods only consider direct relations in representation learning. We argue that multiple-step relation paths also contain rich inference patterns between entities, and propose a path-based representation learning model. This model considers relation paths as translations between entities for representation learning, and addresses two key challenges: (1) Since not all relation paths are reliable, we design a path-constraint resource allocation algorithm to measure the reliability of relation paths. (2) We represent relation paths via semantic composition of relation embeddings. Experimental results on real-world datasets show that, as compared with baselines, our model achieves significant and consistent improvements on knowledge base completion and relation extraction from text. The source code of this paper can be obtained from https://github.com/mrlyk423/ relation_extraction.","[{'name': 'Yankai Lin', 'id': 2163825132}, {'name': 'Zhiyuan Liu', 'org': 'Tsinghua University,', 'id': 2580718499}, {'name': 'Huanbo Luan', 'id': 2239152555}, {'name': 'Maosong Sun', 'id': 2157167650}, {'name': 'Siwei Rao', 'id': 2315242413}, {'name': 'Song Liu', 'id': 2321478378}]"
205829674,A Three-Way Model for Collective Learning on Multi-Relational Data,2011,1,,,citation,"Relational learning is becoming increasingly important in many areas of application. Here, we present a novel approach to relational learning based on the factorization of a three-way tensor. We show that unlike other tensor approaches, our method is able to perform collective learning via the latent components of the model and provide an efficient algorithm to compute the factorization. We substantiate our theoretical considerations regarding the collective learning capabilities of our model by the means of experiments on both a new dataset and a dataset commonly used in entity resolution. Furthermore, we show on common benchmark datasets that our approach achieves better or on-par results, if compared to current state-of-the-art relational learning solutions, while it is significantly faster to compute.","[{'name': 'Maximilian Nickel', 'org': 'Ludwig-Maximilians-Universit?t, Munich, Germany', 'id': 2152648595}, {'name': 'Volker Tresp', 'org': 'Siemens Ag, Corporate Technology, Munich, Germany', 'id': 175204660}, {'name': 'Hans-peter Kriegel', 'org': 'Ludwig-Maximilians-Universit?t, Munich, Germany', 'id': 1919135125}]"
102708294,DBpedia: a nucleus for a web of open data,2007,1,,,citation,"DBpedia is a community effort to extract structured information from Wikipedia and to make this information available on the Web. DBpedia allows you to ask sophisticated queries against datasets derived from Wikipedia and to link other datasets on the Web to Wikipedia data. We describe the extraction of the DBpedia datasets, and how the resulting information is published on the Web for human-andmachine-consumption. We describe some emerging applications from the DBpedia community and show how website authors can facilitate DBpedia content within their sites. Finally, we present the current status of interlinking DBpedia with other open datasets on the Web and outline how DBpedia could serve as a nucleus for an emerging Web of open data.","[{'name': 'Sören Auer', 'org': 'Universität Leipzig, Department of Computer Science, Leipzig, Germany and University of Pennsylvania, Department of Computer and Information Science, Philadelphia, PA#TAB#', 'id': 1994200327}, {'name': 'Christian Bizer', 'org': 'Freie Universität Berlin, Web-based Systems Group, Berlin, Germany#TAB#', 'id': 247353998}, {'name': 'Georgi Kobilarov', 'org': 'Freie Universität Berlin, Web-based Systems Group, Berlin, Germany#TAB#', 'id': 1082517911}, {'name': 'Jens Lehmann', 'org': 'Universität Leipzig, Department of Computer Science, Leipzig, Germany#TAB#', 'id': 2106343576}, {'name': 'Richard Cyganiak', 'org': 'Freie Universität Berlin, Web-based Systems Group, Berlin, Germany#TAB#', 'id': 57495579}, {'name': 'Zachary Ives', 'org': 'University of Pennsylvania, Department of Computer and Information Science, Philadelphia, PA#TAB#', 'id': 53579654}]"
2949972983,Holographic Embeddings of Knowledge Graphs,2015,1,,,citation,"Learning embeddings of entities and relations is an efficient and versatile method to perform machine learning on relational data such as knowledge graphs. In this work, we propose holographic embeddings (HolE) to learn compositional vector space representations of entire knowledge graphs. The proposed method is related to holographic models of associative memory in that it employs circular correlation to create compositional representations. By using correlation as the compositional operator HolE can capture rich interactions but simultaneously remains efficient to compute, easy to train, and scalable to very large datasets. In extensive experiments we show that holographic embeddings are able to outperform state-of-the-art methods for link prediction in knowledge graphs and relational learning benchmark datasets.","[{'name': 'Maximilian Nickel', 'id': 2152648595}, {'name': 'Lorenzo Rosasco', 'id': 2028927923}, {'name': 'Tomaso Poggio', 'id': 693931197}]"
2247119764,Learning structured embeddings of knowledge bases,2011,1,,,citation,"Many Knowledge Bases (KBs) are now readily available and encompass colossal quantities of information thanks to either a long-term funding effort (e.g. WordNet, OpenCyc) or a collaborative process (e.g. Freebase, DBpedia). However, each of them is based on a different rigid symbolic framework which makes it hard to use their data in other systems. It is unfortunate because such rich structured knowledge might lead to a huge leap forward in many other areas of AI like natural language processing (word-sense disambiguation, natural language understanding, ...), vision (scene classification, image semantic annotation, ...) or collaborative filtering. In this paper, we present a learning process based on an innovative neural network architecture designed to embed any of these symbolic representations into a more flexible continuous vector space in which the original knowledge is kept and enhanced. These learnt embeddings would allow data from any KB to be easily used in recent machine learning methods for prediction and information retrieval. We illustrate our method on WordNet and Freebase and also present a way to adapt it to knowledge extraction from raw text.","[{'name': 'Antoine Bordes', 'org': 'Heudiasyc UMR CNRS 6599, Université de Technologie, Compiègne, France#TAB#', 'id': 2160652726}, {'name': 'Jason Weston', 'org': 'Google., New York, NY#TAB#', 'id': 2981281612}, {'name': 'Ronan Collobert', 'org': 'IDIAP, Martigny, Switzerland#TAB#', 'id': 130200899}, {'name': 'Yoshua Bengio', 'org': 'Departement IRO, Universite de Montreal Montreal. QC, Canada#TAB#', 'id': 161269817}]"
2963542836,Learning Natural Language Inference with LSTM,2016,1,,,citation,,"[{'name': 'Shuohang Wang', 'id': 2200892348}, {'name': 'Jing Jiang', 'id': 2286546702}]"
2962854379,The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems,2015,1,,,citation,"This paper introduces the Ubuntu Dialogue Corpus, a dataset containing almost 1 million multi-turn dialogues, with a total of over 7 million utterances and 100 million words. This provides a unique resource for research into building dialogue managers based on neural language models that can make use of large amounts of unlabeled data. The dataset has both the multi-turn property of conversations in the Dialog State Tracking Challenge datasets, and the unstructured nature of interactions from microblog services such as Twitter. We also describe two neural learning architectures suitable for analyzing this dataset, and provide benchmark performance on the task of selecting the best next response.","[{'name': 'Ryan Lowe', 'id': 2262140602}, {'name': 'Nissan Pow', 'id': 2550377245}, {'name': 'Iulian Serban', 'id': 2221625686}, {'name': 'Joelle Pineau', 'id': 2092672596}]"
2962790214,Convolutional Spatial Attention Model for Reading Comprehension with Multiple-Choice Questions,2019,1,,,citation,"Machine Reading Comprehension (MRC) with multiplechoice questions requires the machine to read given passage and select the correct answer among several candidates. In this paper, we propose a novel approach called Convolutional Spatial Attention (CSA) model which can better handle the MRC with multiple-choice questions. The proposed model could fully extract the mutual information among the passage, question, and the candidates, to form the enriched representations. Furthermore, to merge various attention results, we propose to use convolutional operation to dynamically summarize the attention values within the different size of regions. Experimental results show that the proposed model could give substantial improvements over various state-of- the-art systems on both RACE and SemEval-2018 Task11 datasets.","[{'name': 'Zhipeng Chen', 'org': '(iFLYTEK Research)', 'id': 2510227619}, {'name': 'Yiming Cui', 'org': '(iFLYTEK Research)', 'id': 2687376174}, {'name': 'Wentao Ma', 'org': '(iFLYTEK Research)', 'id': 2758072514}, {'name': 'Shijin Wang', 'org': '(iFLYTEK CO., LTD)', 'id': 2496586547}, {'name': 'Guoping Hu', 'org': 'Ministry of Public Security', 'id': 2496894573}]"
2962739339,DEEP CONTEXTUALIZED WORD REPRESENTATIONS,2018,1,,,citation,"We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pretrained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pretrained network is crucial, allowing downstream models to mix different types of semi-supervision signals.","[{'name': 'Matthew E Peters', 'org': 'Allen Institute for Artificial Intelligence', 'id': 2502758396}, {'name': 'Mark Neumann', 'org': 'Allen Institute for Artificial Intelligence', 'id': 2723434371}, {'name': 'Mohit Iyyer', 'org': 'Allen Institute for Artificial Intelligence', 'id': 2068391019}, {'name': 'Matt Gardner', 'org': 'Allen Institute for Artificial Intelligence', 'id': 2133268498}, {'name': 'Christopher Clark', 'org': 'University of Washington,', 'id': 2568940999}, {'name': 'Kenton Lee', 'org': 'University of Washington,', 'id': 2552119883}, {'name': 'Luke Zettlemoyer', 'org': 'University of Washington,', 'id': 334758317}]"
2951815760,Bidirectional Attention Flow for Machine Comprehension,2016,1,,,citation,"Machine comprehension (MC), answering a query about a given context paragraph, requires modeling complex interactions between the context and the query. Recently, attention mechanisms have been successfully extended to MC. Typically these methods use attention to focus on a small portion of the context and summarize it with a fixed-size vector, couple attentions temporally, and/or often form a uni-directional attention. In this paper we introduce the Bi-Directional Attention Flow (BIDAF) network, a multi-stage hierarchical process that represents the context at different levels of granularity and uses bi-directional attention flow mechanism to obtain a query-aware context representation without early summarization. Our experimental evaluations show that our model achieves the state-of-the-art results in Stanford Question Answering Dataset (SQuAD) and CNN/DailyMail cloze test.","[{'name': 'Minjoon Seo', 'id': 2252216270}, {'name': 'Aniruddha Kembhavi', 'id': 2096537899}, {'name': 'Ali Farhadi', 'id': 1988090614}, {'name': 'Hannaneh Hajishirzi', 'id': 91410043}]"
2891416139,Sequential Matching Network: A New Architecture for Multi-turn Response Selection in Retrieval-Based Chatbots,2017,1,,,citation,,"[{'name': 'Yu Wu', 'id': 2150904948}, {'name': 'Wei Wu', 'id': 2590381716}, {'name': 'Chen Xing', 'id': 2915079835}, {'name': 'Ming Zhou', 'id': 2143584880}, {'name': 'Zhoujun Li', 'id': 2133880114}]"
2798456655,Multi-Turn Response Selection for Chatbots with Deep Attention Matching Network,2018,1,,,citation,,"[{'name': 'Xiangyang Zhou', 'id': 2558220530}, {'name': 'Lu Li', 'id': 2799099007}, {'name': 'Daxiang Dong', 'id': 2251109285}, {'name': 'Yi Liu', 'id': 2798769482}, {'name': 'Ying Chen', 'id': 2798617802}, {'name': 'Wayne Xin Zhao', 'id': 2307999729}, {'name': 'Dianhai Yu', 'id': 2627746506}, {'name': 'Hua Wu', 'id': 2223354072}]"
2597655663,A Structured Self-attentive Sentence Embedding,2017,1,,,citation,"This paper proposes a new model for extracting an interpretable sentence embedding by introducing self-attention. Instead of using a vector, we use a 2-D matrix to represent the embedding, with each row of the matrix attending on a different part of the sentence. We also propose a self-attention mechanism and a special regularization term for the model. As a side effect, the embedding comes with an easy way of visualizing what specific parts of the sentence are encoded into the embedding. We evaluate our model on 3 different tasks: author profiling, sentiment classification, and textual entailment. Results show that our model yields a significant performance gain compared to other sentence embedding methods in all of the 3 tasks.","[{'name': 'Zhouhan Lin', 'id': 2584500735}, {'name': 'Minwei Feng', 'id': 2651107085}, {'name': 'Cicero Nogueira dos Santos', 'id': 2158019794}, {'name': 'Mo Yu', 'id': 2751222758}, {'name': 'Bing Xiang', 'id': 2168100440}, {'name': 'Bowen Zhou', 'id': 2142227750}, {'name': 'Yoshua Bengio', 'id': 161269817}]"
2561368124,Multi-view Response Selection for Human-Computer Conversation,2016,1,,,citation,,"[{'name': 'Xiangyang Zhou', 'id': 2558220530}, {'name': 'Daxiang Dong', 'id': 2251109285}, {'name': 'Hua Wu', 'id': 2223354072}, {'name': 'Shiqi Zhao', 'id': 2289062988}, {'name': 'Dianhai Yu', 'id': 2627746506}, {'name': 'Hao Tian', 'id': 2479431458}, {'name': 'Xuan Liu', 'id': 2564367114}, {'name': 'Rui Yan', 'id': 2109109241}]"
2399060250,On the Evaluation of Dialogue Systems with Next Utterance Classification,2016,1,,,citation,"An open challenge in constructing dialogue systems is developing methods for automatically learning dialogue strategies from large amounts of unlabelled data. Recent work has proposed Next-Utterance-Classification (NUC) as a surrogate task for building dialogue systems from text data. In this paper we investigate the performance of humans on this task to validate the relevance of NUC as a method of evaluation. Our results show three main findings: (1) humans are able to correctly classify responses at a rate much better than chance, thus confirming that the task is feasible, (2) human performance levels vary across task domains (we consider 3 datasets) and expertise levels (novice vs experts), thus showing that a range of performance is possible on this type of task, (3) automated dialogue systems built using state-of-the-art machine learning methods have similar performance to the human novices, but worse than the experts, thus confirming the utility of this class of tasks for driving further research in automated dialogue systems.","[{'name': 'Ryan Lowe', 'id': 2262140602}, {'name': 'Iulian V. Serban', 'id': 2221625686}, {'name': 'Mike Noseworthy', 'id': 2619450762}, {'name': 'Laurent Charlin', 'id': 242798638}, {'name': 'Joelle Pineau', 'id': 2092672596}]"
2338325072,Match-SRNN: Modeling the Recursive Matching Structure with Spatial RNN,2016,1,,,citation,"Semantic matching, which aims to determine the matching degree between two texts, is a fundamental problem for many NLP applications. Recently, deep learning approach has been applied to this problem and significant improvements have been achieved. In this paper, we propose to view the generation of the global interaction between two texts as a recursive process: i.e. the interaction of two texts at each position is a composition of the interactions between their prefixes as well as the word level interaction at the current position. Based on this idea, we propose a novel deep architecture, namely Match-SRNN, to model the recursive matching structure. Firstly, a tensor is constructed to capture the word level interactions. Then a spatial RNN is applied to integrate the local interactions recursively, with importance determined by four types of gates. Finally, the matching score is calculated based on the global interaction. We show that, after degenerated to the exact matching scenario, Match-SRNN can approximate the dynamic programming process of longest common subsequence. Thus, there exists a clear interpretation for Match-SRNN. Our experiments on two semantic matching tasks showed the effectiveness of Match-SRNN, and its ability of visualizing the learned matching structure.","[{'name': 'Shengxian Wan', 'id': 2109603945}, {'name': 'Yanyan Lan', 'id': 2154124860}, {'name': 'Jun Xu', 'id': 2598177019}, {'name': 'Jiafeng Guo', 'id': 2581340266}, {'name': 'Liang Pang', 'id': 2655198468}, {'name': 'Xueqi Cheng', 'id': 2129598186}]"
2306229986,Sentence Pair Scoring: Towards Unified Framework for Text Comprehension.,2016,1,,,citation,"We review the task of Sentence Pair Scoring, popular in the literature in various forms - viewed as Answer Sentence Selection, Semantic Text Scoring, Next Utterance Ranking, Recognizing Textual Entailment, Paraphrasing or e.g. a component of Memory Networks.  :[38],""argue that all such tasks are similar from the model perspective and propose new baselines by comparing the performance of common IR metrics and popular convolutional, recurrent and attention-based neural models across many Sentence Pair Scoring tasks and datasets. We discuss the problem of evaluating randomized models, propose a statistically grounded methodology, and attempt to improve comparisons by releasing new datasets that are much harder than some of the currently used well explored benchmarks. We introduce a unified open source software framework with easily pluggable models and tasks, which enables us to experiment with multi-task reusability of trained sentence model. We set a new state-of-art in performance on the Ubuntu Dialogue dataset.","[{'name': 'Petr Baudis', 'id': 2052191846}, {'name': 'Jan Sedivý', 'id': 2224042201}]"
2250539671,Glove: Global Vectors for Word Representation,2014,1,,,citation,"Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.","[{'name': 'Jeffrey Pennington', 'org': 'Stanford, University', 'id': 2517910439}, {'name': 'Richard Socher', 'id': 1964982643}, {'name': 'Christopher Manning', 'org': 'Stanford, University', 'id': 2149153931}]"
2197546379,Improved Deep Learning Baselines for Ubuntu Corpus Dialogs.,2015,1,,,citation,"This paper presents results of our experiments for the next utterance ranking on the Ubuntu Dialog Corpus -- the largest publicly available multi-turn dialog corpus. First, we use an in-house implementation of previously reported models to do an independent evaluation using the same data. Second, we evaluate the performances of various LSTMs, Bi-LSTMs and CNNs on the dataset. Third, we create an ensemble by averaging predictions of multiple models. The ensemble further improves the performance and it achieves a state-of-the-art result for the next utterance ranking on this dataset. Finally, we discuss our future plans using this corpus.","[{'name': 'Rudolf Kadlec', 'id': 2076763229}, {'name': 'Martin Schmid', 'id': 2497506858}, {'name': 'Jan Kleindienst', 'id': 2188175883}]"
2128892113,A Deep Architecture for Matching Short Texts,2013,1,,,citation,"Many machine learning problems can be interpreted as learning for matching two types of objects (e.g., images and captions, users and products, queries and documents, etc.). The matching level of two objects is usually measured as the inner product in a certain feature space, while the modeling effort focuses on mapping of objects from the original space to the feature space. This schema, although proven successful on a range of matching tasks, is insufficient for capturing the rich structure in the matching process of more complicated objects. In this paper, we propose a new deep architecture to more effectively model the complicated matching relations between two objects from heterogeneous domains. More specifically, we apply this model to matching tasks in natural language, e.g., finding sensible responses for a tweet, or relevant answers to a given question. This new architecture naturally combines the localness and hierarchy intrinsic to the natural language problems, and therefore greatly improves upon the state-of-the-art models.","[{'name': 'Zhengdong Lu', 'org': ""Noah's Ark Lab, Huawei Technologies Co. Ltd., Sha Tin, Hong Kong#TAB#"", 'id': 2514095899}, {'name': 'Hang Li', 'org': ""Noah's Ark Lab, Huawei Technologies Co. Ltd., Sha Tin, Hong Kong#TAB#"", 'id': 2128739099}]"
2096145771,Quantitative and Qualitative Evaluation of Darpa Communicator Spoken Dialogue Systems,2001,1,,,citation,"This paper describes the application of the PARADISE evaluation framework to the corpus of 662 human-computer dialogues collected in the June 2000 Darpa Communicator data collection. We describe results based on the standard logfile metrics as well as results based on additional qualitative metrics derived using the DATE dialogue act tagging scheme. We show that performance models derived via using the standard metrics can account for 37% of the variance in user satisfaction, and that the addition of DATE metrics improved the models by an absolute 5%.","[{'name': 'Marilyn A. Walker', 'org': 'AT&T Labs- Research, Florham Park, NJ', 'id': 2152519802}, {'name': 'Rebecca Passonneau', 'org': 'AT&T Labs- Research, Florham Park, NJ', 'id': 113116722}, {'name': 'Julie E. Boland', 'org': 'University of Louisiana at Lafayette, Lafayette, LA', 'id': 2131078755}]"
1910529161,Syntax-based Deep Matching of Short Texts,2015,1,,,citation,"Many tasks in natural language processing, ranging from machine translation to question answering, can be reduced to the problem of matching two sentences or more generally two short texts. We propose a new approach to the problem, called Deep Match Tree (DeepMatch$_{tree}$), under a general setting. The approach consists of two components, 1) a mining algorithm to discover patterns for matching two short-texts, defined in the product space of dependency trees, and 2) a deep neural network for matching short texts using the mined patterns, as well as a learning algorithm to build the network having a sparse structure. We test our algorithm on the problem of matching a tweet and a response in social media, a hard matching problem proposed in [Wang et al., 2013], and show that DeepMatch$_{tree}$ can outperform a number of competitor models including one without using dependency trees and one based on word-embedding, all with large margins","[{'name': 'Mingxuan Wang', 'id': 2140908962}, {'name': 'Zhengdong Lu', 'id': 2514095899}, {'name': 'Hang Li', 'id': 2943731910}, {'name': 'Qun Liu', 'id': 2573745738}]"
1836465849,Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift,2015,1,,,citation,"Training Deep Neural Networks is complicated by the fact that the distribution of each layeru0027s inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.82% top-5 test error, exceeding the accuracy of human raters.","[{'name': 'Sergey Ioffe', 'org': 'Google, 1600 Amphitheatre Pkwy, Mountain View, CA 94043', 'id': 2272624714}, {'name': 'Christian Szegedy', 'org': 'Google, 1600 Amphitheatre Pkwy, Mountain View, CA 94043', 'id': 331124168}]"
1591706642,A Neural Conversational Model,2015,1,,,citation,"Conversational modeling is an important task in natural language understanding and machine intelligence. Although previous approaches exist, they are often restricted to specific domains (e.g., booking an airline ticket) and require hand-crafted rules. In this paper, we present a simple approach for this task which uses the recently proposed sequence to sequence framework. Our model converses by predicting the next sentence given the previous sentence or sentences in a conversation. The strength of our model is that it can be trained end-to-end and thus requires much fewer hand-crafted rules. We find that this straightforward model can generate simple conversations given a large conversational training dataset. Our preliminary results suggest that, despite optimizing the wrong objective function, the model is able to converse well. It is able extract knowledge from both a domain specific dataset, and from a large, noisy, and general domain dataset of movie subtitles. On a domain-specific IT helpdesk dataset, the model can find a solution to a technical problem via conversations. On a noisy open-domain movie transcript dataset, the model can perform simple forms of common sense reasoning. As expected, we also find that the lack of consistency is a common failure mode of our model.","[{'name': 'Oriol Vinyals', 'org': 'GOOGLE', 'id': 2634174050}, {'name': 'Quoc V. Le', 'id': 2148448995}]"
1522301498,Adam: A Method for Stochastic Optimization,2014,1,,,citation,"We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.","[{'name': 'Diederik P. Kingma', 'id': 2055604604}, {'name': 'Jimmy Ba', 'id': 2097546270}]"
295828404,An Information Retrieval Approach to Short Text Conversation.,2014,1,,,citation,"Human computer conversation is regarded as one of the most difficult problems in artificial intelligence. In this paper, we address one of its key sub-problems, referred to as short text conversation, in which given a message from human, the computer returns a reasonable response to the message. We leverage the vast amount of short conversation data available on social media to study the issue. We propose formalizing short text conversation as a search problem at the first step, and employing state-of-the-art information retrieval (IR) techniques to carry out the task. We investigate the significance as well as the limitation of the IR approach. Our experiments demonstrate that the retrieval-based model can make the system behave rather ""intelligently"", when combined with a huge repository of conversation data from social media.","[{'name': 'Zongcheng Ji', 'id': 2232556785}, {'name': 'Zhengdong Lu', 'id': 2514095899}, {'name': 'Hang Li', 'id': 2128739099}]"
10957333,Data-Driven Response Generation in Social Media,2011,1,,,citation,"We present a data-driven approach to generating responses to Twitter status posts, based on phrase-based Statistical Machine Translation. We find that mapping conversational stimuli onto responses is more difficult than translating between languages, due to the wider range of possible responses, the larger fraction of unaligned words/phrases, and the presence of large phrase pairs whose alignment cannot be further decomposed. After addressing these challenges, we compare approaches based on SMT and Information Retrieval in a human evaluation. We show that SMT outperforms IR on this task, and its output is preferred over actual human responses in 15% of cases. As far as we are aware, this is the first work to investigate the use of phrase-based SMT to directly translate a linguistic stimulus into an appropriate response.","[{'name': 'Alan Ritter', 'org': 'University of Washington, Seattle, WA', 'id': 2154095546}, {'name': 'Colin Cherry', 'org': 'National Research Council Canada Ottawa, Ontario', 'id': 1987215999}, {'name': 'William B. Dolan', 'org': 'Microsoft Research, Redmond, WA', 'id': 2031298526}]"
2964453327,Providing Location Information in a Ubiquitous Computing Environment.,1993,1,,,citation,,"[{'name': 'Mike Spreitzer', 'id': 2643266344}, {'name': 'Marvin Theimer', 'id': 2667704432}]"
2160170050,Context-Aware Computing Applications,1994,1,,,citation,"This paper describes systems that examine and react to an individualu0027s changing context. Such systems can promote and mediate peopleu0027s interactions with devices, computers, and other people, and they can help navigate unfamiliar places. We believe that a limited amount of information covering a personu0027s proximate environment is most important for this form of computing since the interesting part of the world around us is what we can see, hear, and touch. In this paper we define context-aware computing, and describe four catagories of context-aware applications: proximate selection, automatic contextual reconfiguration, contextual information and commands, and contex-triggered actions. Instances of these application types have been prototyped on the PARCTAB, a wireless, palm-sized computer.","[{'name': 'B. Schilit', 'org': 'Department of Computer Science, Columbia University, New York, NY, USA#TAB#', 'id': 362519894}, {'name': 'N. Adams', 'id': 2601688008}, {'name': 'R. Want', 'id': 2423577896}]"
2139392747,Mobisaic: An Information System for a Mobile Wireless Computing Environment,1994,1,,,citation,"Mobisaic is a World Wide Web information system designed to serve users in a mobile wireless computing environment. Mobisaic extends the Web by allowing documents to both refer and react to potentially changing contextual information, such as current location in the wireless network. Mobisaic relies on client side processing of HTML documents that support two new concepts: dynamic uniform resource locators (URLs) and active documents. A dynamic URL is one whose results depend upon the state of the useru0027s mobile context at the time it is resolved. An active document is one that automatically updates its contents in response to changes in a useru0027s mobile context. The paper describes the design of Mobisaic, the mechanism it uses for representing a useru0027s mobile context, and the extensions made to the syntax and function of uniform resource locators and HyperText markup language documents to support mobility.","[{'name': 'G.M. Voelker', 'org': 'Dept. of Comput. Sci. & Eng., Washington Univ., Seattle, WA, USA', 'id': 241629895}, {'name': 'B.N. Bershad', 'org': 'Dept. of Comput. Sci. & Eng., Washington Univ., Seattle, WA, USA', 'id': 1988425031}]"
2121075562,Dynamic Documents: Mobile Wireless Access to the WWW,1994,1,,,citation,"We propose dynamic documents as an approach to extending and customizing the WWW/Mosaic for mobile computing platforms. Dynamic documents are programs executed on a mobile platform to generate a document; they are implemented as Tcl scripts. We have modified the NCSA Mosaic web client to run the dynamic documents it retrieves through a modified Tcl interpreter. The interpreter is designed to execute only commands that do not violate safety. To hide the latencies of slow links we have modified the Mosaic client to perform caching and prefetching. The policies for caching and prefetching can be under control of dynamic documents, allowing the strategies to be document specific. Using dynamic documents, we have built an adaptive E mail browser that employs application specific caching and prefetching strategies. Both the browser and the displayed E mail messages are dynamically customized to the mobile computing environment in which they run.","[{'name': 'M.F. Kaashoek', 'org': 'Lab. for Comput. Sci., MIT. Cambridge, MA, USA', 'id': 2683940979}, {'name': 'T. Pinckney', 'org': 'Lab. for Comput. Sci., MIT. Cambridge, MA, USA', 'id': 2699848509}, {'name': 'J.A. Tauber', 'org': 'Lab. for Comput. Sci., MIT. Cambridge, MA, USA', 'id': 2142513814}]"
2096999549,The Design of a Human Memory Prosthesis,1994,1,,,citation,", CB2 1ABworkplace and on technological possibilities fordealing with these problems. These guidelinesdefine this new class of application, provide thebasis for our continuing work in support of theproblems of everyday office life, and offer a newchallenge for computer systems research.Key words: human memory, officesystems, memory prosthesis, informationretrieval, Personal Digital Assistant (PDA),mobile computing, distributed computing","[{'name': 'Mik Lamming', 'org': 'Rank Xerox Cambridge EuroPARC, 61 Regent Street, Cambridge CB2 1AB, UK', 'id': 2251404911}, {'name': 'Peter Brown', 'org': 'Rank Xerox Cambridge EuroPARC, 61 Regent Street, Cambridge CB2 1AB, UK', 'id': 2598795831}, {'name': 'Kathleen Carter', 'org': 'Rank Xerox Cambridge EuroPARC, 61 Regent Street, Cambridge CB2 1AB, UK', 'id': 2100661235}, {'name': 'Margery Eldridge', 'org': 'Rank Xerox Cambridge EuroPARC, 61 Regent Street, Cambridge CB2 1AB, UK', 'id': 2146455470}, {'name': 'Mike Flynn', 'org': 'Rank Xerox Cambridge EuroPARC, 61 Regent Street, Cambridge CB2 1AB, UK', 'id': 2164279596}, {'name': 'Gifford Louie', 'org': 'Rank Xerox Cambridge EuroPARC, 61 Regent Street, Cambridge CB2 1AB, UK', 'id': 2311036381}, {'name': 'Peter Robinson', 'org': 'Rank Xerox Cambridge EuroPARC, 61 Regent Street, Cambridge CB2 1AB, UK', 'id': 2990473469}, {'name': 'Abigail Sellen', 'org': 'Rank Xerox Cambridge EuroPARC, 61 Regent Street, Cambridge CB2 1AB, UK', 'id': 1985629368}]"
2094204865,The active badge location system,1992,1,,,citation,"A novel system for the location of people in an office environment is described. Members of staff wear badges that transmit signals providing information about their location to a centralized location service, through a network of sensors. The paper also examines alternative location techniques, system design issues and applications, particularly relating to telephone call routing. Location systems raise concerns about the privacy of an individual and these issues are also addressed.","[{'name': 'Roy Want', 'org': 'Olivetti Research Ltd. (ORL), England#TAB#', 'id': 2423577896}, {'name': 'Andy Hopper', 'org': 'Olivetti Research Ltd. (ORL), England#TAB#', 'id': 2161765548}, {'name': 'Veronica Falcão', 'org': 'Olivetti Research Ltd. (ORL), England#TAB#', 'id': 2223173290}, {'name': 'Jonathan Gibbons', 'org': 'Olivetti Research Ltd. (ORL), England#TAB#', 'id': 2671322643}]"
2078119328,Matching interface design with user tasks. Modalities of interaction with CMU wearable computers,1996,1,,,citation,"To maximize the effectiveness of wearable systems in mobile computing environments, interface design must be carefully matched with user tasks. By constructing mental models of user actions, interface elements may be chosen and tuned to meet the specific software and hardware requirements of specific procedures. This article details specific cases of task study and interface implementation by the Carnegie Mellon University (CMU) wearable computer project over six generations of systems. An abstract model for application interface design is given, with examples of implementation on both embedded systems and general purpose platforms. It describes the factors of human interface in wearable systems design focusing on how the application impacts the design and especially the user interface. First examined is the process of modeling specific user tasks, and establishing a linkage with the system interface that closely mirrors this model. Next is an overview of the VuMan embedded systems, followed by a description of the Navigator general-purpose machines. The article concludes with a summary of information developed through the design and testing of these wearable systems.","[{'name': 'A. Smailagic', 'org': 'Engineering Design Research Center, Carnegie Mellon University, Pittsburgh, PA, USA', 'id': 2118764631}, {'name': 'D.P. Siewiorek', 'id': 2973598084}]"
2061056631,An overview of the PARCTAB ubiquitous computing experiment,1995,1,,,citation,"The PARCTAB system integrates a palm-sized mobile computer into an office network. The PARCTAB project serves as a preliminary testbed for ubiquitous computing, a philosophy originating at Xerox PARC that aims to enrich our computing environment by emphasizing context sensitivity, casual interaction and the spatial arrangement of computers. This article describes the ubiquitous computing philosophy, the PARCTAB system, user interface issues for small devices, and our experience in developing and testing a variety of mobile applications.","[{'name': 'R. Want', 'org': 'Xerox, PARC, USA', 'id': 2423577896}, {'name': 'B.N. Schilit', 'org': 'Xerox, PARC, USA', 'id': 362519894}, {'name': 'N.I. Adams', 'org': 'Xerox, PARC, USA', 'id': 2601688008}, {'name': 'R. Gold', 'org': 'Xerox, PARC, USA', 'id': 2011717288}, {'name': 'K. Petersen', 'org': 'Xerox, PARC, USA', 'id': 2795421043}, {'name': 'D. Goldberg', 'org': 'Xerox, PARC, USA', 'id': 2618025618}, {'name': 'J.R. Ellis', 'org': 'Xerox, PARC, USA', 'id': 2668360263}, {'name': 'M. Weiser', 'org': 'Xerox, PARC, USA', 'id': 2762642306}]"
1584093612,PEPYS: generating autobiographies by automatic tracking,1991,1,,,citation,"This paper presents one part of a broad research project entitled u0027Activity-Based Information Retrievalu0027 (AIR) which is being carded out at EuroPARC. The basic hypothesis of this project is that if contextual data about human activities can be automatically captured and later presented as recognisable descriptions of past episodes, then human memory of those past episodes can be improved. This paper describes an application called Pepys, designed to yield descriptions of episodes based on automatically collected location data. The program pays particular attention to meetings and other episodes involving two or more people. The episodes are presented to the user as a diary generated at the end of each day and distributed by electronic mail. The paper also discusses the methods used to assess the accuracy of the descriptions generated by the recogniser.","[{'name': 'William M. Newman', 'org': 'Rank Xerox EuroPARC, England#TAB#', 'id': 2128949213}, {'name': 'Margery A. Eldridge', 'org': 'Rank Xerox EuroPARC, England#TAB#', 'id': 2146455470}, {'name': 'Michael G. Lamming', 'org': 'Rank Xerox EuroPARC, England#TAB#', 'id': 2081679208}]"
1526165842,An infrared network for mobile computers,1993,1,,,citation,"The infrared network provides a flexible infrastructure for research into wireless mobile computing. The network consists of a collection of room-sized cells each wired with a base station transceiver. Mobile computers communicate with transceivers through a carrier sense multiple access (CSMA) protocol and act as terminals for applications executing on remote hosts. Each mobile computer is represented by a proxy, or agent, accessible to applications at a fixed network address. In the system it is the agent that is responsible for delivering requests to its corresponding mobile computer, and tracking the mobile as it moves from cell to cell.","[{'name': 'Norman Adams', 'org': 'Palo Alto Research Center, Xerox Corporation', 'id': 2601688008}, {'name': 'Rich Gold', 'org': 'Palo Alto Research Center, Xerox Corporation', 'id': 2011717288}, {'name': 'Bill N. Schilit', 'org': 'Computer Science Dept., Columbia University', 'id': 362519894}, {'name': 'Michael M. Tso', 'org': 'EECS dept. MIT', 'id': 2145821119}, {'name': 'Roy Want', 'org': 'Palo Alto Research Center, Xerox Corporation', 'id': 2423577896}]"
2964352502,Context-Aware Sequential Recommendation,2016,1,,,citation,"Since sequential information plays an important role in modeling user behaviors, various sequential recommendation methods have been proposed. Methods based on Markov assumption are widely-used, but independently combine several most recent components. Recently, Recurrent Neural Networks (RNN) based methods have been successfully applied in several sequential modeling tasks. However, for real-world applications, these methods have difficulty in modeling the contextual information, which has been proved to be very important for behavior modeling. In this paper, we propose a novel model, named Context-Aware Recurrent Neural Networks (CA-RNN). Instead of using the constant input matrix and transition matrix in conventional RNN models, CA-RNN employs adaptive context-specific input matrices and adaptive context-specific transition matrices. The adaptive context-specific input matrices capture external situations where user behaviors happen, such as time, location, weather and so on. And the adaptive context-specific transition matrices capture how lengths of time intervals between adjacent behaviors in historical sequences affect the transition of global sequential features. Experimental results show that the proposed CA-RNN model yields significant improvements over state-of-the-art sequential recommendation methods and context-aware recommendation methods on two public datasets, i.e., the Taobao dataset and the Movielens-1M dataset.","[{'name': 'Qiang Liu', 'id': 2989406943}, {'name': 'Shu Wu', 'id': 2122580694}, {'name': 'Diyi Wang', 'id': 2522055496}, {'name': 'Zhaokang Li', 'id': 2700323474}, {'name': 'Liang Wang', 'id': 2226151461}]"
2951707557,Neural Collaborative Filtering,2017,1,,,citation,"In recent years, deep neural networks have yielded immense success on speech recognition, computer vision and natural language processing. However, the exploration of deep neural networks on recommender systems has received relatively less scrutiny. In this work, we strive to develop techniques based on neural networks to tackle the key problem in recommendation -- collaborative filtering -- on the basis of implicit feedback. Although some recent work has employed deep learning for recommendation, they primarily used it to model auxiliary information, such as textual descriptions of items and acoustic features of musics. When it comes to model the key factor in collaborative filtering -- the interaction between user and item features, they still resorted to matrix factorization and applied an inner product on the latent features of users and items. By replacing the inner product with a neural architecture that can learn an arbitrary function from data, we present a general framework named NCF, short for Neural network-based Collaborative Filtering. NCF is generic and can express and generalize matrix factorization under its framework. To supercharge NCF modelling with non-linearities, we propose to leverage a multi-layer perceptron to learn the user-item interaction function. Extensive experiments on two real-world datasets show significant improvements of our proposed NCF framework over the state-of-the-art methods. Empirical evidence shows that using deeper layers of neural networks offers better recommendation performance.","[{'name': 'Xiangnan He', 'id': 2155461083}, {'name': 'Lizi Liao', 'id': 2675087758}, {'name': 'Hanwang Zhang', 'id': 2141833608}, {'name': 'Liqiang Nie', 'id': 2151954441}, {'name': 'Xia Hu', 'id': 2161448330}, {'name': 'Tat-Seng Chua', 'id': 2160663097}]"
2951001079,DeepFM: A Factorization-Machine based Neural Network for CTR Prediction,2017,1,,,citation,"Learning sophisticated feature interactions behind user behaviors is critical in maximizing CTR for recommender systems. Despite great progress, existing methods seem to have a strong bias towards low- or high-order interactions, or require expertise feature engineering. In this paper, we show that it is possible to derive an end-to-end learning model that emphasizes both low- and high-order feature interactions. The proposed model, DeepFM, combines the power of factorization machines for recommendation and deep learning for feature learning in a new neural network architecture. Compared to the latest Wide \u0026 Deep model from Google, DeepFM has a shared input to its ""wide"" and ""deep"" parts, with no need of feature engineering besides raw features. Comprehensive experiments are conducted to demonstrate the effectiveness and efficiency of DeepFM over the existing models for CTR prediction, on both benchmark data and commercial data.","[{'name': 'Huifeng Guo', 'id': 2661230528}, {'name': 'Ruiming Tang', 'id': 2598570375}, {'name': 'Yunming Ye', 'id': 2167640884}, {'name': 'Zhenguo Li', 'id': 2142886067}, {'name': 'Xiuqiang He', 'id': 2302983537}]"
2950975304,BPR: Bayesian Personalized Ranking from Implicit Feedback,2012,1,,,citation,"Item recommendation is the task of predicting a personalized ranking on a set of items (e.g. websites, movies, products). In this paper, we investigate the most common scenario with implicit feedback (e.g. clicks, purchases). There are many methods for item recommendation from implicit feedback like matrix factorization (MF) or adaptive knearest-neighbor (kNN). Even though these methods are designed for the item prediction task of personalized ranking, none of them is directly optimized for ranking. In this paper we present a generic optimization criterion BPR-Opt for personalized ranking that is the maximum posterior estimator derived from a Bayesian analysis of the problem. We also provide a generic learning algorithm for optimizing models with respect to BPR-Opt. The learning method is based on stochastic gradient descent with bootstrap sampling. We show how to apply our method to two state-of-the-art recommender models: matrix factorization and adaptive kNN. Our experiments indicate that for the task of personalized ranking our optimization method outperforms the standard learning techniques for MF and kNN. The results show the importance of optimizing models for the right criterion.","[{'name': 'Steffen Rendle', 'id': 1585981875}, {'name': 'Christoph Freudenthaler', 'id': 2043953584}, {'name': 'Zeno Gantner', 'id': 285694533}, {'name': 'Lars Schmidt-Thieme', 'id': 78243962}]"
2950178297,"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention",2015,1,,,citation,"Inspired by recent work in machine translation and object detection, we introduce an attention based model that automatically learns to describe the content of images. We describe how we can train this model in a deterministic manner using standard backpropagation techniques and stochastically by maximizing a variational lower bound. We also show through visualization how the model is able to automatically learn to fix its gaze on salient objects while generating the corresponding words in the output sequence. We validate the use of attention with state-of-the-art performance on three benchmark datasets: Flickr8k, Flickr30k and MS COCO.","[{'name': 'Kelvin Xu', 'id': 2485834696}, {'name': 'Jimmy Ba', 'id': 2097546270}, {'name': 'Ryan Kiros', 'id': 1190321462}, {'name': 'Kyunghyun Cho', 'id': 2462121670}, {'name': 'Aaron Courville', 'id': 2328522601}, {'name': 'Ruslan Salakhutdinov', 'id': 2031945151}, {'name': 'Richard Zemel', 'id': 2149392531}, {'name': 'Yoshua Bengio', 'id': 161269817}]"
2949274928,Sequential Click Prediction for Sponsored Search with Recurrent Neural Networks,2014,1,,,citation,"Click prediction is one of the fundamental problems in sponsored search. Most of existing studies took advantage of machine learning approaches to predict ad click for each event of ad view independently. However, as observed in the real-world sponsored search system, useru0027s behaviors on ads yield high dependency on how the user behaved along with the past time, especially in terms of what queries she submitted, what ads she clicked or ignored, and how long she spent on the landing pages of clicked ads, etc. Inspired by these observations, we introduce a novel framework based on Recurrent Neural Networks (RNN). Compared to traditional methods, this framework directly models the dependency on useru0027s sequential behaviors into the click prediction process through the recurrent structure in RNN. Large scale evaluations on the click-through logs from a commercial search engine demonstrate that our approach can significantly improve the click prediction accuracy, compared to sequence-independent approaches.","[{'name': 'Yuyu Zhang', 'id': 2638183652}, {'name': 'Hanjun Dai', 'id': 2169951634}, {'name': 'Chang Xu', 'id': 2665015169}, {'name': 'Jun Feng', 'id': 2680159566}, {'name': 'Taifeng Wang', 'id': 2157154139}, {'name': 'Jiang Bian', 'id': 2609123459}, {'name': 'Bin Wang', 'id': 2690358303}, {'name': 'Tie-Yan Liu', 'id': 2108341226}]"
2889227399,Wide and Deep Model of Multi-Source Information-Aware Recommender System,2018,1,,,citation,"Collaborative filtering recommendation suffers from the problems of high data sparsity, poor expansibility, cold start, and the difficulty of modeling user preferences, among which data sparsity is the greatest issue. Although our previous work on matrix completion model, named low rank non-negative matrix factorization and completion algorithm (LR-NMFC) and stochastic sub-gradient based low rank matrix completion algorithm, could effectively alleviate the sparsity problem, they customarily model the linear feature interactions instead of the complex nonlinear structures between users and items when making recommendations. To better depict user preferences and item features, we deepen the linear model LR-NMFC to establish a wide and deep model, which we named Wide and Deep model of Multi-source information-Aware recommender system (WDMMA), based on multi-source information composed of user-item interaction matrix, attributes, and context. The wide part mainly handles the linear interactions between users and items, while the deep part portrays the high-order nonlinear interactions. We pre-train both the wide and the deep part using LR-NMFC in the embedding layer. In the pooling layer, we define a pooling operation, AC-pooling, which is used to model the various interactions among users, items, attributes, and context information. Upon the pooling layer, we stack some hidden layers to capture the high-order nonlinear feature interactions. Experiments on two public datasets show that WDMMA can learn complex nonlinear feature patterns successfully and effectively and is beneficial to improve the recommendation performance. Therefore, it is an effective way to consider both linear user-item interactions and multi-source information-aware nonlinear interactions in a deep learning framework when making recommendations.","[{'name': 'Weihua Yuan', 'org': 'School of Information Science and Engineering Shandong Normal University Jinan China', 'id': 2769931492}, {'name': 'Hong Wang', 'org': 'School of Information Science and Engineering Shandong Normal University Jinan China', 'id': 2718872510}, {'name': 'Baofang Hu', 'org': 'School of Information Science and Engineering Shandong Normal University Jinan China', 'id': 2770016731}, {'name': 'Lutong Wang', 'org': 'School of Information Science and Engineering Shandong Normal University Jinan China', 'id': 2908346269}, {'name': 'Qian Wang', 'org': 'School of Information Science and Engineering Shandong Normal University Jinan China', 'id': 2889270142}]"
2789456849,Shared-nearest-neighbor-based Clustering by Fast Search and Find of Density Peaks,2018,1,,,citation,"Abstract   Clustering by fast search and find of density peaks (DPC) is a new clustering method that was reported in Science in June 2014. This clustering algorithm is based on the assumption that cluster centers have high local densities and are generally far from each other. With a decision graph, cluster centers can be easily located. However, this approach suffers from certain disadvantages. First, the definition of the local density and distance measurement is too simple; therefore, the DPC algorithm might perform poorly on complex datasets that are of multiple scales, cross-winding, of various densities, or of high dimensionality. Second, the one-step allocation strategy is not robust and has poor fault tolerance. Thus, if a point is assigned incorrectly, then the subsequent allocation will further amplify the error, resulting in more errors, which will have a severe negative impact on the clustering results. Third, the cutoff distance  d c   is generally difficult to determine since the range of each attribute is unknown in most cases. Even when being normalized or using the relative percentage method, a small change in  d c   will still cause a conspicuous fluctuation in the result, and this is especially true for real-world datasets. Considering these drawbacks, we propose a shared-nearest-neighbor-based clustering by fast search and find of density peaks (SNN-DPC) algorithm. We present three new definitions: SNN similarity, local density  ρ  and distance from the nearest larger density point  δ . These definitions take the information of the nearest neighbors and the shared neighbors into account, and they can self-adapt to the local surroundings. Then, we introduce our two-step allocation method: inevitably subordinate and possibly subordinate. The former quickly and accurately recognizes and allocates the points that certainly belong to one cluster by counting the number of shared neighbors between two points. The latter assigns the remaining points by finding the clusters to which more neighbors belong. The algorithm is benchmarked on publicly available synthetic datasets, UCI real-world datasets and the Olivetti Faces dataset, which are often used to test the performance of clustering algorithms. We compared the results with those of DPC, fuzzy weighted K-nearest neighbors density peak clustering (FKNN-DPC), affinity propagation (AP), ordering points to identify the clustering structure (OPTICS), density-based spatial clustering of applications with noise (DBSCAN), and K-means. The metrics used are adjusted mutual information (AMI), adjusted Rand index (ARI), and Fowlkes–Mallows index (FMI). The experimental results prove that our method can recognize clusters regardless of their size, shape, and dimensions; is robust to noise; and is remarkably superior to DPC, FKNN-DPC, AP, OPTICS, DBSCAN, and K-means.","[{'name': 'Rui Liu', 'org': 'School of Information Science and Engineering, Shandong Normal University, Jinan, Shandong 250358, China', 'id': 2792789126}, {'name': 'Hong Wang', 'org': 'School of Information Science and Engineering, Shandong Normal University, Jinan, Shandong 250358, China', 'id': 2793391160}, {'name': 'Xiaomei Yu', 'org': 'School of Information Science and Engineering, Shandong Normal University, Jinan, Shandong 250358, China', 'id': 2793905068}]"
2779616106,Leveraging Long and Short-term Information in Content-aware Movie Recommendation.,2017,1,,,citation,"Movie recommendation systems provide users with ranked lists of movies based on individualu0027s preferences and constraints. Two types of models are commonly used to generate ranking results: long-term models and session-based models. While long-term models represent the interactions between users and movies that are supposed to change slowly across time, session-based models encode the information of usersu0027 interests and changing dynamics of moviesu0027 attributes in short terms. In this paper, we propose an LSIC model, leveraging Long and Short-term Information in Content-aware movie recommendation using adversarial training. In the adversarial process, we train a generator as an agent of reinforcement learning which recommends the next movie to a user sequentially. We also train a discriminator which attempts to distinguish the generated list of movies from the real records. The poster information of movies is integrated to further improve the performance of movie recommendation, which is specifically essential when few ratings are available. The experiments demonstrate that the proposed model has robust superiority over competitors and sets the state-of-the-art. We will release the source code of this work after publication.","[{'name': 'Wei Zhao', 'id': 2741507603}, {'name': 'Benyou Wang', 'id': 2231501501}, {'name': 'Jianbo Ye', 'id': 2128333061}, {'name': 'Yongqiang Gao', 'id': 2780564487}, {'name': 'Min Yang', 'id': 2798240726}, {'name': 'Zhou Zhao', 'id': 2118299058}, {'name': 'Xiaojun Chen', 'id': 2891911005}]"
2770326696,Sparse network embedding for community detection and sign prediction in signed social networks,2019,1,,,citation,"Network embedding is an important pre-process for analysing large scale information networks. Several network embedding algorithms have been proposed for unsigned social networks. However, these methods cannot be simply migrate to signed social networks which have both positive and negative relationships. In this paper, we present our signed social network embedding model which is based on the word embedding model. To deal with two kinds of links, we define two relationships: neighbour relationship and common neighbour relationship, as well as design a bias random walk procedure. In order to further improve interpretation of the representation vectors, the follow-proximally-regularized-leader online learning algorithm is introduced to the traditional word embedding framework to acquire sparse representations. Extensive experiments were carried out to compare our algorithm with three state-of-the-art methods for community detection and sign prediction tasks. The experimental results demonstrate that our algorithm performs better than the comparison algorithms on most signed social networks.","[{'name': 'Baofang Hu', 'org': 'Shandong\xa0Women`s\xa0University', 'id': 2770016731}, {'name': 'Hong Wang', 'org': 'Shandong Normal University', 'id': 2718872510}, {'name': 'Xiaomei Yu', 'org': 'Shandong Normal University', 'id': 2770551552}, {'name': 'Weihua Yuan', 'org': 'Shandong Normal University', 'id': 2769931492}, {'name': 'Tianwen He', 'org': 'Shandong Normal University', 'id': 2769836885}]"
2741249238,Attentive Collaborative Filtering: Multimedia Recommendation with Item- and Component-Level Attention,2017,1,,,citation,"Multimedia content is dominating todayu0027s Web information. The nature of multimedia user-item interactions is 1/0 binary implicit feedback (e.g., photo likes, video views, song downloads, etc.), which can be collected at a larger scale with a much lower cost than explicit feedback (e.g., product ratings). However, the majority of existing collaborative filtering (CF) systems are not well-designed for multimedia recommendation, since they ignore the implicitness in usersu0027 interactions with multimedia content. We argue that, in multimedia recommendation, there exists item- and component-level implicitness which blurs the underlying usersu0027 preferences. The item-level implicitness means that usersu0027 preferences on items (e.g. photos, videos, songs, etc.) are unknown, while the component-level implicitness means that inside each item usersu0027 preferences on different components (e.g. regions in an image, frames of a video, etc.) are unknown. For example, a u0027viewu0027u0027 on a video does not provide any specific information about how the user likes the video (i.e.item-level) and which parts of the video the user is interested in (i.e.component-level). In this paper, we introduce a novel attention mechanism in CF to address the challenging item- and component-level implicit feedback in multimedia recommendation, dubbed Attentive Collaborative Filtering (ACF). Specifically, our attention model is a neural network that consists of two attention modules: the component-level attention module, starting from any content feature extraction network (e.g. CNN for images/videos), which learns to select informative components of multimedia items, and the item-level attention module, which learns to score the item preferences. ACF can be seamlessly incorporated into classic CF models with implicit feedback, such as BPR and SVD++, and efficiently trained using SGD. Through extensive experiments on two real-world multimedia Web services: Vine and Pinterest, we show that ACF significantly outperforms state-of-the-art CF methods.","[{'name': 'Jingyuan Chen', 'org': 'National University of Singapore, Singapore, Singapore', 'id': 2535028075}, {'name': 'Hanwang Zhang', 'org': 'Columbia University. New York, NY, USA', 'id': 2141833608}, {'name': 'Xiangnan He', 'org': 'National University of Singapore, Singapore, Singapore', 'id': 2155461083}, {'name': 'Liqiang Nie', 'org': 'Shandong University, Jinan,  China', 'id': 2151954441}, {'name': 'Wei Liu', 'org': 'Tencent AI Lab, Shenzhen, China', 'id': 2182080890}, {'name': 'Tat-Seng Chua', 'org': 'National University of Singapore, Singapore, Singapore', 'id': 2160663097}]"
2740885325,Attentional Factorization Machines: Learning the Weight of Feature Interactions via Attention Networks,2017,1,,,citation,"Factorization Machines (FMs) are a supervised learning approach that enhances the linear regression model by incorporating the second-order feature interactions. Despite effectiveness, FM can be hindered by its modelling of all feature interactions with the same weight, as not all feature interactions are equally useful and predictive. For example, the interactions with useless features may even introduce noises and adversely degrade the performance. In this work, we improve FM by discriminating the importance of different feature interactions. We propose a novel model named Attentional Factorization Machine (AFM), which learns the importance of each feature interaction from data via a neural attention network. Extensive experiments on two real-world datasets demonstrate the effectiveness of AFM. Empirically, it is shown on regression task AFM betters FM with a $8.6\%$ relative improvement, and consistently outperforms the state-of-the-art deep learning methods Wideu0026Deep and DeepCross with a much simpler structure and fewer model parameters. Our implementation of AFM is publicly available at: this https URL","[{'name': 'Jun Xiao', 'id': 2309571964}, {'name': 'Hao Ye', 'id': 2746096226}, {'name': 'Xiangnan He', 'id': 2155461083}, {'name': 'Hanwang Zhang', 'id': 2141833608}, {'name': 'Fei Wu', 'id': 2266924332}, {'name': 'Tat-Seng Chua', 'id': 2160663097}]"
2739273093,Deep Learning Based Recommender System: A Survey and New Perspectives,2019,1,,,citation,"With the growing volume of online information, recommender systems have been an effective strategy to overcome information overload. The utility of recommender systems cannot be overstated, given their widespread adoption in many web applications, along with their potential impact to ameliorate many problems related to over-choice. In recent years, deep learning has garnered considerable interest in many research fields such as computer vision and natural language processing, owing not only to stellar performance but also to the attractive property of learning feature representations from scratch. The influence of deep learning is also pervasive, recently demonstrating its effectiveness when applied to information retrieval and recommender systems research. The field of deep learning in recommender system is flourishing. This article aims to provide a comprehensive review of recent research efforts on deep learning-based recommender systems. More concretely, we provide and devise a taxonomy of deep learning-based recommendation models, along with a comprehensive summary of the state of the art. Finally, we expand on current trends and provide new perspectives pertaining to this new and exciting development of the field.","[{'name': 'Shuai Zhang', 'org': 'University of New South Wales, CSE, UNSW, Sydney, Australia', 'id': 2625417909}, {'name': 'Lina Yao', 'org': 'University of New South Wales, CSE, UNSW, Sydney, Australia', 'id': 2223456168}, {'name': 'Aixin Sun', 'org': 'Nanyang Technological University Nanyang Avenue, Singapore', 'id': 2124989948}, {'name': 'Yi Tay', 'org': 'Nanyang Technological University Nanyang Avenue, Singapore', 'id': 2738935859}]"
2583674722,Recurrent Recommender Networks,2017,1,,,citation,"Recommender systems traditionally assume that user profiles and movie attributes are static. Temporal dynamics are purely reactive, that is, they are inferred after they are observed, e.g. after a useru0027s taste has changed or based on hand-engineered temporal bias corrections for movies. We propose Recurrent Recommender Networks (RRN) that are able to predict future behavioral trajectories. This is achieved by endowing both users and movies with a Long Short-Term Memory (LSTM) autoregressive model that captures dynamics, in addition to a more traditional low-rank factorization. On multiple real-world datasets, our model offers excellent prediction accuracy and it is very compact, since we need not learn latent state but rather just the state transition function.","[{'name': 'Chao-Yuan Wu', 'org': 'University of Texas at Austin, Austin, TX, USA#TAB#', 'id': 2538604194}, {'name': 'Amr Ahmed', 'org': 'Google, Mountain View, CA, USA.', 'id': 2259645355}, {'name': 'Alex Beutel', 'org': 'Google, Mountain View, CA, USA.', 'id': 2045447989}, {'name': 'Alexander J. Smola', 'org': 'Carnegie-Mellon Univ., Pittsburgh, PA, USA', 'id': 1972291593}, {'name': 'How Jing', 'org': 'LinkedIn, Mountain View, CA, USA#TAB#', 'id': 2592724704}]"
2548570154,Product-Based Neural Networks for User Response Prediction,2016,1,,,citation,"Predicting user responses, such as clicks and conversions, is of great importance and has found its usage inmany Web applications including recommender systems, websearch and online advertising. The data in those applicationsis mostly categorical and contains multiple fields, a typicalrepresentation is to transform it into a high-dimensional sparsebinary feature representation via one-hot encoding. Facing withthe extreme sparsity, traditional models may limit their capacityof mining shallow patterns from the data, i.e. low-order featurecombinations. Deep models like deep neural networks, on theother hand, cannot be directly applied for the high-dimensionalinput because of the huge feature space. In this paper, we proposea Product-based Neural Networks (PNN) with an embeddinglayer to learn a distributed representation of the categorical data, a product layer to capture interactive patterns between interfieldcategories, and further fully connected layers to explorehigh-order feature interactions. Our experimental results on twolarge-scale real-world ad click datasets demonstrate that PNNsconsistently outperform the state-of-the-art models on various metrics.","[{'name': 'Yanru Qu', 'id': 2633427306}, {'name': 'Han Cai', 'id': 2584166797}, {'name': 'Kan Ren', 'id': 2277084468}, {'name': 'Weinan Zhang', 'id': 2527611484}, {'name': 'Yong Yu', 'id': 2119244895}, {'name': 'Ying Wen', 'id': 2701415101}, {'name': 'Jun Wang', 'id': 2936723753}]"
2467173223,Abstractive Sentence Summarization with Attentive Recurrent Neural Networks,2016,1,,,citation,,"[{'name': 'Sumit Chopra', 'id': 2620976108}, {'name': 'Michael Auli', 'id': 2139710560}, {'name': 'Alexander M. Rush', 'id': 2701382563}]"
2295739661,Factorization Machines,2010,1,,,citation,"In this paper, we introduce Factorization Machines (FM) which are a new model class that combines the advantages of Support Vector Machines (SVM) with factorization models. Like SVMs, FMs are a general predictor working with any real valued feature vector. In contrast to SVMs, FMs model all interactions between variables using factorized parameters. Thus they are able to estimate interactions even in problems with huge sparsity (like recommender systems) where SVMs fail. We show that the model equation of FMs can be calculated in linear time and thus FMs can be optimized directly. So unlike nonlinear SVMs, a transformation in the dual form is not necessary and the model parameters can be estimated directly without the need of any support vector in the solution. We show the relationship to SVMs and the advantages of FMs for parameter estimation in sparse settings. On the other hand there are many different factorization models like matrix factorization, parallel factor analysis or specialized models like SVD++, PITF or FPMC. The drawback of these models is that they are not applicable for general prediction tasks but work only with special input data. Furthermore their model equations and optimization algorithms are derived individually for each task. We show that FMs can mimic these models just by specifying the input data (i.e. the feature vectors). This makes FMs easily applicable even for users without expert knowledge in factorization models.","[{'name': 'Steffen Rendle', 'id': 1585981875}]"
2288597091,Deep Learning over Multi-field Categorical Data: A Case Study on User Response Prediction,2016,1,,,citation,"Predicting user responses, such as click-through rate and conversion rate, are critical in many web applications including web search, personalised recommendation, and online advertising. Different from continuous raw features that we usually found in the image and audio domains, the input features in web space are always of multi-field and are mostly discrete and categorical while their dependencies are little known. Major user response prediction models have to either limit themselves to linear models or require manually building up high-order combination features. The former loses the ability of exploring feature interactions, while the latter results in a heavy computation in the large feature space. To tackle the issue, we propose two novel models using deep neural networks (DNNs) to automatically learn effective patterns from categorical feature interactions and make predictions of usersu0027 ad clicks. To get our DNNs efficiently work, we propose to leverage three feature transformation methods, i.e., factorisation machines (FMs), restricted Boltzmann machines (RBMs) and denoising auto-encoders (DAEs). This paper presents the structure of our models and their efficient training algorithms. The large-scale experiments with real-world data demonstrate that our methods work better than major state-of-the-art models.","[{'name': 'Weinan Zhang', 'id': 2527611484}, {'name': 'Tianming Du', 'id': 2626929240}, {'name': 'Jun Wang', 'id': 2936723753}]"
2171279286,Factorizing personalized Markov chains for next-basket recommendation,2010,1,,,citation,"Recommender systems are an important component of many websites. Two of the most popular approaches are based on matrix factorization (MF) and Markov chains (MC). MF methods learn the general taste of a user by factorizing the matrix over observed user-item preferences. On the other hand, MC methods model sequential behavior by learning a transition graph over items that is used to predict the next action based on the recent actions of a user. In this paper, we present a method bringing both approaches together. Our method is based on personalized transition graphs over underlying Markov chains. That means for each user an own transition matrix is learned - thus in total the method uses a transition cube. As the observations for estimating the transitions are usually very limited, our method factorizes the transition cube with a pairwise interaction model which is a special case of the Tucker Decomposition. We show that our factorized personalized MC (FPMC) model subsumes both a common Markov chain and the normal matrix factorization model. For learning the model parameters, we introduce an adaption of the Bayesian Personalized Ranking (BPR) framework for sequential basket data. Empirically, we show that our FPMC model outperforms both the common matrix factorization and the unpersonalized MC model both learned with and without factorization.","[{'name': 'Steffen Rendle', 'org': 'The Institute of Scientific and Industrial Research Osaka University Osaka, Japan', 'id': 1585981875}, {'name': 'Christoph Freudenthaler', 'org': 'Institute for Computer Science University of Hildesheim, Hildesheim, Germany', 'id': 2043953584}, {'name': 'Lars Schmidt-Thieme', 'org': 'Institute for Computer Science University of Hildesheim, Hildesheim, Germany', 'id': 78243962}]"
2159155347,Temporal diversity in recommender systems,2010,1,,,citation,"Collaborative Filtering (CF) algorithms, used to build web-based recommender systems, are often evaluated in terms of how accurately they predict user ratings. However, current evaluation techniques disregard the fact that users continue to rate items over time: the temporal characteristics of the systemu0027s top-N recommendations are not investigated. In particular, there is no means of measuring the extent that the same items are being recommended to users over and over again. In this work, we show that temporal diversity is an important facet of recommender systems, by showing how CF data changes over time and performing a user survey. We then evaluate three CF algorithms from the point of view of the diversity in the sequence of recommendation lists they produce over time. We examine how a number of characteristics of user rating patterns (including profile size and time between rating) affect diversity. We then propose and evaluate set methods that maximise temporal recommendation diversity without extensively penalising accuracy.","[{'name': 'Neal Lathia', 'org': 'University College London \xa0London, United Kingdom', 'id': 2023330040}, {'name': 'Stephen Hailes', 'org': 'University College London \xa0London, United Kingdom', 'id': 2051689263}, {'name': 'Licia Capra', 'org': 'University College London \xa0London, United Kingdom', 'id': 2105995467}, {'name': 'Xavier Amatriain', 'org': 'Telefonica Research; Barcelona, Spain', 'id': 2570462777}]"
2158515176,Methods and metrics for cold-start recommendations,2002,1,,,citation,"We have developed a method for recommending items that combines content and collaborative data under a single probabilistic framework. We benchmark our algorithm against a naive Bayes classifier on the  cold-start problem, where we wish to recommend items that no one in the community has yet rated. We systematically explore three testing methodologies using a publicly available data set, and explain how these methods apply to specific real-world applications. We advocate heuristic recommenders when benchmarking to give competent baseline performance. We introduce a new performance metric, the CROC curve, and demonstrate empirically that the various components of our testing strategy combine to obtain deeper understanding of the performance characteristics of recommender systems. Though the emphasis of our testing is on cold-start recommending, our methods for recommending and evaluation are general.","[{'name': 'Andrew I. Schein', 'org': '#N##TAB##TAB##TAB##TAB# University of Pennsylvania, Philadelphia, PA#N##TAB##TAB##TAB#', 'id': 2086932039}, {'name': 'Alexandrin Popescul', 'org': '#N##TAB##TAB##TAB##TAB# University of Pennsylvania, Philadelphia, PA#N##TAB##TAB##TAB#', 'id': 2050399472}, {'name': 'Lyle H. Ungar', 'org': '#N##TAB##TAB##TAB##TAB# University of Pennsylvania, Philadelphia, PA#N##TAB##TAB##TAB#', 'id': 2147282416}, {'name': 'David M. Pennock', 'org': 'NEC Research Institute Princeton, NJ', 'id': 2303646384}]"
2157331557,Learning Phrase Representations using RNN Encoder--Decoder for Statistical Machine Translation,2014,1,,,citation,"In this paper, we propose a novel neural network model called RNN Encoder‐ Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixedlength vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder‐Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.","[{'name': 'Kyunghyun Cho', 'id': 2462121670}, {'name': 'Bart van Merrienboer', 'id': 256273151}, {'name': 'Caglar Gulcehre', 'id': 152899538}, {'name': 'Dzmitry Bahdanau', 'org': ""Laboratoire d'Informatique de l'Université du Maine"", 'id': 2509101809}, {'name': 'Fethi Bougares', 'org': ""Laboratoire d'Informatique de l'Université du Maine"", 'id': 184786478}, {'name': 'Holger Schwenk', 'org': ""Laboratoire d'Informatique de l'Université du Maine"", 'id': 2160549261}, {'name': 'Yoshua Bengio', 'org': 'Alcatel-Lucent,', 'id': 161269817}]"
2138857742,Why Does Unsupervised Pre-training Help Deep Learning?,2010,1,,,citation,"Much recent research has been devoted to learning algorithms for deep architectures such as Deep Belief Networks and stacks of auto-encoder variants, with impressive results obtained in several areas, mostly on vision and language data sets. The best results obtained on supervised learning tasks involve an unsupervised learning component, usually in an unsupervised pre-training phase. Even though these new algorithms have enabled training deep models, many questions remain as to the nature of this difficult learning problem. The main question investigated here is the following: how does unsupervised pre-training work? Answering this questions is important if learning in deep architectures is to be further improved. We propose several explanatory hypotheses and test them through extensive simulations. We empirically show the influence of pre-training with respect to architecture depth, model capacity, and number of training examples. The experiments confirm and clarify the advantage of unsupervised pre-training. The results suggest that unsupervised pre-training guides the learning towards basins of attraction of minima that support better generalization from the training data set; the evidence from these results supports a regularization explanation for the effect of pre-training.","[{'name': 'Dumitru Erhan', 'org': 'Université de Montréal,', 'id': 2308824398}, {'name': 'Yoshua Bengio', 'org': 'Université de Montréal,', 'id': 161269817}, {'name': 'Aaron Courville', 'org': 'Université de Montréal,', 'id': 2328522601}, {'name': 'Pierre-Antoine Manzagol', 'org': 'Université de Montréal,', 'id': 278754694}, {'name': 'Pascal Vincent', 'org': 'Université de Montréal,', 'id': 2397241174}, {'name': 'Samy Bengio', 'org': 'GOOGLE', 'id': 2016539005}]"
2137245235,Probabilistic Matrix Factorization,2007,1,,,citation,"Many existing approaches to collaborative filtering can neither handle very large datasets nor easily deal with users who have very few ratings. In this paper we present the Probabilistic Matrix Factorization (PMF) model which scales linearly with the number of observations and, more importantly, performs well on the large, sparse, and very imbalanced Netflix dataset. We further extend the PMF model to include an adaptive prior on the model parameters and show how the model capacity can be controlled automatically. Finally, we introduce a constrained version of the PMF model that is based on the assumption that users who have rated similar sets of movies are likely to have similar preferences. The resulting model is able to generalize considerably better for users with very few ratings. When the predictions of multiple PMF models are linearly combined with the predictions of Restricted Boltzmann Machines models, we achieve an error rate of 0.8861, that is nearly 7% better than the score of Netflixu0027s own system.","[{'name': 'Andriy Mnih', 'org': 'Department of Computer Science, University of Toronto, Canada', 'id': 223511343}, {'name': 'Ruslan R Salakhutdinov', 'org': 'University of Toronto,#TAB#', 'id': 2031945151}]"
2124187902,One-Class Collaborative Filtering,2008,1,,,citation,"Many applications of collaborative filtering (CF), such as news item recommendation and bookmark recommendation, are most naturally thought of as one-class collaborative filtering (OCCF) problems. In these problems, the training data usually consist simply of binary data reflecting a useru0027s action or inaction, such as page visitation in the case of news item recommendation or webpage bookmarking in the bookmarking scenario. Usually this kind of data are extremely sparse (a small fraction are positive examples), therefore ambiguity arises in the interpretation of the non-positive examples. Negative examples and unlabeled positive examples are mixed together and we are typically unable to distinguish them. For example, we cannot really attribute a user not bookmarking a page to a lack of interest or lack of awareness of the page. Previous research addressing this one-class problem only considered it as a classification task. In this paper, we consider the one-class problem under the CF setting. We propose two frameworks to tackle OCCF. One is based on weighted low rank approximation; the other is based on negative example sampling. The experimental results show that our approaches significantly outperform the baselines.","[{'name': 'Rong Pan', 'org': 'HP Lab, Palo Alto, CA', 'id': 2194641296}, {'name': 'Yunhong Zhou', 'org': 'Rocket Fuel Inc., Redwood Shores, CA', 'id': 2155061604}, {'name': 'Bin Cao', 'org': 'Hong Kong University of Science and Technology, Kowloon', 'id': 2606635942}, {'name': 'N.N. Liu', 'org': 'Hong Kong University of Science and Technology, Kowloon', 'id': 2130611317}, {'name': 'R. Lukose', 'org': 'HP Lab, Palo Alto, CA', 'id': 2087782347}, {'name': 'M. Scholz', 'org': 'HP Lab, Palo Alto, CA', 'id': 2634377749}, {'name': 'Qiang Yang', 'org': 'Hong Kong University of Science and Technology, Kowloon', 'id': 2109031554}]"
2108920354,FISM: factored item similarity models for top-N recommender systems,2013,1,,,citation,"The effectiveness of existing top-N recommendation methods decreases as the sparsity of the datasets increases. To alleviate this problem, we present an item-based method for generating top-N recommendations that learns the item-item similarity matrix as the product of two low dimensional latent factor matrices. These matrices are learned using a structural equation modeling approach, wherein the value being estimated is not used for its own estimation. A comprehensive set of experiments on multiple datasets at three different sparsity levels indicate that the proposed methods can handle sparse datasets effectively and outperforms other state-of-the-art top-N recommendation methods. The experimental results also show that the relative performance gains compared to competing methods increase as the data gets sparser.","[{'name': 'Santosh Kabbur', 'org': 'University of Minnesota Minneapolis, MN USA', 'id': 2060234691}, {'name': 'Xia Ning', 'org': 'NEC Labs., America, Princeton, NJ, USA', 'id': 2151954795}, {'name': 'George Karypis', 'org': 'University of Minnesota Minneapolis, MN USA', 'id': 219814910}]"
2101409192,Collaborative Filtering for Implicit Feedback Datasets,2008,1,,,citation,"A common task of recommender systems is to improve customer experience through personalized recommendations based on prior implicit feedback. These systems passively track different sorts of user behavior, such as purchase history, watching habits and browsing activity, in order to model user preferences. Unlike the much more extensively researched explicit feedback, we do not have any direct input from the users regarding their preferences. In particular, we lack substantial evidence on which products consumer dislike. In this work we identify unique properties of implicit feedback datasets. We propose treating the data as indication of positive and negative preference associated with vastly varying confidence levels. This leads to a factor model which is especially tailored for implicit feedback recommenders. We also suggest a scalable optimization procedure, which scales linearly with the data size. The algorithm is used successfully within a recommender system for television shows. It compares favorably with well tuned implementations of other known methods. In addition, we offer a novel way to give explanations to recommendations given by this factor model.","[{'name': 'Yifan Hu', 'org': 'AT&T Labs, Florham Park, NJ#TAB#', 'id': 2145280021}, {'name': 'Y. Koren', 'org': 'Yahoo! Res., Haifa', 'id': 2781213378}, {'name': 'C. Volinsky', 'org': 'AT&T Labs, Florham Park, NJ#TAB#', 'id': 130248871}]"
2080320419,Collaborative filtering with temporal dynamics,2009,1,,,citation,"Customer preferences for products are drifting over time. Product perception and popularity are constantly changing as new selection emerges. Similarly, customer inclinations are evolving, leading them to ever redefine their taste. Thus, modeling temporal dynamics should be a key when designing recommender systems or general customer preference models. However, this raises unique challenges. Within the eco-system intersecting multiple products and customers, many different characteristics are shifting simultaneously, while many of them influence each other and often those shifts are delicate and associated with a few data instances. This distinguishes the problem from concept drift explorations, where mostly a single concept is tracked. Classical time-window or instance-decay approaches cannot work, as they lose too much signal when discarding data instances. A more sensitive approach is required, which can make better distinctions between transient effects and long term patterns. The paradigm we offer is creating a model tracking the time changing behavior throughout the life span of the data. This allows us to exploit the relevant components of all data instances, while discarding only what is modeled as being irrelevant. Accordingly, we revamp two leading collaborative filtering recommendation approaches. Evaluation is made on a large movie rating dataset by Netflix. Results are encouraging and better than those previously reported on this dataset.","[{'name': 'Yehuda Koren', 'org': 'Yahoo research, Haifa, Israel', 'id': 2781213378}]"
2042281163,Item-based collaborative filtering recommendation algorithms,2001,1,,,citation,"Recommender systems apply knowledge discovery techniques to the problem of making personalized recommendations for information, products or services during a live interaction. These systems, especially the k-nearest neighbor collaborative ltering based ones, are achieving widespread success on the Web. The tremendous growth in the amount of available information and the number of visitors to Web sites in recent years poses some key challenges for recommender systems. These are: producing high quality recommendations, performing many recommendations per second for millions of users and items and achieving high coverage in the face of data sparsity. In traditional collaborative ltering systems the amount of work increases with the number of participants in the system. New recommender system technologies are needed that can quickly produce high quality recommendations, even for very large-scale problems. To address these issues we have explored item-based collaborative ltering techniques. Item-based techniques rst analyze the user-item matrix to identify relationships between di erent items, and then use these relationships to indirectly compute recommendations for users. In this paper we analyze di erent item-based recommendation generation algorithms. We look into di erent techniques for computing item-item similarities (e.g., item-item correlation vs. cosine similarities between item vectors) and di erent techniques for obtaining recommendations from them (e.g., weighted sum vs. regression model). Finally, we experimentally evaluate our results and compare them to the basic k-nearest neighbor approach. Our experiments suggest that item-based algorithms provide dramatically better performance than user-based algorithms, while at the same time providing better quality than the best available userbased algorithms.","[{'name': 'Badrul Sarwar', 'org': 'GroupLens Research Group / Army HPC Research Center, Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN#TAB#', 'id': 2124832546}, {'name': 'George Karypis', 'org': 'GroupLens Research Group / Army HPC Research Center, Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN#TAB#', 'id': 219814910}, {'name': 'Joseph Konstan', 'org': 'GroupLens Research Group / Army HPC Research Center, Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN#TAB#', 'id': 2002483998}, {'name': 'John Riedl', 'org': 'GroupLens Research Group / Army HPC Research Center, Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN#TAB#', 'id': 1986422195}]"
2039899121,VideoReach: an online video recommendation system,2007,1,,,citation,"This paper presents a novel online video recommendation system called VideoReach, which alleviates usersu0027 efforts on finding the most relevant videos according to current viewings without a sufficient collection of user profiles as required in traditional recommenders. In this system, video recommendation is formulated as finding a list of relevant videos in terms of multimodal relevance (i.e. textual, visual, and aural relevance) and user click-through. Since different videos have different intra-weights of relevance within an individual modality and inter-weights among different modalities, we adopt relevance feedback to automatically find optimal weights by user click-though, as well as an attention fusion function to fuse multimodal relevance. We use 20 clips as the representative test videos, which are searched by top 10 queries from more than 13k online videos, and report superior performance compared with an existing video site.","[{'name': 'Tao Mei', 'org': 'Microsoft Res., Asia, Beijing, China', 'id': 2039801083}, {'name': 'Bo Yang', 'org': 'Tsinghua University; Beijing China', 'id': 2639985647}, {'name': 'Xian-Sheng Hua', 'org': 'Microsoft Res., Asia, Beijing, China', 'id': 2165599877}, {'name': 'Linjun Yang', 'org': 'Microsoft Res., Asia, Beijing, China', 'id': 2097638213}, {'name': 'Shi-Qiang Yang', 'org': 'Tsinghua University; Beijing China', 'id': 2127183023}, {'name': 'Shipeng Li', 'org': 'Microsoft Res., Asia, Beijing, China', 'id': 2142168775}]"
1995343386,One of a Kind: User Profiling by Social Curation,2014,1,,,citation,"Social Curation Service (SCS) is a new type of emerging social media platform, where users can select, organize and keep track of multimedia contents they like. In this paper, we take advantage of this great opportunity and target at the very starting point in social media: user profiling, which supports fundamental applications such as personalized search and recommendation. As compared to other profiling methods in conventional Social Network Services (SNS), our work benefits from the two distinguishable characteristics of SCS: a) organized multimedia user-generated contents, and b) content-centric social network. Based on these two characteristics, we are able to deploy the state-of-the-art multimedia analysis techniques to establish content-based user profiles by extracting user preferences and their social relations. First, we automatically construct a content-based user preference ontology and learn the ontological models to generate comprehensive user profiles. In particular, we propose a new deep learning strategy called multi-task convolutional neural network (mtCNN) to learn profile models and profile-related visual features simultaneously. Second, we propose to model the multi-level social relations offered by SCS to refine the user profiles in a low-rank recovery framework. To the best of our knowledge, our work is the first that explores how social curation can help in content-based social media technologies, taking user profiling as an example. Extensive experiments on 1,293 users and 1.5 million images collected from Pinterest in fashion domain demonstrate that recommendation methods based on the proposed user profiles are considerably more effective than other state-of-the-art recommendation strategies.","[{'name': 'Xue Geng', 'org': 'National University of Singapore, Singapore, Singapore', 'id': 2141712068}, {'name': 'Hanwang Zhang', 'org': 'National University of Singapore, Singapore, Singapore', 'id': 2141833608}, {'name': 'Zheng Song', 'org': 'Visenze Pte. Ltd, Singapore, Singapore', 'id': 2238331463}, {'name': 'Yang Yang', 'org': 'Univ. of Electronic Science and Technology of China, Chengdu, China#TAB#', 'id': 2673033531}, {'name': 'Huanbo Luan', 'org': 'National University of Singapore, Sinagpore, Singapore#TAB#', 'id': 2635811833}, {'name': 'Tat-Seng Chua', 'org': 'National University of Singapore, Sinagpore, Singapore#TAB#', 'id': 2160663097}]"
1994389483,Factorization meets the neighborhood: a multifaceted collaborative filtering model,2008,1,,,citation,"Recommender systems provide users with personalized suggestions for products or services. These systems often rely on Collaborating Filtering (CF), where past transactions are analyzed in order to establish connections between users and products. The two more successful approaches to CF are latent factor models, which directly profile both users and products, and neighborhood models, which analyze similarities between products or users. In this work we introduce some innovations to both approaches. The factor and neighborhood models can now be smoothly merged, thereby building a more accurate combined model. Further accuracy improvements are achieved by extending the models to exploit both explicit and implicit feedback by the users. The methods are tested on the Netflix data. Results are better than those previously published on that dataset. In addition, we suggest a new evaluation metric, which highlights the differences among methods, based on their performance at a top-K recommendation task.","[{'name': 'Yehuda Koren', 'org': 'AT&T, Florham Park, NJ, USA', 'id': 2781213378}]"
1989318262,Playlist prediction via metric embedding,2012,1,,,citation,"Digital storage of personal music collections and cloud-based music services (e.g. Pandora, Spotify) have fundamentally changed how music is consumed. In particular, automatically generated playlists have become an important mode of accessing large music collections. The key goal of automated playlist generation is to provide the user with a coherent listening experience. In this paper, we present Latent Markov Embedding (LME), a machine learning algorithm for generating such playlists. In analogy to matrix factorization methods for collaborative filtering, the algorithm does not require songs to be described by features a priori, but it learns a representation from example playlists. We formulate this problem as a regularized maximum-likelihood embedding of Markov chains in Euclidian space, and show how the resulting optimization problem can be solved efficiently. An empirical evaluation shows that the LME is substantially more accurate than adaptations of smoothed n-gram models commonly used in natural language processing.","[{'name': 'Shuo Chen', 'org': 'Cornell University, Ithaca, ny, USA,', 'id': 2695358889}, {'name': 'Josh L. Moore', 'org': 'Cornell University, Ithaca, ny, USA,', 'id': 2974615033}, {'name': 'Douglas Turnbull', 'org': 'Ithaca College,Ithaca, NY, USA', 'id': 2227091269}, {'name': 'Thorsten Joachims', 'org': 'Cornell University, Ithaca, ny, USA,', 'id': 245171893}]"
1985854669,Learning Hierarchical Representation Model for NextBasket Recommendation,2015,1,,,citation,"Next basket recommendation is a crucial task in market basket analysis. Given a useru0027s purchase history, usually a sequence of transaction data, one attempts to build a recommender that can predict the next few items that the user most probably would like. Ideally, a good recommender should be able to explore the sequential behavior (i.e., buying one item leads to buying another next), as well as account for usersu0027 general taste (i.e., what items a user is typically interested in) for recommendation. Moreover, these two factors may interact with each other to influence usersu0027 next purchase. To tackle the above problems, in this paper, we introduce a novel recommendation approach, namely hierarchical representation model (HRM). HRM can well capture both sequential behavior and usersu0027 general taste by involving transaction and user representations in prediction. Meanwhile, the flexibility of applying different aggregation operations, especially nonlinear operations, on representations allows us to model complicated interactions among different factors. Theoretically, we show that our model subsumes several existing methods when choosing proper aggregation operations. Empirically, we demonstrate that our model can consistently outperform the state-of-the-art baselines under different evaluation metrics on real-world transaction data.","[{'name': 'Pengfei Wang', 'org': 'CAS Key Lab of Network Data Science and Technology, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China#TAB#', 'id': 2671177797}, {'name': 'Jiafeng Guo', 'org': 'CAS Key Lab of Network Data Science and Technology, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China#TAB#', 'id': 2581340266}, {'name': 'Yanyan Lan', 'org': 'CAS Key Lab of Network Data Science and Technology, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China#TAB#', 'id': 2154124860}, {'name': 'Jun Xu', 'org': 'CAS Key Lab of Network Data Science and Technology, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China#TAB#', 'id': 2598177019}, {'name': 'Shengxian Wan', 'org': 'CAS Key Lab of Network Data Science and Technology, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China#TAB#', 'id': 2109603945}, {'name': 'Xueqi Cheng', 'org': 'CAS Key Lab of Network Data Science and Technology, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China#TAB#', 'id': 2129598186}]"
1843891098,A Neural Attention Model for Abstractive Sentence Summarization,2015,1,,,citation,"Summarization based on text extraction is inherently limited, but generation-style abstractive methods have proven challenging to build. In this work, we propose a fully data-driven approach to abstractive sentence summarization. Our method utilizes a local attention-based model that generates each word of the summary conditioned on the input sentence. While the model is structurally simple, it can easily be trained end-to-end and scales to a large amount of training data. The model shows significant performance gains on the DUC-2004 shared task compared with several strong baselines.","[{'name': 'Alexander M. Rush', 'id': 2701382563}, {'name': 'Sumit Chopra', 'id': 2620976108}, {'name': 'Jason Weston', 'id': 2058584252}]"
1530276735,Content-based recommendation systems,2007,1,,,citation,"This chapter discusses content-based recommendation systems, i.e., systems that recommend an item to a user based upon a description of the item and a profile of the useru0027s interests. Content-based recommendation systems may be used in a variety of domains ranging from recommending web pages, news articles, restaurants, television programs, and items for sale. Although the details of various systems differ, content-based recommendation systems share in common a means for describing the items that may be recommended, a means for creating a profile of the user that describes the types of items the user likes, and a means of comparing items to the user profile to determine what to recommend. The profile is often created and updated automatically in response to feedback on the desirability of items that have been presented to the user.","[{'name': 'Michael J. Pazzani', 'org': 'Rutgers University, ASBIII, New Brunswick, NJ#TAB#', 'id': 1996789426}, {'name': 'Daniel Billsus', 'org': 'FX Palo Alto Laboratory, Inc., Palo Alto, CA', 'id': 2186721938}]"
980913505,COT: contextual operating tensor for context-aware recommender systems,2015,1,,,citation,"With rapid growth of information on the internet, recommender systems become fundamental for helping users alleviate the problem of information overload. Since contextual information can be used as a significant factor in modeling user behavior, various context-aware recommendation methods are proposed. However, the state-of-the-art context modeling methods treat contexts as other dimensions similar to the dimensions of users and items, and cannot capture the special semantic operation of contexts. On the other hand, some works on multi-domain relation prediction can be used for the context-aware recommendation, but they have problems in generating recommendation under a large amount of contextual information. In this work, we propose Contextual Operating Tensor (COT) model, which represents the common semantic effects of contexts as a contextual operating tensor and represents a context as a latent vector. Then, to model the semantic operation of a context combination, we generate contextual operating matrix from the contextual operating tensor and latent vectors of contexts. Thus latent vectors of users and items can be operated by the contextual operating matrices. Experimental results show that the proposed COT model yields significant improvements over the competitive compared methods on three typical datasets, i.e., Food, Adom and Movielens-1M datasets.","[{'name': 'Qiang Liu', 'org': 'Center for Research on Intelligent Perception and Computing, National Laboratory of Pattern Recognition Institute of Automation, Chinese Academy of Sciences, China#TAB#', 'id': 2776955352}, {'name': 'Shu Wu', 'org': 'Center for Research on Intelligent Perception and Computing, National Laboratory of Pattern Recognition Institute of Automation, Chinese Academy of Sciences, China#TAB#', 'id': 2122580694}, {'name': 'Liang Wang', 'org': 'Center for Research on Intelligent Perception and Computing, National Laboratory of Pattern Recognition Institute of Automation, Chinese Academy of Sciences, China#TAB#', 'id': 2226151461}]"
2548746141,On Approximate Reasoning Capabilities of Low-Rank Vector Spaces,2015,2,,,citation,"In relational databases, relations between objects, represented by binary matrices or tensors, may be arbitrarily complex. In practice however, there are recurring relational patterns such as transitive, permutation, and sequential relationships, that have a regular structure which is not captured by the classical notion of matrix rank or tensor rank. In this paper, we show that factorizing the relational tensor using a logistic or hinge loss instead of the more standard squared loss is more appropriate because it can accurately model many common relations with a fixed-size embedding (depends sub-linearly on the number of entities in the knowledge base). We illustrate this fact empirically by being able to efficiently predict missing links in several synthetic and real-world experiments. Further, we provide theoretical justification for logistic loss by studying its connection to a complexity measure from the field of information complexity called sign rank. Sign rank is a more appropriate complexity measure as it is low for transitive, permutation, or sequential relationships, while being suitably large, with a high probability, for uniformly sampled binary matrices/tensors.","[{'name': 'Guillaume Bouchard', 'org': 'XEROX', 'id': 2336810427}, {'name': 'Sameer Singh', 'org': 'University of Washington,', 'id': 2279876130}]"
2340412028,A Factorization Machine Framework for Testing Bigram Embeddings in Knowledgebase Completion,2016,2,,,citation,"Embedding-based Knowledge Base Completion models have so far mostly combined distributed representations of individual entities or relations to compute truth scores of missing links. Facts can however also be represented using pairwise embeddings, i.e. embeddings for pairs of entities and relations. In this paper we explore such bigram embeddings with a flexible Factorization Machine model and several ablations from it. We investigate the relevance of various bigram types on the fb15k237 dataset and find relative improvements compared to a compositional model.","[{'name': 'Johannes Welbl', 'id': 2336861845}, {'name': 'Guillaume Bouchard', 'id': 2336810427}, {'name': 'Sebastian Riedel', 'id': 1976791985}]"
2146502635,Adaptive Subgradient Methods for Online Learning and Stochastic Optimization,2011,2,,,citation,"We present a new family of subgradient methods that dynamically incorporate knowledge of the geometry of the data observed in earlier iterations to perform more informative gradient-based learning. Metaphorically, the adaptation allows us to find needles in haystacks in the form of very predictive but rarely seen features. Our paradigm stems from recent advances in stochastic optimization and online learning which employ proximal functions to control the gradient steps of the algorithm. We describe and analyze an apparatus for adaptively modifying the proximal function, which significantly simplifies setting a learning rate and results in regret guarantees that are provably as good as the best proximal function that can be chosen in hindsight. We give several efficient algorithms for empirical risk minimization problems with common and important regularization functions and domain constraints. We experimentally study our theoretical analysis and show that adaptive subgradient methods outperform state-of-the-art, yet non-adaptive, subgradient algorithms.","[{'name': 'John Duchi', 'org': '""University of California, Berkeley""', 'id': 2524462901}, {'name': 'Elad Hazan', 'org': 'Princeton University *', 'id': 2139423477}, {'name': 'Yoram Singer', 'org': 'GOOGLE', 'id': 2292250447}]"
2145544171,Holographic embeddings of knowledge graphs,2016,2,,,citation,"Learning embeddings of entities and relations is an efficient and versatile method to perform machine learning on relational data such as knowledge graphs. In this work, we propose holographic embeddings (HOLE) to learn compositional vector space representations of entire knowledge graphs. The proposed method is related to holographic models of associative memory in that it employs circular correlation to create compositional representations. By using correlation as the compositional operator, HOLE can capture rich interactions but simultaneously remains efficient to compute, easy to train, and scalable to very large datasets. Experimentally, we show that holographic embeddings are able to outperform state-of-the-art methods for link prediction on knowledge graphs and relational learning benchmark datasets.","[{'name': 'Maximilian Nickel', 'org': 'Laboratory for Computational and Statistical Learning and Center for Brains, Minds and Machines, Massachusetts Institute of Technology, Cambridge, MA and Istituto Italiano di Tecnologia, Genova, I ...#TAB#', 'id': 2152648595}, {'name': 'Lorenzo Rosasco', 'org': 'Laboratory for Computational and Statistical Learning and Center for Brains, Minds and Machines, Massachusetts Institute of Technology, Cambridge, MA and Istituto Italiano di Tecnologia, Genova, I ...#TAB#', 'id': 2028927923}, {'name': 'Tomaso Poggio', 'org': 'Laboratory for Computational and Statistical Learning and Center for Brains, Minds and Machines, Massachusetts Institute of Technology, Cambridge, MA#TAB#', 'id': 693931197}]"
2123228027,Modelling Relational Data using Bayesian Clustered Tensor Factorization,2009,2,,,citation,"We consider the problem of learning probabilistic models for complex relational structures between various types of objects. A model can help us ""understand"" a dataset of relational facts in at least two ways, by finding interpretable structure in the data, and by supporting predictions, or inferences about whether particular unobserved relations are likely to be true. Often there is a tradeoff between these two aims: cluster-based models yield more easily interpretable representations, while factorization-based approaches have given better predictive performance on large data sets. We introduce the Bayesian Clustered Tensor Factorization (BCTF) model, which embeds a factorized representation of relations in a nonparametric Bayesian clustering framework. Inference is fully Bayesian but scales well to large data sets. The model simultaneously discovers interpretable clusters and yields predictive performance that matches or beats previous probabilistic models for relational data.","[{'name': 'Ilya Sutskever', 'org': 'University of Toronto,#TAB#', 'id': 215131072}, {'name': 'Joshua B. Tenenbaum', 'org': 'mit', 'id': 2149572011}, {'name': 'Ruslan R Salakhutdinov', 'org': 'mit', 'id': 2031945151}]"
2115632234,Irreflexive and Hierarchical Relations as Translations,2013,2,,,citation,"We consider the problem of embedding entities and relations of knowledge bases in low-dimensional vector spaces. Unlike most existing approaches, which are primarily efficient for modeling equivalence relations, our approach is designed to explicitly model irreflexive relations, such as hierarchies, by interpreting them as translations operating on the low-dimensional embeddings of the entities. Preliminary experiments show that, despite its simplicity and a smaller number of parameters than previous approaches, our approach achieves state-of-the-art performance according to standard evaluation protocols on data from WordNet and Freebase.","[{'name': 'Antoine Bordes', 'org': 'University of Technology of Compiègne#TAB#', 'id': 2160652726}, {'name': 'Nicolas Usunier', 'id': 121890299}, {'name': 'Alberto García-Durán', 'id': 2047865013}, {'name': 'Jason Weston', 'id': 2058584252}, {'name': 'Oksana Yakhnenko', 'id': 2000873150}]"
2101802482,A latent factor model for highly multi-relational data,2012,2,,,citation,"Many data such as social networks, movie preferences or knowledge bases are multi-relational, in that they describe multiple relations between entities. While there is a large body of work focused on modeling these data, modeling these multiple types of relations jointly remains challenging. Further, existing approaches tend to breakdown when the number of these types grows. In this paper, we propose a method for modeling large multi-relational datasets, with possibly thousands of relations. Our model is based on a bilinear structure, which captures various orders of interaction of the data, and also shares sparse latent factors across different relations. We illustrate the performance of our approach on standard tensor-factorization datasets where we attain, or outperform, state-of-the-art results. Finally, a NLP application demonstrates our scalability and the ability of our model to learn efficient and semantically meaningful verb representations.","[{'name': 'Rodolphe Jenatton', 'org': 'CMAP, UMR CNRS 7641, Ecole Polytechnique, Palaiseau, France#TAB#', 'id': 90224947}, {'name': 'Nicolas L. Roux', 'org': 'INRIA - SIERRA Project Team, Ecole Normale Supérieure, Paris, France#TAB#', 'id': 2044175236}, {'name': 'Antoine Bordes', 'org': 'Heudiasyc, UMR CNRS 7253, Université de Technologie de Compiègne, France#TAB#', 'id': 2160652726}, {'name': 'Guillaume R Obozinski', 'org': 'INRIA - SIERRA Project Team, Ecole Normale Supérieure, Paris, France#TAB#', 'id': 1995962232}]"
2094728533,Freebase: a collaboratively created graph database for structuring human knowledge,2008,2,,,citation,"Freebase is a practical, scalable tuple database used to structure general human knowledge. The data in Freebase is collaboratively created, structured, and maintained. Freebase currently contains more than 125,000,000 tuples, more than 4000 types, and more than 7000 properties. Public read/write access to Freebase is allowed through an HTTP-based graph-query API using the Metaweb Query Language (MQL) as a data query and manipulation language. MQL provides an easy-to-use object-oriented interface to the tuple data in Freebase and is designed to facilitate the creation of collaborative, Web-based data-oriented applications.","[{'name': 'Kurt Bollacker', 'org': 'Metaweb Technologies, San Francisco, CA, USA', 'id': 2866403201}, {'name': 'Colin Evans', 'org': 'Metaweb Technologies, San Francisco, CA, USA', 'id': 2722202041}, {'name': 'Praveen Paritosh', 'org': 'Metaweb Technologies, San Francisco, CA, USA', 'id': 315021205}, {'name': 'Tim Sturge', 'org': 'Metaweb Technologies, San Francisco, CA, USA', 'id': 2232019639}, {'name': 'Jamie Taylor', 'org': 'Metaweb Technologies, San Francisco, CA, USA', 'id': 2103267263}]"
2054141820,Matrix Factorization Techniques for Recommender Systems,2009,2,,,citation,"As the Netflix Prize competition has demonstrated, matrix factorization models are superior to classic nearest neighbor techniques for producing product recommendations, allowing the incorporation of additional information such as implicit feedback, temporal effects, and confidence levels.","[{'name': 'Y. Koren', 'org': 'Yahoo! Research, Santa Clara , CA, USA', 'id': 2781213378}, {'name': 'R. Bell', 'org': 'AT&TLabs#TAB#', 'id': 2148013773}, {'name': 'C. Volinsky', 'org': 'AT&TLabs#TAB#', 'id': 130248871}]"
1852412531,Relation Extraction with Matrix Factorization and Universal Schemas,2013,2,,,citation,"© 2013 Association for Computational Linguistics. Traditional relation extraction predicts relations within some fixed and finite target schema. Machine learning approaches to this task require either manual annotation or, in the case of distant supervision, existing structured sources of the same schema. The need for existing datasets can be avoided by using a universal schema: the union of all involved schemas (surface form predicates as in OpenIE, and relations in the schemas of preexisting databases). This schema has an almost unlimited set of relations (due to surface forms), and supports integration with existing structured data (through the relation types of existing databases). To populate a database of such schema we present matrix factorization models that learn latent feature vectors for entity tuples and relations. We show that such latent models achieve substantially higher accuracy than a traditional classification approach. More importantly, by operating simultaneously on relations observed in text and in pre-existing structured DBs such as Freebase, we are able to reason about unstructured and structured data in mutually-supporting ways. By doing so our approach outperforms stateof- the-Art distant supervision.","[{'name': 'Sebastian Riedel', 'org': 'Univ. College, London#TAB#', 'id': 1976791985}, {'name': 'Limin Yao', 'org': 'University of Massachusetts-Amherst', 'id': 2151403046}, {'name': 'Andrew McCallum', 'org': 'University of Massachusetts-Amherst', 'id': 2131293038}, {'name': 'Benjamin M. Marlin', 'org': 'University of Massachusetts-Amherst', 'id': 1559204946}]"
1754706138,Sign rank versus VC dimension,2015,2,,,citation,"This work studies the maximum possible sign rank of $N \times N$ sign matrices with a given VC dimension $d$. For $d=1$, this maximum is {three}. For $d=2$, this maximum is $\tilde{\Theta}(N^{1/2})$. For $d u003e2$, similar but slightly less accurate statements hold. {The lower bounds improve over previous ones by Ben-David et al., and the upper bounds are novel.}  lower bounds are :[59,98],""obtained by probabilistic constructions, using a theorem of Warren in real algebraic topology. The upper bounds are :[59,98],""obtained using a result of Welzl about spanning trees with low stabbing number, and using the moment curve.  upper bound technique is also used to: (i) provide estimates on the number of classes of a given VC dimension, and the number of maximum classes of a given VC dimension -- answering a question of Frankl from u002789, and (ii) design an efficient algorithm that provides an $O(N/\log(N))$ multiplicative approximation for the sign rank.  also :[154,264],""observe a general connection between sign rank and spectral gaps which is based on Forsteru0027s argument. Consider the $N \times N$ adjacency matrix of a $\Delta$ regular graph with a second eigenvalue of absolute value $\lambda$ and $\Delta \leq N/2$. We show that the sign rank of the signed version of this matrix is at least $\Delta/\lambda$. We use this connection to prove the existence of a maximum class $C\subseteq\{\pm 1\}^N$ with VC dimension $2$ and sign rank $\tilde{\Theta}(N^{1/2})$. This answers a question of Ben-David et al.~regarding the sign rank of large VC classes. We also describe limitations of this approach, in the spirit of the Alon-Boppana theorem.  further describe connections to communication complexity, geometry, learning theory, and combinatorics.","[{'name': 'Noga Alon', 'id': 2112574952}, {'name': 'Shay Moran', 'id': 2114518581}, {'name': 'Amir Yehudayoff', 'id': 230026076}]"
1533230146,Embedding Entities and Relations for Learning and Inference in Knowledge Bases,2015,2,,,citation,"Abstract: We consider learning representations of entities and relations in KBs using the neural-embedding approach. We show that most existing models, including NTN (Socher et al., 2013) and TransE (Bordes et al., 2013b), can be generalized under a unified learning framework, where entities are low-dimensional vectors learned from a neural network and relations are bilinear and/or linear mapping functions. Under this framework, we compare a variety of embedding models on the link prediction task. We show that a simple bilinear formulation achieves new state-of-the-art results for the task (achieving a top-10 accuracy of 73.2% vs. 54.7% by TransE on Freebase). Furthermore, we introduce a novel approach that utilizes the learned relation embeddings to mine logical rules such as ""BornInCity(a,b) and CityInCountry(b,c) =u003e Nationality(a,c)"". We find that embeddings learned from the bilinear objective are particularly good at capturing relational semantics and that the composition of relations is characterized by matrix multiplication. More interestingly, we demonstrate that our embedding-based rule extraction approach successfully outperforms a state-of-the-art confidence-based rule mining approach in mining Horn rules that involve compositional reasoning.","[{'name': 'Bishan Yang', 'org': 'Department of Computer Science, Cornell University, Ithaca, NY, 14850, USA', 'id': 2505662152}, {'name': 'Wen-tau Yih', 'org': 'Microsoft Research, Redmond, WA 98052, USA', 'id': 2116578203}, {'name': 'Xiaodong He', 'org': 'Microsoft Research, Redmond, WA 98052, USA', 'id': 2106698597}, {'name': 'Jianfeng Gao', 'org': 'Microsoft Research, Redmond, WA 98052, USA', 'id': 2104437897}, {'name': 'Li Deng', 'org': 'Microsoft Research, Redmond, WA 98052, USA', 'id': 2101552792}]"
1529533208,A Review of Relational Machine Learning for Knowledge Graphs,2016,2,,,citation,"Relational machine learning studies methods for the statistical analysis of relational, or graph-structured, data. In this paper, we provide a review of how such statistical models can be “trained” on large knowledge graphs, and then used to predict new facts about the world (which is equivalent to predicting new edges in the graph). In particular, we discuss two fundamentally different kinds of statistical relational models, both of which can scale to massive data sets. The first is based on latent feature models such as tensor factorization and multiway neural networks. The second is based on mining observable patterns in the graph. We also show how to combine these latent and observable models to get improved modeling power at decreased computational cost. Finally, we discuss how such statistical models of graphs can be combined with text-based information extraction methods for automatically constructing knowledge graphs from the Web. To this end, we also discuss Googleu0027s knowledge vault project as an example of such combination.","[{'name': 'Maximilian Nickel', 'org': 'Laboratory for Computational and Statistical Learning (LCSL), Massachusetts Institute of Technology, Cambridge, MA, USA', 'id': 2152648595}, {'name': 'Kevin Murphy', 'org': 'Google Inc, Mountain View, CA, USA', 'id': 2167731548}, {'name': 'Volker Tresp', 'org': 'Siemens Ag, Corporate Technology, Munich, Germany', 'id': 175204660}, {'name': 'Evgeniy Gabrilovich', 'org': 'Google Inc, Mountain View, CA, USA', 'id': 1804802447}]"
2952792693,Open Question Answering with Weakly Supervised Embedding Models,2014,2,,,citation,"Building computers able to answer questions on any subject is a long standing goal of artificial intelligence. Promising progress has recently been achieved by methods that learn to map questions to logical forms or database queries. Such approaches can be effective but at the cost of either large amounts of human-labeled data or by defining lexicons and grammars tailored by practitioners. In this paper, we instead take the radical approach of learning to map questions to vectorial feature representations. By mapping answers into the same space one can query any knowledge base independent of its schema, without requiring any grammar or lexicon. Our method is trained with a new optimization procedure combining stochastic gradient descent followed by a fine-tuning step using the weak supervision provided by blending automatically and collaboratively generated resources. We empirically demonstrate that our model can capture meaningful signals from its noisy supervision leading to major improvements over paralex, the only existing method able to be trained on similar weakly labeled data.","[{'name': 'Antoine Bordes', 'id': 2160652726}, {'name': 'Jason Weston', 'id': 2981281612}, {'name': 'Nicolas Usunier', 'id': 121890299}]"
2803681287,Learning Probabilistic Relational Models,1999,2,,,citation,"A large portion of real-world data is stored in commercial relational database systems. In contrast, most statistical learning methods work only with ""flat"" data representations. Thus, to apply these methods, we are forced to convert our data into a flat form, thereby losing much of the relational structure present in our database. This paper builds on the recent work on probabilistic relational models (PRMs), and describes how to learn them from databases. PRMs allow the properties of an object to depend probabilistically both on other properties of that object and on properties of related objects. Although PRMs are significantly more expressive than standard models, such as Bayesian networks, we show how to extend well-known statistical methods for learning Bayesian networks to learn these models. We describe both parameter estimation and structure learning -- the automatic induction of the dependency structure in a model. Moreover, we show how the learning procedure can exploit standard database retrieval techniques for efficient learning from large datasets. We present experimental results on both real and synthetic relational databases.","[{'name': 'Nir Friedman', 'org': 'The Institute of Computer Science, Hebrew University, Jerusalem, Israel', 'id': 2079978182}, {'name': 'Lise Getoor', 'org': 'Computer Science Department, Stanford University, Stanford, CA', 'id': 1984940772}, {'name': 'Daphne Koller', 'org': 'Computer Science Department, Stanford University, Stanford, CA', 'id': 2167404190}, {'name': 'Avi Pfeffer', 'org': 'Computer Science Department, Stanford University, Stanford, CA', 'id': 2776652334}]"
2733421109,Complex and Holographic Embeddings of Knowledge Graphs: A Comparison.,2017,2,,,citation,"Embeddings of knowledge graphs have received significant attention due to their excellent performance for tasks like link prediction and entity resolution. In this short paper, we are providing a comparison of two state-of-the-art knowledge graph embeddings for which their equivalence has recently been established, i.e., ComplEx and HolE [Nickel, Rosasco, and Poggio, 2016; Trouillon et al., 2016; Hayashi and Shimbo, 2017]. First, we briefly review both models and discuss how their scoring functions are equivalent. We then analyze the discrepancy of results reported in the original articles, and show experimentally that they are likely due to the use of different loss functions. In further experiments, we evaluate the ability of both models to embed symmetric and antisymmetric patterns. Finally, we discuss advantages and disadvantages of both models and under which conditions one would be preferable to the other.","[{'name': 'Théo Trouillon', 'id': 347299695}, {'name': 'Maximilian Nickel', 'id': 2152648595}]"
2547316200,Discriminative Gaifman Models,2016,2,,,citation,"We present discriminative Gaifman models, a novel family of relational machine learning models. Gaifman models learn feature representations bottom up from representations of locally connected and bounded-size regions of knowledge bases (KBs). Considering local and bounded-size neighborhoods of knowledge bases renders logical inference and learning tractable, mitigates the problem of overfitting, and facilitates weight sharing. Gaifman models sample neighborhoods of knowledge bases so as to make the learned relational models more robust to missing objects and relations which is a common situation in open-world KBs. We present the core ideas of Gaifman models and apply them to large-scale relational learning problems. We also discuss the ways in which Gaifman models relate to some existing relational machine learning approaches.","[{'name': 'Mathias Niepert', 'id': 120810172}]"
2432356473,Complex Embeddings for Simple Link Prediction,2016,2,,,citation,"In statistical relational learning, the link prediction problem is key to automatically understand the structure of large knowledge bases. As in previous studies, we propose to solve this problem through latent factorization. However, here we make use of complex valued embeddings. The composition of complex embeddings can handle a large variety of binary relations, among them symmetric and antisymmetric relations. Compared to state-of-the-art models such as Neural Tensor Network and Holographic Embeddings, our approach based on complex embeddings is arguably simpler, as it only uses the Hermitian dot product, the complex counterpart of the standard dot product between real vectors. Our approach is scalable to large datasets as it remains linear in both space and time, while consistently outperforming alternative approaches on standard link prediction benchmarks.","[{'name': 'Théo Trouillon', 'org': 'XEROX', 'id': 347299695}, {'name': 'Johannes Welbl', 'org': 'Univ. College, London#TAB#', 'id': 2336861845}, {'name': 'Sebastian Riedel', 'org': 'Univ. College, London#TAB#', 'id': 1976791985}, {'name': 'Éric Gaussier', 'id': 2815217814}, {'name': 'Guillaume Bouchard', 'org': 'Univ. College, London#TAB#', 'id': 2336810427}]"
2400319678,Initial investigation of speech synthesis based on complex-valued neural networks,2016,2,,,citation,"Although frequency analysis often leads us to a speech signal in the complex domain, the acoustic models we frequently use are designed for real-valued data. Phase is usually ignored or modelled separately from spectral amplitude. Here, we propose a complex-valued neural network (CVNN) for directly modelling the results of the frequency analysis in the complex domain (such as the complex amplitude). We also introduce a phase encoding technique to map real-valued data (e.g. cepstra or log amplitudes) into the complex domain so we can use the same CVNN processing seamlessly. In this paper, a fully complex-valued neural network, namely a neural network where all of the weight matrices, activation functions and learning algorithms are in the complex domain, is applied for speech synthesis. Results show its ability to model both complex-valued and real-valued data.","[{'name': 'Qiong Hu', 'org': 'The Centre for Speech Technology Research, University of Edinburgh, UK', 'id': 2146296319}, {'name': 'Junichi Yamagishi', 'org': 'The Centre for Speech Technology Research, University of Edinburgh, UK', 'id': 1975726436}, {'name': 'Korin Richmond', 'org': 'The Centre for Speech Technology Research, University of Edinburgh, UK', 'id': 2158195643}, {'name': 'Kartick Subramanian', 'org': 'School of Computer Engineering, Nanyang Technological University,                         Singapore,', 'id': 2234278218}, {'name': 'Yannis Stylianou', 'org': 'Toshiba Research Europe Ltd., Cambridge, U.K.', 'id': 281475089}]"
2396019715,Matrix Completion has No Spurious Local Minimum,2016,2,,,citation,"Matrix completion is a basic machine learning problem that has wide applications, especially in collaborative filtering and recommender systems. Simple non-convex optimization algorithms are popular and effective in practice. Despite recent progress in proving various non-convex algorithms converge from a good initial point, it remains unclear why random or arbitrary initialization suffices in practice. We prove that the commonly used non-convex objective function for \textit{positive semidefinite} matrix completion has no spurious local minima --- all local minima must also be global. Therefore, many popular optimization algorithms such as (stochastic) gradient descent can provably solve positive semidefinite matrix completion with \textit{arbitrary} initialization in polynomial time. The result can be generalized to the setting when the observed entries contain noise. We believe that our main proof strategy can be useful for understanding geometric properties of other statistical problems involving partial or noisy observations.","[{'name': 'Rong Ge', 'id': 2286931549}, {'name': 'Jason D. Lee', 'id': 2239320619}, {'name': 'Tengyu Ma', 'id': 2171800532}]"
2296268288,Injecting Logical Background Knowledge into Embeddings for Relation Extraction,2015,2,,,citation,"Matrix factorization approaches to relation extraction provide several attractive features: they support distant supervision, handle open schemas, and leverage unlabeled data. Unfortunately, these methods share a shortcoming with all other distantly supervised approaches: they cannot learn to extract target relations without existing data in the knowledge base, and likewise, these models are inaccurate for relations with sparse data. Rule-based extractors, on the other hand, can be easily extended to novel relations and improved for existing but inaccurate relations, through first-order formulae that capture auxiliary domain knowledge. However, usually a large set of such formulae is necessary to achieve generalization. In this paper, we introduce a paradigm for learning low-dimensional embeddings of entity-pairs and relations that combine the advantages of matrix factorization with first-order logic domain knowledge. We introduce simple approaches for estimating such embeddings, as well as a novel training algorithm to jointly optimize over factual and first-order logic information. Our results show that this method is able to learn accurate extractors with little or no distant supervision alignments, while at the same time generalizing to textual patterns that do not appear in the formulae.","[{'name': 'Tim Rocktäschel', 'id': 2252160535}, {'name': 'Sameer Singh', 'id': 2279876130}, {'name': 'Sebastian Riedel', 'id': 1976791985}]"
2265796482,Associative long short-term memory,2016,2,,,citation,"We investigate a new method to augment recurrent neural networks with extra memory without increasing the number of network parameters. The system has an associative memory based on complex-valued vectors and is closely related to Holographic Reduced Representations and Long Short-Term Memory networks. Holographic Reduced Representations have limited capacity: as they store more information, each retrieval becomes noisier due to interference. Our system in contrast creates redundant copies of stored information, which enables retrieval with reduced noise. Experiments demonstrate faster learning on multiple memorization tasks.","[{'name': 'Ivo Danihelka', 'org': 'Google Deepmind', 'id': 99853849}, {'name': 'Greg Wayne', 'org': 'Google Deepmind', 'id': 2495352179}, {'name': 'Benigno Uria', 'org': 'Google Deepmind', 'id': 1679353438}, {'name': 'Nal Kalchbrenner', 'org': 'Google Deepmind', 'id': 223268448}, {'name': 'Alex Graves', 'org': 'Google Deepmind', 'id': 2116712232}]"
2147544992,Independent component analysis and (simultaneous) third-order tensor diagonalization,2001,2,,,citation,"Comonu0027s (1994) well-known scheme for independent component analysis (ICA) is based on the maximal diagonalization, in a least-squares sense, of a higher-order cumulant tensor. In a previous paper, we proved that for fourth-order cumulants, the computation of an elementary Jacobi rotation is equivalent to the computation of the best rank-1 approximation of a fourth-order tensor. In this paper, we show that for third-order tensors, the computation of an elementary Jacobi rotation is again equivalent to a best rank-1 approximation; however, here, it is a matrix that has to be approximated. This favorable computational load makes it attractive to do ""something third-order-like"" for fourth-order cumulant tensors as well. We show that simultaneous optimal diagonalization of ""third-order tensor slices"" of the fourth-order cumulant is a suitable strategy. This ""simultaneous third-order tensor diagonalization"" approach (STOTD) is similar in spirit to the efficient JADE-algorithm.","[{'name': 'L. de Lathauwer', 'org': 'ESAT, Katholieke Univ., Leuven, Belgium#TAB#', 'id': 386056786}, {'name': 'B. de Moor', 'id': 2134205613}, {'name': 'J. Vandewalle', 'id': 1964643177}]"
2142638745,A blind source separation technique using second-order statistics,1997,2,,,citation,"Separation of sources consists of recovering a set of signals of which only instantaneous linear mixtures are observed. In many situations, no a priori information on the mixing matrix is available: The linear mixture should be ""blindly"" processed. This typically occurs in narrowband array processing applications when the array manifold is unknown or distorted. This paper introduces a new source separation technique exploiting the time coherence of the source signals. In contrast with other previously reported techniques, the proposed approach relies only on stationary second-order statistics that are based on a joint diagonalization of a set of covariance matrices. Asymptotic performance analysis of this method is carried out; some numerical simulations are provided to illustrate the effectiveness of the proposed method.","[{'name': 'A. Belouchrani', 'org': 'Dept. of Electr. and Comput. Eng., Villanova Univ., PA, USA', 'id': 660988112}, {'name': 'K. Abed-Meraim', 'id': 239548094}, {'name': 'J.-F. Cardoso', 'id': 2271037092}, {'name': 'E. Moulines', 'id': 2924292120}]"
2118862682,Modeling distances in large-scale networks by matrix factorization,2004,2,,,citation,"In this paper, we propose a model for representing and predicting distances in large-scale networks by matrix factorization. The model is useful for network distance sensitive applications, such as content distribution networks, topology-aware overlays, and server selections. Our approach overcomes several limitations of previous coordinates-based mechanisms, which cannot model sub-optimal routing or asymmetric routing policies. We describe two algorithms --- singular value decomposition (SVD) and nonnegative matrix factorization (NMF)---for representing a matrix of network distances as the product of two smaller matrices. With such a representation, we build a scalable system--- Internet Distance Estimation Service (IDES)---that predicts large numbers of network distances from limited numbers of measurements. Extensive simulations on real-world data sets show that IDES leads to more accurate, efficient and robust predictions of latencies in large-scale networks than previous approaches.","[{'name': 'Yun Mao', 'org': 'University of Pennsylvania', 'id': 2110157785}, {'name': 'Lawrence K. Saul', 'org': 'University of Pennsylvania', 'id': 2143047568}]"
2102363952,Typed Tensor Decomposition of Knowledge Bases for Relation Extraction,2014,2,,,citation,"While relation extraction has traditionally been viewed as a task relying solely on textual data, recent work has shown that by taking as input existing facts in the form of entity-relation triples from both knowledge bases and textual data, the performance of relation extraction can be improved significantly. Following this new paradigm, we propose a tensor decomposition approach for knowledge base embedding that is highly scalable, and is especially suitable for relation extraction. By leveraging relational domain knowledge about entity type information, our learning algorithm is significantly faster than previous approaches and is better able to discover new relations missing from the database. In addition, when applied to a relation extraction task, our approach alone is comparable to several existing systems, and improves the weighted mean average precision of a state-of-theart method by 10 points when used as a subcomponent.","[{'name': 'Kai-Wei Chang', 'id': 2137603918}, {'name': 'Wen-tau Yih', 'id': 2116578203}, {'name': 'Bishan Yang', 'id': 2505662152}, {'name': 'Christopher Meek', 'id': 2422299352}]"
2055515294,Exploiting matrix factorization to asymmetric user similarities in recommendation systems,2015,2,,,citation,"Although collaborative filtering is widely applied in recommendation systems, it still suffers from several major limitations, including data sparsity and scalability. Sparse data affects the quality of the user similarity measurement and consequently the quality of the recommender system. In this paper, we propose a novel user similarity measure aimed at providing a valid similarity measurement between users with very few ratings. The contributions of this paper are twofold: First, we suggest an asymmetric user similarity method to distinguish between the impact that the user has on his neighbor and the impact that the user receives from his neighbor. Second, we apply matrix factorization to the user similarity matrix in order to discover the similarities between users who have rated different items. Experimental results show that our method performs better than commonly used approaches, especially under cold-start condition.","[{'name': 'Parivash Pirasteh', 'org': 'Dept. of Computer Engineering, Yeungnam University, Republic of Korea', 'id': 2133908295}, {'name': 'Dosam Hwang', 'org': 'Dept. of Computer Engineering, Yeungnam University, Republic of Korea', 'id': 2105899569}, {'name': 'Jason J. Jung', 'org': 'Department of Computer Engineering, Chung-Ang University, Republic of Korea#TAB#', 'id': 2107704472}]"
1997707785,Online dating recommender systems: the split-complex number approach,2012,2,,,citation,"A typical recommender setting is based on two kinds of relations: similarity between users (or between objects) and the taste of users towards certain objects. In environments such as online dating websites, these two relations are difficult to separate, as the users can be similar to each other, but also have preferences towards other users, i.e., rate other users. In this paper, we present a novel and unified way to model this duality of the relations by using split-complex numbers, a number system related to the complex numbers that is used in mathematics, physics and other fields. We show that this unified representation is capable of modeling both notions of relations between users in a joint expression and apply it for recommending potential partners. In experiments with the Czech dating website Libimseti.cz we show that our modeling approach leads to an improvement over baseline recommendation methods in this scenario.","[{'name': 'Jérôme Kunegis', 'org': 'University of Koblenz-Landau Koblenz Germany', 'id': 2232072325}, {'name': 'Gerd Gröner', 'org': 'University of Koblenz-Landau Koblenz Germany', 'id': 2043977584}, {'name': 'Thomas Gottron', 'org': 'University of Koblenz-Landau Koblenz Germany', 'id': 223387194}]"
1977970897,Markov logic networks,2006,2,,,citation,"We propose a simple approach to combining first-order logic and probabilistic graphical models in a single representation. A Markov logic network (MLN) is a first-order knowledge base with a weight attached to each formula (or clause). Together with a set of constants representing objects in the domain, it specifies a ground Markov network containing one feature for each possible grounding of a first-order formula in the KB, with the corresponding weight. Inference in MLNs is performed by MCMC over the minimal subset of the ground network required for answering the query. Weights are efficiently learned from relational databases by iteratively optimizing a pseudo-likelihood measure. Optionally, additional clauses are learned using inductive logic programming techniques. Experiments with a real-world database and knowledge base in a university domain illustrate the promise of this approach.","[{'name': 'Matthew Richardson', 'org': 'Department of Computer Science and Engineering, University of Washington, Seattle, USA#TAB#', 'id': 2131647568}, {'name': 'Pedro Domingos', 'org': 'Department of Computer Science and Engineering, University of Washington, Seattle, USA#TAB#', 'id': 2169012919}]"
1930472418,Querying Factorized Probabilistic Triple Databases,2014,2,,,citation,"An increasing amount of data is becoming available in the form of large triple stores, with the Semantic Webu0027s linked open data cloud (LOD) as one of the most prominent examples. Data quality and completeness are key issues in many community-generated data stores, like LOD, which motivates probabilistic and statistical approaches to data representation, reasoning and querying. In this paper we address the issue from the perspective of probabilistic databases, which account for uncertainty in the data via a probability distribution over all database instances. We obtain a highly compressed representation using the recently developed RESCAL approach and demonstrate experimentally that efficient querying can be obtained by exploiting inherent features of RESCAL via sub-query approximations of deterministic views.","[{'name': 'Denis Krompaβ', 'org': 'Ludwig-Maximilian-University Munich  Germany', 'id': 2477706755}, {'name': 'Maximilian Nickel', 'org': 'Massachusetts Institute of Technology, Cambridge, USA and Istituto Italiano di Tecnologia, Genova, Italy#TAB#', 'id': 2152648595}, {'name': 'Volker Tresp', 'org': 'Ludwig Maximilian University, Munich, Germany and Siemens AG, Corporate Technology, Munich, Germany#TAB#', 'id': 175204660}]"
1910578190,TripleRank: Ranking Semantic Web Data by Tensor Decomposition,2009,2,,,citation,"The Semantic Web fosters novel applications targeting a more efficient and satisfying exploitation of the data available on the web, e.g. faceted browsing of linked open data. Large amounts and high diversity of knowledge in the Semantic Web pose the challenging question of appropriate relevance ranking for producing fine-grained and rich descriptions of the available data, e.g. to guide the user along most promising knowledge aspects. Existing methods for graph-based authority ranking lack support for fine-grained latent coherence between resources and predicates (i.e. support for link semantics in the linked data model). In this paper, we present TripleRank, a novel approach for faceted authority ranking in the context of RDF knowledge bases. TripleRank captures the additional latent semantics of Semantic Web data by means of statistical methods in order to produce richer descriptions of the available data. We model the Semantic Web by a 3-dimensional tensor that enables the seamless representation of arbitrary semantic links. For the analysis of that model, we apply the PARAFAC decomposition, which can be seen as a multi-modal counterpart to Web authority ranking with HITS. The result are groupings of resources and predicates that characterize their authority and navigational (hub) properties with respect to identified topics. We have applied TripleRank to multiple data sets from the linked open data community and gathered encouraging feedback in a user evaluation where TripleRank results have been exploited in a faceted browsing scenario.","[{'name': 'Thomas Franz', 'org': 'ISWeb, University of Koblenz-Landau, Germany', 'id': 2236104399}, {'name': 'Antje Schultz', 'org': 'ISWeb, University of Koblenz-Landau, Germany', 'id': 2113302916}, {'name': 'Sergej Sizov', 'org': 'ISWeb, University of Koblenz-Landau, Germany', 'id': 2310687856}, {'name': 'Steffen Staab', 'org': 'ISWeb, University of Koblenz-Landau, Germany', 'id': 1941402522}]"
1767833073,Query Evaluation on Probabilistic RDF Databases,2009,2,,,citation,"Over the last few years, RDF has been used as a knowledge representation model in a wide variety of domains. Some domains are full of uncertainty. Thus, it is desired to process and manage probabilistic RDF data. The core operation of queries on an RDF probabilistic database is computing the probability of the result to a query. In this paper, we describe a general framework for supporting SPARQL queries on probabilistic RDF databases. In particular, we consider transitive inference capability for RDF instance data. We show that the find operation for an atomic query with the transitive property can be formalized as the problem of computing path expressions on the transitive relation graph and we also propose an approximate algorithm for computing path expressions efficiently. At last, we implement and experimentally evaluate our approach.","[{'name': 'Hai Huang', 'org': 'Faulty of ICT, Swinburne University of Technology, Australia', 'id': 2620505991}, {'name': 'Chengfei Liu', 'org': 'Faulty of ICT, Swinburne University of Technology, Australia', 'id': 2144108974}]"
614875374,Combining two and three-way embedding models for link prediction in knowledge bases,2016,2,,,citation,"This paper tackles the problem of endogenous link prediction for knowledge base completion. Knowledge bases can be represented as directed graphs whose nodes correspond to entities and edges to relationships. Previous attempts either consist of powerful systems with high capacity to model complex connectivity patterns, which unfortunately usually end up overfitting on rare relationships, or in approaches that trade capacity for simplicity in order to fairly model all relationships, frequent or not. In this paper, we propose TATEC, a happy medium obtained by complementing a high-capacity model with a simpler one, both pre-trained separately and then combined. We present several variants of this model with different kinds of regularization and combination strategies and show that this approach outperforms existing methods on different types of relationships by achieving state-of-the-art results on four benchmarks of the literature.","[{'name': 'Alberto García-Durán', 'org': 'Sorbonne Universités, Université de Technologie de Compiègne, Compiègne, France', 'id': 2047865013}, {'name': 'Antoine Bordes', 'org': 'Facebook AI Research, New York, NY#TAB#', 'id': 2160652726}, {'name': 'Nicolas Usunier', 'org': 'Facebook AI Research, Paris, France#TAB#', 'id': 121890299}, {'name': 'Yves Grandvalet', 'org': 'Sorbonne Universités, Université de Technologie de Compiègne, Compiègne, France', 'id': 24574532}]"
68132019,A semantic matching energy function for learning with multi-relational data,2014,2,,,citation,"Large-scale relational learning becomes crucial for handling the huge amounts of structured data generated daily in many application domains ranging from computational biology or information retrieval, to natural language processing. In this paper, we present a new neural network architecture designed to embed multi-relational graphs into a flexible continuous vector space in which the original data is kept and enhanced. The network is trained to encode the semantics of these graphs in order to assign high probabilities to plausible components. We empirically show that it reaches competitive performance in link prediction on standard datasets from the literature as well as on data from a real-world knowledge base (WordNet). In addition, we present how our method can be applied to perform word-sense disambiguation in a context of open-text semantic parsing, where the goal is to learn to assign a structured meaning representation to almost any sentence of free text, demonstrating that it can scale up to tens of thousands of nodes and thousands of types of relation.","[{'name': 'Antoine Bordes', 'org': 'Heudiasyc UMR 7253, Université de Technlogie de Compiègne & CNRS, Compiègne, France#TAB#', 'id': 2160652726}, {'name': 'Xavier Glorot', 'org': 'Université de Montréal, Montréal, Canadá', 'id': 295353625}, {'name': 'Jason Weston', 'org': 'Google, New York, USA', 'id': 2058584252}, {'name': 'Yoshua Bengio', 'org': 'Université de Montréal, Montréal, Canadá', 'id': 161269817}]"
2952155763,Compositional Vector Space Models for Knowledge Base Completion,2015,2,,,citation,"Knowledge base (KB) completion adds new facts to a KB by making inferences from existing facts, for example by inferring with high likelihood nationality(X,Y) from bornIn(X,Y). Most previous methods infer simple one-hop relational synonyms like this, or use as evidence a multi-hop relational path treated as an atomic feature, like bornIn(X,Z) -u003e containedIn(Z,Y). This paper presents an approach that reasons about conjunctions of multi-hop relations non-atomically, composing the implications of a path using a recursive neural network (RNN) that takes as inputs vector embeddings of the binary relation in the path. Not only does this allow us to generalize to paths unseen at training time, but also, with a single high-capacity RNN, to predict new relation types not seen when the compositional model was trained (zero-shot learning). We assemble a new dataset of over 52M relational triples, and show that our method improves over a traditional classifier by 11%, and a method leveraging pre-trained embeddings by 7%.","[{'name': 'Arvind Neelakantan', 'id': 2498206862}, {'name': 'Benjamin Roth', 'id': 2310044572}, {'name': 'Andrew McCallum', 'id': 2131293038}]"
2567619939,Joint Representation Learning of Text and Knowledge for Knowledge Graph Completion.,2016,2,,,citation,"Joint representation learning of text and knowledge within a unified semantic space enables us to perform knowledge graph completion more accurately. In this work, we propose a novel framework to embed words, entities and relations into the same continuous vector space. In this model, both entity and relation embeddings are learned by taking knowledge graph and plain text into consideration. In experiments, we evaluate the joint learning model on three tasks including entity prediction, relation prediction and relation classification from text. The experiment results show that our model can significantly and consistently improve the performance on the three tasks as compared with other baselines.","[{'name': 'Xu Han', 'id': 2561023778}, {'name': 'Zhiyuan Liu', 'id': 2580718499}, {'name': 'Maosong Sun', 'id': 2157167650}]"
2433281745,Knowledge graph completion with adaptive sparse transfer matrix,2016,2,,,citation,"We model knowledge graphs for their completion by encoding each entity and relation into a numerical space. All previous work including Trans(E, H, R, and D) ignore the heterogeneity (some relations link many entity pairs and others do not) and the imbalance (the number of head entities and that of tail entities in a relation could be different) of knowledge graphs. In this paper, we propose a novel approach TranSparse to deal with the two issues. In TranSparse, transfer matrices are replaced by adaptive sparse matrices, whose sparse degrees are determined by the number of entities (or entity pairs) linked by relations. In experiments, we design structured and unstructured sparse patterns for transfer matrices and analyze their advantages and disadvantages. We evaluate our approach on triplet classification and link prediction tasks. Experimental results show that TranSparse outperforms Trans(E, H, R, and D) significantly, and achieves state-of-the-art performance.","[{'name': 'Guoliang Ji', 'org': 'National Laboratory of Pattern Recognition NLPR, Institute of Automation, Chinese Academy of Sciences, Beijing, China#TAB#', 'id': 2718547011}, {'name': 'Kang Liu', 'org': 'National Laboratory of Pattern Recognition NLPR, Institute of Automation, Chinese Academy of Sciences, Beijing, China#TAB#', 'id': 2130404924}, {'name': 'Shizhu He', 'org': 'National Laboratory of Pattern Recognition NLPR, Institute of Automation, Chinese Academy of Sciences, Beijing, China#TAB#', 'id': 2126153884}, {'name': 'Jun Zhao', 'org': 'National Laboratory of Pattern Recognition NLPR, Institute of Automation, Chinese Academy of Sciences, Beijing, China#TAB#', 'id': 2590483556}]"
2250807343,Aligning Knowledge and Text Embeddings by Entity Descriptions,2015,2,,,citation,"We study the problem of jointly embedding a knowledge base and a text corpus. The key issue is the alignment model making sure the vectors of entities, relations and words are in the same space. Wang et al. (2014a) rely on Wikipedia anchors, making the applicable scope quite limited. In this paper we propose a new alignment model based on text descriptions of entities, without dependency on anchors. We require the embedding vector of an entity not only to fit the structured constraints in KBs but also to be equal to the embedding vector computed from the text description. Extensive experiments show that, the proposed approach consistently performs comparably or even better than the method of Wang et al. (2014a), which is encouraging as we do not use any anchor information.","[{'name': 'Huaping Zhong', 'id': 2662424319}, {'name': 'Jianwen Zhang', 'id': 2212130774}, {'name': 'Zhen Wang', 'id': 2573191577}, {'name': 'Hai Wan', 'id': 2608505370}, {'name': 'Zheng Chen', 'id': 2425877144}]"
2131774270,Bidirectional recurrent neural networks,1997,2,,,citation,"In the first part of this paper, a regular recurrent neural network (RNN) is extended to a bidirectional recurrent neural network (BRNN). The BRNN can be trained without the limitation of using input information just up to a preset future frame. This is accomplished by training it simultaneously in positive and negative time direction. Structure and training procedure of the proposed network are explained. In regression and classification experiments on artificial data, the proposed structure gives better results than other approaches. For real data, classification experiments for phonemes from the TIMIT database show the same tendency. In the second part of this paper, it is shown how the proposed bidirectional structure can be easily modified to allow efficient estimation of the conditional posterior probability of complete symbol sequences without making any explicit assumption about the shape of the distribution. For this part, experiments on real data are reported.","[{'name': 'M. Schuster', 'org': 'ATR Interpreting Telecommun. Res. Lab., Kyoto, Japan', 'id': 2568636091}, {'name': 'K.K. Paliwal', 'id': 2097766447}]"
2120615054,A Convolutional Neural Network for Modelling Sentences,2014,2,,,citation,"The ability to accurately represent sentences is central to language understanding. We describe a convolutional architecture dubbed the Dynamic Convolutional Neural Network (DCNN) that we adopt for the semantic modelling of sentences. The network uses Dynamic k-Max Pooling, a global pooling operation over linear sequences. The network handles input sentences of varying length and induces a feature graph over the sentence that is capable of explicitly capturing short and long-range relations. The network does not rely on a parse tree and is easily applicable to any language. We test the DCNN in four experiments: small scale binary and multi-class sentiment prediction, six-way question classification and Twitter sentiment prediction by distant supervision. The network achieves excellent performance in the first three tasks and a greater than 25% error reduction in the last task with respect to the strongest baseline.","[{'name': 'Nal Kalchbrenner', 'org': 'University of Oxford', 'id': 223268448}, {'name': 'Edward Grefenstette', 'id': 12494109}, {'name': 'Phil Blunsom', 'org': 'University of Oxford', 'id': 297118547}]"
2110485445,Finding Structure in Time,1990,2,,,citation,"Time underlies many interesting human behaviors. Thus, the question of how to represent time in connectionist models is very important. One approach is to represent time implicitly by its effects on processing rather than explicitly (as in a spatial representation). The current report develops a proposal along these lines first described by Jordan (1986) which involves the use of recurrent links in order to provide networks with a dynamic memory. In this approach, hidden unit patterns are fed back to themselves; the internal representations which develop thus reflect task demands in the context of prior internal states. A set of simulations is reported which range from relatively simple problems (temporal version of XOR) to discovering syntactic/semantic features for words. The networks are able to learn interesting internal representations which incorporate task demands with memory demands; indeed, in this approach the notion of memory is inextricably bound up with task processing. These representations reveal a rich structure, which allows them to be highly context-dependent while also expressing generalizations across classes of items. These representations suggest a method for representing lexical categories and the type/token distinction.","[{'name': 'Jeffrey L. Elman', 'org': 'University of California‐San Diego', 'id': 2014120117}]"
2097826433,Learning structured prediction models: a large margin approach,2005,2,,,citation,"We consider large margin estimation in a broad range of prediction models where inference involves solving combinatorial optimization problems, for example, weighted graph-cuts or matchings. Our goal is to learn parameters such that inference using the model reproduces correct answers on the training data. Our method relies on the expressive power of convex optimization problems to compactly capture inference or solution optimality in structured prediction models. Directly embedding this structure within the learning formulation produces concise convex problems for efficient estimation of very complex and diverse models. We describe experimental results on a matching task, disulfide connectivity prediction, showing significant improvements over state-of-the-art methods.","[{'name': 'Ben Taskar', 'org': 'UC Berkeley Berkeley, CA#TAB#', 'id': 2192679303}, {'name': 'Vassil Chatalbashev', 'org': 'Stanford Univ., Stanford, CA', 'id': 3635574}, {'name': 'Daphne Koller', 'org': 'Stanford Univ., Stanford, CA', 'id': 2167404190}, {'name': 'Carlos Guestrin', 'org': 'Carnegie Mellon University, Pittsburgh Pa', 'id': 1988556028}]"
2081580037,WordNet: a lexical database for English,1995,2,,,citation,"Because meaningful sentences are composed of meaningful words, any system that hopes to process natural languages as people do must have information about words and their meanings. This information is traditionally provided through dictionaries, and machine-readable dictionaries are now widely available. But dictionary entries evolved for the convenience of human readers, not for machines. WordNet 1  provides a more effective combination of traditional lexicographic information and modern computing. WordNet is an online lexical database designed for use under program control. English nouns, verbs, adjectives, and adverbs are organized into sets of synonyms, each representing a lexicalized concept. Semantic relations link the synonym sets [4].","[{'name': 'George A. Miller', 'org': 'Princeton Univ., Princeton, NJ', 'id': 2122820242}]"
2064675550,Long short-term memory,1997,2,,,citation,"Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiteru0027s (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.","[{'name': 'Sepp Hochreiter', 'org': 'Fakultät für Informatik, Technische Universität München, 80290 München, Germany#TAB#', 'id': 97377512}, {'name': 'Jürgen Schmidhuber', 'org': 'IDSIA, Corso Elvezia 36, 6900 Lugano, Switzerland#TAB#', 'id': 2116333191}]"
1950142954,Reading The Web with Learned Syntactic-Semantic Inference Rules,2012,2,,,citation,"We study how to extend a large knowledge base (Freebase) by reading relational information from a large Web text corpus. Previous studies on extracting relational knowledge from text show the potential of syntactic patterns for extraction, but they do not exploit background knowledge of other relations in the knowledge base. We describe a distributed, Web-scale implementation of a path-constrained random walk model that learns syntactic-semantic inference rules for binary relations from a graph representation of the parsed text and the knowledge base. Experiments show significant accuracy improvements in binary relation prediction over methods that consider only text, or only the existing knowledge base.","[{'name': 'Ni Lao', 'org': 'Carnegie Mellon University, Pittsburgh Pa', 'id': 2145221253}, {'name': 'Amarnag Subramanya', 'org': 'Google Research, Mountain View, CA', 'id': 2038661477}, {'name': 'Fernando Pereira', 'org': 'Google Research, Mountain View, CA', 'id': 2291088731}, {'name': 'William W. Cohen', 'org': 'Carnegie Mellon University, Pittsburgh Pa', 'id': 2115385359}]"
2962769333,Distributional Semantics Beyond Words: Supervised Learning of Analogy and Paraphrase,2013,2,,,citation,"There have been several efforts to extend distributional semantics beyond individual words, to measure the similarity of word pairs, phrases, and sentences (briefly,   tuples  ; ordered sets of words, contiguous or noncontiguous). One way to extend beyond words is to compare two tuples using a function that combines pairwise similarities between the component words in the tuples. A strength of this approach is that it works with both relational similarity (analogy) and compositional similarity (paraphrase). However, past work required hand-coding the combination function for different tasks. The main contribution of this paper is that combination functions are generated by supervised learning. We achieve state-of-the-art results in measuring relational similarity between word pairs (SAT analogies and SemEval 2012 Task 2) and measuring compositional similarity between noun-modifier phrases and unigrams (multiple-choice paraphrase questions).","[{'name': 'Peter D. Turney', 'org': 'National Research Council of Canada,', 'id': 2969534961}]"
2950797609,A Fast and Simple Algorithm for Training Neural Probabilistic Language Models,2012,2,,,citation,"In spite of their superior performance, neural probabilistic language models (NPLMs) remain far less widely used than n-gram models due to their notoriously long training times, which are measured in weeks even for moderately-sized datasets. Training NPLMs is computationally expensive because they are explicitly normalized, which leads to having to consider all words in the vocabulary when computing the log-likelihood gradients.  :[61,142],""propose a fast and simple algorithm for training NPLMs based on noise-contrastive estimation, a newly introduced procedure for estimating unnormalized continuous distributions. We investigate the behaviour of the algorithm on the Penn Treebank corpus and show that it reduces the training times by more than an order of magnitude without affecting the quality of the resulting models. The algorithm is also more efficient and much more stable than importance sampling because it requires far fewer noise samples to perform well.  demonstrate the scalability of the proposed approach by training several neural language models on a 47M-word corpus with a 80K-word vocabulary, obtaining state-of-the-art results on the Microsoft Research Sentence Completion Challenge dataset.","[{'name': 'Andriy Mnih', 'org': 'Univ. College, London#TAB#', 'id': 223511343}, {'name': 'Yee Whye Teh', 'org': 'Univ. College, London#TAB#', 'id': 1354816936}]"
2158139315,Word Representations: A Simple and General Method for Semi-Supervised Learning,2010,2,,,citation,"If we take an existing supervised NLP system, a simple and general way to improve accuracy is to use unsupervised word representations as extra word features. We evaluate Brown clusters, Collobert and Weston (2008) embeddings, and HLBL (Mnih u0026 Hinton, 2009) embeddings of words on both NER and chunking. We use near state-of-the-art supervised baselines, and find that each of the three word representations improves the accuracy of these baselines. We find further improvements by combining different word representations. You can download our word features, for off-the-shelf use in existing NLP systems, as well as our code, here: http://metaoptimize.com/projects/wordreprs/","[{'name': 'Joseph Turian', 'org': 'Université de Montréal, Montreal, Québec, Canada#TAB#', 'id': 2036062915}, {'name': 'Lev-Arie Ratinov', 'org': 'UNIVERSITY OF ILLINOIS AT URBANA–CHAMPAIGN, URBANA, IL', 'id': 2974754003}, {'name': 'Yoshua Bengio', 'org': 'Université de Montréal, Montreal, Québec, Canada#TAB#', 'id': 161269817}]"
2138204974,"Noise-contrastive estimation of unnormalized statistical models, with applications to natural image statistics",2012,2,,,citation,"We consider the task of estimating, from observed data, a probabilistic model that is parameterized by a finite number of parameters. In particular, we are considering the situation where the model probability density function is unnormalized. That is, the model is only specified up to the partition function. The partition function normalizes a model so that it integrates to one for any choice of the parameters. However, it is often impossible to obtain it in closed form. Gibbs distributions, Markov and multi-layer networks are examples of models where analytical normalization is often impossible. Maximum likelihood estimation can then not be used without resorting to numerical approximations which are often computationally expensive. We propose here a new objective function for the estimation of both normalized and unnormalized models. The basic idea is to perform nonlinear logistic regression to discriminate between the observed data and some artificially generated noise. With this approach, the normalizing partition function can be estimated like any other parameter. We prove that the new estimation method leads to a consistent (convergent) estimator of the parameters. For large noise sample sizes, the new estimator is furthermore shown to behave like the maximum likelihood estimator. In the estimation of unnormalized models, there is a trade-off between statistical and computational performance. We show that the new method strikes a competitive trade-off in comparison to other estimation methods for unnormalized models. As an application to real data, we estimate novel two-layer models of natural image statistics with spline nonlinearities.","[{'name': 'Michael U. Gutmann', 'org': 'Department of Computer Science, Department of Mathematics and Statistics, Helsinki Institute for Information Technology, University of Helsinki, Finland', 'id': 2125193858}, {'name': 'Aapo Hyvärinen', 'org': 'Department of Computer Science, Department of Mathematics and Statistics, Helsinki Institute for Information Technology, University of Helsinki, Finland', 'id': 2029196934}]"
2132339004,A neural probabilistic language model,2003,2,,,citation,"A goal of statistical language modeling is to learn the joint probability function of sequences of words in a language. This is intrinsically difficult because of the curse of dimensionality: a word sequence on which the model will be tested is likely to be different from all the word sequences seen during training. Traditional but very successful approaches based on n-grams obtain generalization by concatenating very short overlapping sequences seen in the training set. We propose to fight the curse of dimensionality by learning a distributed representation for words which allows each training sentence to inform the model about an exponential number of semantically neighboring sentences. The model learns simultaneously (1) a distributed representation for each word along with (2) the probability function for word sequences, expressed in terms of these representations. Generalization is obtained because a sequence of words that has never been seen before gets high probability if it is made of words that are similar (in the sense of having a nearby representation) to words forming an already seen sentence. Training such large models (with millions of parameters) within a reasonable time is itself a significant challenge. We report on experiments using neural networks for the probability function, showing on two text corpora that the proposed approach significantly improves on state-of-the-art n-gram models, and that the proposed approach allows to take advantage of longer contexts.","[{'name': 'Yoshua Bengio', 'org': ""Département d'Informatique et Recherche Opérationnelle, Centre de Recherche Mathématiques, Université de Montréal, Montréal, Québec, Canada"", 'id': 161269817}, {'name': 'Réjean Ducharme', 'org': ""Département d'Informatique et Recherche Opérationnelle, Centre de Recherche Mathématiques, Université de Montréal, Montréal, Québec, Canada"", 'id': 2101434519}, {'name': 'Pascal Vincent', 'org': ""Département d'Informatique et Recherche Opérationnelle, Centre de Recherche Mathématiques, Université de Montréal, Montréal, Québec, Canada"", 'id': 2397241174}, {'name': 'Christian Janvin', 'org': ""Département d'Informatique et Recherche Opérationnelle, Centre de Recherche Mathématiques, Université de Montréal, Montréal, Québec, Canada"", 'id': 2345664702}]"
2117130368,A unified architecture for natural language processing: deep neural networks with multitask learning,2008,2,,,citation,"We describe a single convolutional neural network architecture that, given a sentence, outputs a host of language processing predictions: part-of-speech tags, chunks, named entity tags, semantic roles, semantically similar words and the likelihood that the sentence makes sense (grammatically and semantically) using a language model. The entire network is trained jointly on all these tasks using weight-sharing, an instance of multitask learning. All the tasks use labeled data except the language model which is learnt from unlabeled text and represents a novel form of semi-supervised learning for the shared tasks. We show how both multitask learning and semi-supervised learning improve the generalization of the shared tasks, resulting in state-of-the-art-performance.","[{'name': 'Ronan Collobert', 'org': 'NEC-Labs America, Princeton, NJ#TAB#', 'id': 130200899}, {'name': 'Jason Weston', 'org': 'NEC-Labs America, Princeton, NJ#TAB#', 'id': 2058584252}]"
1970689298,Continuous space language models,2007,2,,,citation,"This paper describes the use of a neural network language model for large vocabulary continuous speech recognition. The underlying idea of this approach is to attack the data sparseness problem by performing the language model probability estimation in a continuous space. Highly efficient learning algorithms are described that enable the use of training corpora of several hundred million words. It is also shown that this approach can be incorporated into a large vocabulary continuous speech recognizer using a lattice rescoring framework at a very low additional processing time. The neural network language model was thoroughly evaluated in a state-of-the-art large vocabulary continuous speech recognizer for several international benchmark tasks, in particular the Nist evaluations on broadcast news and conversational speech recognition. The new approach is compared to four-gram back-off language models trained with modified Kneser-Ney smoothing which has often been reported to be the best known smoothing method. Usually the neural network language model is interpolated with the back-off language model. In that way, consistent word error rate reductions for all considered tasks and languages were achieved, ranging from 0.4% to almost 1% absolute.","[{'name': 'Holger Schwenk', 'org': 'Spoken Language Processing Group, LIMSI-CNRS, BP 133, 91403 Orsay cedex, France#TAB#', 'id': 2160549261}]"
1965154800,Strategies for training large scale neural network language models,2011,2,,,citation,"We describe how to effectively train neural network based language models on large data sets. Fast convergence during training and better overall performance is observed when the training data are sorted by their relevance. We introduce hash-based implementation of a maximum entropy model, that can be trained as a part of the neural network model. This leads to significant reduction of computational complexity. We achieved around 10% relative reduction of word error rate on English Broadcast News speech recognition task, against large 4-gram model trained on 400M tokens.","[{'name': 'Tomas Mikolov', 'org': 'Brno University of Technology, Speech@FIT, Czech Republic#TAB#', 'id': 292626543}, {'name': 'Anoop Deoras', 'org': 'HLT-COE, CLSP, Johns Hopkins University, Baltimore, MD, USA', 'id': 2224921168}, {'name': 'Daniel Povey', 'org': 'Microsoft Research, , Redmond, WA , USA', 'id': 2779265140}, {'name': 'Lukas Burget', 'org': 'Brno University of Technology, Speech@FIT, Czech Republic#TAB#', 'id': 2091894999}, {'name': 'Jan Cernocky', 'org': 'Brno University of Technology, Speech@FIT, Czech Republic#TAB#', 'id': 1992021946}]"
1889268436,Semantic Compositionality through Recursive Matrix-Vector Spaces,2012,2,,,citation,"Single-word vector space models have been very successful at learning lexical information. However, they cannot capture the compositional meaning of longer phrases, preventing them from a deeper understanding of language. We introduce a recursive neural network (RNN) model that learns compositional vector representations for phrases and sentences of arbitrary syntactic type and length. Our model assigns a vector and a matrix to every node in a parse tree: the vector captures the inherent meaning of the constituent, while the matrix captures how it changes the meaning of neighboring words or phrases. This matrix-vector RNN can learn the meaning of operators in propositional logic and natural language. The model obtains state of the art performance on three different experiments: predicting fine-grained sentiment distributions of adverb-adjective pairs; classifying sentiment labels of movie reviews and classifying semantic relationships such as cause-effect or topic-message between nouns using the syntactic path between them.","[{'name': 'Richard Socher', 'org': 'Stanford, University', 'id': 1964982643}, {'name': 'Brody Huval', 'org': 'Stanford, University', 'id': 1699311759}, {'name': 'Christopher D. Manning', 'org': 'Stanford, University', 'id': 2149153931}, {'name': 'Andrew Y. Ng', 'org': 'Stanford, University', 'id': 2104401652}]"
1662133657,From frequency to meaning: vector space models of semantics,2010,2,,,citation,"Computers understand very little of the meaning of human language. This profoundly limits our ability to give instructions to computers, the ability of computers to explain their actions to us, and the ability of computers to analyse and process text. Vector space models (VSMs) of semantics are beginning to address these limits. This paper surveys the use of VSMs for semantic processing of text. We organize the literature on VSMs according to the structure of the matrix in a VSM. There are currently three broad classes of VSMs, based on term-document, word-context, and pair-pattern matrices, yielding three classes of applications. We survey a broad range of applications in these three categories and we take a detailed look at a specific open source project in each category. Our goal in this survey is to show the breadth of applications of VSMs for semantics, to provide a new perspective on VSMs for those who are already familiar with the area, and to provide pointers into the literature for those who are less familiar with the field.","[{'name': 'Peter D. Turney', 'org': 'National Research Council Canada, Ottawa, Ontario, Canada;', 'id': 2084625574}, {'name': 'Patrick Pantel', 'org': 'Yahoo! Lab., Sunnyvale, CA', 'id': 2250462127}]"
1614298861,Efficient Estimation of Word Representations in Vector Space,2013,2,,,citation,,"[{'name': 'Tomas Mikolov', 'id': 292626543}, {'name': 'Kai Chen', 'id': 2146330397}, {'name': 'Greg S. Corrado', 'id': 1994222016}, {'name': 'Jeffrey Dean', 'id': 2429370538}]"
1423339008,Parsing Natural Scenes and Natural Language with Recursive Neural Networks,2011,2,,,citation,"Recursive structure is commonly found in the inputs of different modalities such as natural scene images or natural language sentences. Discovering this recursive structure helps us to not only identify the units that an image or sentence contains but also how they interact to form a whole. We introduce a max-margin structure prediction architecture based on recursive neural networks that can successfully recover such structure both in complex scene images as well as sentences. The same algorithm can be used both to provide a competitive syntactic parser for natural language sentences from the Penn Treebank and to outperform alternative approaches for semantic scene segmentation, annotation and classification. For segmentation and annotation our algorithm obtains a new level of state-of-the-art performance on the Stanford background dataset (78.1%). The features from the image parse tree outperform Gist descriptors for scene classification by 4%.","[{'name': 'Richard Socher', 'org': 'Computer Science Department, Stanford University, Stanford, CA 94305, USA', 'id': 1964982643}, {'name': 'Cliff C. Lin', 'org': 'Computer Science Department, Stanford University, Stanford, CA 94305, USA', 'id': 2112851132}, {'name': 'Chris Manning', 'org': 'Computer Science Department, Stanford University, Stanford, CA 94305, USA', 'id': 2149153931}, {'name': 'Andrew Y. Ng', 'org': 'Computer Science Department, Stanford University, Stanford, CA 94305, USA', 'id': 2104401652}]"
36903255,Hierarchical Probabilistic Neural Network Language Model.,2005,2,,,citation,"In recent years, variants of a neural network architecture for statistical language modeling have been proposed and successfully applied, e.g. in the language modeling component of speech recognizers. The main advantage of these architectures is that they learn an embedding for words (or other symbols) in a continuous space that helps to smooth the language model and provide good generalization even when the number of training examples is insufficient. However, these models are extremely slow in comparison to the more commonly used n-gram models, both for training and recognition. As an alternative to an importance sampling method proposed to speed-up training, we introduce a hierarchical decomposition of the conditional probabilities that yields a speed-up of about 200 both during training and recognition. The hierarchical decomposition is a binary hierarchical clustering constrained by the prior knowledge extracted from the WordNet semantic hierarchy.","[{'name': 'Frederic Morin', 'org': 'Université de Montréal,', 'id': 2129930937}, {'name': 'Yoshua Bengio', 'org': 'Université de Montréal,', 'id': 161269817}]"
21006490,WSABIE: scaling up to large vocabulary image annotation,2011,2,,,citation,"Image annotation datasets are becoming larger and larger, with tens of millions of images and tens of thousands of possible annotations. We propose a strongly performing method that scales to such datasets by simultaneously learning to optimize precision at the top of the ranked list of annotations for a given image and learning a low-dimensional joint embedding space for both images and annotations. Our method, called WSABIE, both outperforms several baseline methods and is faster and consumes less memory.","[{'name': 'Jason Weston', 'org': 'GOOGLE', 'id': 2058584252}, {'name': 'Samy Bengio', 'org': 'GOOGLE', 'id': 2016539005}, {'name': 'Nicolas Usunier', 'org': 'Université Paris 6, LIP6, France#TAB#', 'id': 121890299}]"
2951084826,CORL: A Continuous-state Offset-dynamics Reinforcement Learner,2012,2,,,citation,"Continuous state spaces and stochastic, switching dynamics characterize a number of rich, realworld domains, such as robot navigation across varying terrain. We describe a reinforcementlearning algorithm for learning in these domains and prove for certain environments the algorithm is probably approximately correct with a sample complexity that scales polynomially with the state-space dimension. Unfortunately, no optimal planning techniques exist in general for such problems; instead we use fitted value iteration to solve the learned MDP, and include the error due to approximate planning in our bounds. Finally, we report an experiment using a robotic car driving over varying terrain to demonstrate that these dynamics representations adequately capture real-world dynamics and that our algorithm can be used to efficiently solve such problems.","[{'name': 'Emma Brunskill', 'id': 1800007723}, {'name': 'Bethany Leffler', 'id': 1972177269}, {'name': 'Lihong Li', 'id': 2125714999}, {'name': 'Michael L. Littman', 'id': 1075592465}, {'name': 'Nicholas Roy', 'id': 2103369886}]"
2484153108,Machine invention of first order predicates by inverting resolution,1988,2,,,citation,"It has often been noted that the performance of existing learning systems is strongly biased by the vocabulary provided in the problem description language. An ideal system should be capable of overcoming this restriction by defining its own vocabulary. Such a system would be less reliant on the teacheru0027s ingenuity in supplying an appropriate problem representation. For this purpose we present a mechanism for automatically inventing and generalising first-order Horn clause predicates. The method is based on inverting the mechanism of resolution. The approach has its roots in the Duce system for induction of propositional Horn clauses. We have implemented the new mechanism in a system called CIGOL. CIGOL uses incremental induction to augment incomplete clausal theories. A single, uniform knowledge representation allows existing clauses to be used as background knowledge in the construction of new predicates. Given examples of a high-level predicate CIGOL generates related sub-concepts which it then asks its human teacher to name. Generalisations of predicates are tested by asking questions of the human teacher. CIGOL generates new concepts and generalisations with a preference for simplicity. We illustrate the operation of CIGOL by way of various sessions in which auxiliary predicates are automatically introduced and generalised.","[{'name': 'Stephen Muggleton', 'org': 'The Turing Institute, 36 North Hanover St., Glasgow G1 2 AD, United Kingdom', 'id': 735181462}, {'name': 'Wray L. Buntine', 'org': 'The University of Technology, Sydney, P.O. Box 123, Broadway, NSW, 2007, Australia', 'id': 2282891647}]"
2471366537,Open information extraction: the second generation,2011,2,,,citation,"How do we scale information extraction to the massive size and unprecedented heterogeneity of the Web corpus? Beginning in 2003, our KnowItAll project has sought to extract high-quality knowledge from the  :[31],""2007, we introduced the Open Information Extraction (Open IE) paradigm which eschews hand-labeled training examples, and avoids domain-specific verbs and nouns, to develop unlexicalized, domain-independent extractors that scale to the Web corpus. Open IE systems have extracted billions of assertions as the basis for both common-sense knowledge and novel question-answering  :[82],""paper describes the second generation of Open IE systems, which rely on a novel model of how relations and their arguments are expressed in English sentences to double precision/recall compared with previous systems such as TEXTRUNNER and WOE.","[{'name': 'Oren Etzioni', 'org': 'Turing Center, Department of Computer Science and Engineering, University of Washington, Seattle, WA', 'id': 57747768}, {'name': 'Anthony Fader', 'org': 'Turing Center, Department of Computer Science and Engineering, University of Washington, Seattle, WA', 'id': 2013751244}, {'name': 'Janara Christensen', 'org': 'Dept. of Computer Science and Eng., Univ. of Washington, Seattle, WA#TAB#', 'id': 2138490204}, {'name': 'Stephen Soderland', 'org': 'Turing Center, Department of Computer Science and Engineering, University of Washington, Seattle, WA', 'id': 1998656315}, {'name': 'Mausam Mausam', 'org': 'Turing Center, Department of Computer Science and Engineering, University of Washington, Seattle, WA', 'id': 115161894}]"
2167044614,Learning to extract symbolic knowledge from the World Wide Web,1998,2,,,citation,"The World Wide Web is a vast source of information accessible to computers, but understandable only to humans. The goal of the research described here is to automatically create a computer understandable world wide knowledge base whose content mirrors that of the World Wide Web. Such a knowledge base would enable much more effective retrieval of Web information, and promote new uses of the Web to support knowledge-based inference and problem solving. Our approach is to develop a trainable information extraction system that takes two inputs: an ontology defining the classes and relations of interest, and a set of training data consisting of labeled regions of hypertext representing instances of these classes and relations. Given these inputs, the system learns to extract information from other pages and hyperlinks on the Web. This paper describes our general approach, several machine learning algorithms for this task, and promising initial results with a prototype system.","[{'name': 'Mark Craven', 'id': 2134323509}, {'name': 'Dan DiPasquo', 'id': 2572384044}, {'name': 'Dayne Freitag', 'org': 'Carnegie - Mellon University#TAB#', 'id': 2144204887}, {'name': 'Andrew McCallum', 'id': 2131293038}, {'name': 'Tom Mitchell', 'id': 2151014374}, {'name': 'Kamal Nigam', 'id': 2111663429}, {'name': 'Seán Slattery', 'id': 2106460457}]"
2139346960,Which Noun Phrases Denote Which Concepts,2011,2,,,citation,"Resolving polysemy and synonymy is required for high-quality information extraction. We present ConceptResolver, a component for the Never-Ending Language Learner (NELL) (Carlson et al., 2010) that handles both phenomena by identifying the latent concepts that noun phrases refer to. ConceptResolver performs both word sense induction and synonym resolution on relations extracted from text using an ontology and a small amount of labeled data. Domain knowledge (the ontology) guides concept creation by defining a set of possible semantic types for concepts. Word sense induction is performed by inferring a set of semantic types for each noun phrase. Synonym detection exploits redundant information to train several domain-specific synonym classifiers in a semi-supervised fashion. When ConceptResolver is run on NELLu0027s knowledge base, 87% of the word senses it creates correspond to real-world concepts, and 85% of noun phrases that it suggests refer to the same concept are indeed synonyms.","[{'name': 'Jayant Krishnamurthy', 'org': 'Carnegie Mellon University, Pittsburgh Pa', 'id': 2137416177}, {'name': 'Tom Mitchell', 'org': 'Carnegie Mellon University, Pittsburgh Pa', 'id': 2151014374}]"
2132655161,Coupled semi-supervised learning for information extraction,2010,2,,,citation,"We consider the problem of semi-supervised learning to extract categories (e.g., academic fields, athletes) and relations (e.g., PlaysSport(athlete, sport)) from web pages, starting with a handful of labeled training examples of each category or relation, plus hundreds of millions of unlabeled web documents. Semi-supervised training using only a few labeled examples is typically unreliable because the learning task is underconstrained. This paper pursues the thesis that much greater accuracy can be achieved by further constraining the learning task, by coupling the semi-supervised training of many extractors for different categories and relations. We characterize several ways in which the training of category and relation extractors can be coupled, and present experimental results demonstrating significantly improved accuracy as a result.","[{'name': 'Andrew Carlson', 'org': 'Carnegie-Mellon Univ., Pittsburgh, PA, USA', 'id': 2154786016}, {'name': 'Justin Betteridge', 'org': 'Carnegie-Mellon Univ., Pittsburgh, PA, USA', 'id': 2143543388}, {'name': 'Richard C. Wang', 'org': 'Carnegie-Mellon Univ., Pittsburgh, PA, USA', 'id': 2110957663}, {'name': 'Estevam R. Hruschka', 'org': 'Federal University of São Carlos, São Carlos, Brazil', 'id': 2137503162}, {'name': 'Tom M. Mitchell', 'org': 'Carnegie-Mellon Univ., Pittsburgh, PA, USA', 'id': 2151014374}]"
2132174753,Eurisko: A program that learns new heuristics and domain concepts,1983,2,,,citation,"The AM program, an early attempt to mechanize learning by discovery, has recently been expanded and extended to several other task domains. AMu0027s ultimate failure apparently was due to its inability to discover new, powerful, domain-specific heuristics for the various new fields it uncovered. At that time, it seemed straight-forward to simply add u0027Heuristicsu0027 as one more field in which to let AM explore, observe, define, and develop. That task-learning new heuristics by discovery-turned out to be much more difficult than was realized initially, and we have just now achieved some successes at it. Along the way, it became clearer why AM had succeeded in the first place, and why it was so difficult to use the same paradigm to discover new heuristics. In essence, AM was an automatic programming system, whose primitive actions were modifications to pieces of LISP code, code which represented the characteristic functions of various math concepts. It was only because of the deep relationship between LISP and Mathematics that these operations (loop unwinding, recursion elimination, composition, argument elimination, function substitution, etc.) which were basic LISP mutators also turned out to yield a high u0027hit ratu0027 of viable, useful new math concepts when applied to previously-known, useful math concepts. But no such deep relationship existed between LISP and Heuristics, and when the basic automatic programming operators were applied to viable, useful heuristics, they almost always produced useless (often worse than useless) new rules. Our work on the nature of heuristics has enabled the construction of a new language in which the statement of heuristics is more natural and compact. Briefly, the vocabulary includes many types of conditions, actions, and descriptive properties that a heuristic might possess; instead of writing a large lump of LISP code to represent the heuristic, one spreads the same information out across dozens of u0027slotsu0027. By employing this new language, the old property that AM satisfied fortuitously is once again satisfied: the primitive syntactic operators usually now produce meaningful semantic variants of what they operate on. The ties to the foundations of Heuretics have been engineered into the syntax and vocabulary of the new language, partly by design and partly by evolution, much as John McCarthy engineered ties to the foundations of Mathematics into LISP. The EURISKO program embodies this language, and it is described in this paper, along with its results in eight task domains: design of naval fleets, elementary set theory and number theory, LISP programming, biological evolution, games in general, the design of three-dimensional VLSI devices, the discovery of heuristics which help the system discover heuristics, and the discovery of appropriate new types of u0027slotsu0027 in each domain. Along the way, some very powerful new concepts, designs, and heuristics were indeed discovered mechanically. Characteristics that make a domain ripe for AM-like exploration for new concepts and conjectures are explicated, plus features that make a domain especially suitable for EURISKO-level exploration for new heuristics.","[{'name': 'Douglas B. Lenat', 'org': 'Computer Science Department, Stanford University, Stanford, CA 94305, U.S.A.', 'id': 2236934353}]"
2117510361,Language-Independent Set Expansion of Named Entities Using the Web,2007,2,,,citation,"Set expansion refers to expanding a given partial set of objects into a more complete set. A well-known example system that does set expansion using the web is Google Sets. In this paper, we propose a novel method for expanding sets of named entities. The approach can be applied to semi-structured documents written in any markup language and in any human language. We present experimental results on 36 benchmark sets in three languages, showing that our system is superior to Google Sets in terms of mean average precision.","[{'name': 'R.C. Wang', 'org': 'Carnegie Mellon Univ., Pittsburgh,', 'id': 2110957663}, {'name': 'W.W. Cohen', 'org': 'Carnegie Mellon Univ., Pittsburgh,', 'id': 2115385359}]"
2115461474,Web-scale information extraction in knowitall: (preliminary results),2004,2,,,citation,"Manually querying search engines in order to accumulate a large bodyof factual information is a tedious, error-prone process of piecemealsearch. Search engines retrieve and rank potentially relevantdocuments for human perusal, but do not extract facts, assessconfidence, or fuse information from multiple documents. This paperintroduces KnowItAll, a system that aims to automate the tedious process ofextracting large collections of facts from the web in an autonomous,domain-independent, and scalable manner.The paper describes preliminary experiments in which an instance of KnowItAll, running for four days on a single machine, was able to automatically extract 54,753 facts. KnowItAll associates a probability with each fact enabling it to trade off precision and recall. The paper analyzes KnowItAllu0027s architecture and reports on lessons learned for the design of large-scale information extraction systems.","[{'name': 'Oren Etzioni', 'org': 'University of Washington, Seattle, WA', 'id': 57747768}, {'name': 'Michael Cafarella', 'org': 'University of Washington, Seattle, WA', 'id': 2893888}, {'name': 'Doug Downey', 'org': 'University of Washington, Seattle, WA', 'id': 2098223845}, {'name': 'Stanley Kok', 'org': 'University of Washington, Seattle, WA', 'id': 2118462989}, {'name': 'Ana-Maria Popescu', 'org': 'University of Washington, Seattle, WA', 'id': 2616900583}, {'name': 'Tal Shaked', 'org': 'University of Washington, Seattle, WA', 'id': 744075988}, {'name': 'Stephen Soderland', 'org': 'University of Washington, Seattle, WA', 'id': 1998656315}, {'name': 'Daniel S. Weld', 'org': 'University of Washington, Seattle, WA', 'id': 560881892}, {'name': 'Alexander Yates', 'org': 'University of Washington, Seattle, WA', 'id': 2893246432}]"
2109718074,Discovering Relations between Noun Categories,2011,2,,,citation,"Traditional approaches to Relation Extraction from text require manually defining the relations to be extracted. We propose here an approach to automatically discovering relevant relations, given a large text corpus plus an initial ontology defining hundreds of noun categories (e.g., Athlete, Musician, Instrument). Our approach discovers frequently stated relations between pairs of these categories, using a two step process. For each pair of categories (e.g., Musician and Instrument) it first co-clusters the text contexts that connect known instances of the two categories, generating a candidate relation for each resulting cluster. It then applies a trained classifier to determine which of these candidate relations is semantically valid. Our experiments apply this to a text corpus containing approximately 200 million web pages and an ontology containing 122 categories from the NELL system [Carlson et al., 2010b], producing a set of 781 proposed candidate relations, approximately half of which are semantically valid. We conclude this is a useful approach to semi-automatic extension of the ontology for large-scale information extraction systems such as NELL.","[{'name': 'Thahir Mohamed', 'org': '(university of pittsburgh)', 'id': 2823991155}, {'name': 'Estevam Hruschka', 'org': 'Federal University of São Carlos', 'id': 2137503162}, {'name': 'Tom Mitchell', 'org': 'Carnegie - Mellon University#TAB#', 'id': 2151014374}]"
2067760738,Proactive learning: cost-sensitive active learning with multiple imperfect oracles,2008,2,,,citation,"Proactive learning is a generalization of active learning designed to relax unrealistic assumptions and thereby reach practical applications. Active learning seeks to select the most informative unlabeled instances and ask an omniscient oracle for their labels, so as to retrain the learning algorithm maximizing accuracy. However, the oracle is assumed to be infallible (never wrong), indefatigable (always answers), individual (only one oracle), and insensitive to costs (always free or always charges the same). Proactive learning relaxes all four of these assumptions, relying on a decision-theoretic approach to jointly select the optimal oracle and instance, by casting the problem as a utility optimization problem subject to a budget constraint. Results on multi-oracle optimization over several data sets demonstrate the superiority of our approach over the single-imperfect-oracle baselines in most cases.","[{'name': 'Pinar Donmez', 'org': 'Carnegie-Mellon Univ., Pittsburgh, PA, USA', 'id': 1264356972}, {'name': 'Jaime G. Carbonell', 'org': 'Carnegie-Mellon Univ., Pittsburgh, PA, USA', 'id': 2100444261}]"
2053237598,A design for the ICARUS architecture,1991,2,,,citation,"We describe our designs for ICARUS, an integrated architecture for controlling an intelligent agent in a complex physical environment. By navigating between locations and manipulating other objects, the agent influences the world and achieves its goals. The architecture includes components for perceiving the environment, for generating plans to solve problems, and for executing the plans generated. A fourth component manages the agentu0027s long-term memory. Our assessment of the design suggests that it is general, versatile, scales well to larger problems, and is consistent with a variety of psychological results.","[{'name': 'Pat Langley', 'id': 2151465254}, {'name': 'Kathleen B. McKusick', 'id': 2189999777}, {'name': 'John A. Allen', 'id': 2145486114}, {'name': 'Wayne F. Iba', 'id': 379189452}, {'name': 'Kevin Thompson', 'id': 2105835115}]"
2048679005,Combining labeled and unlabeled data with co-training,1998,2,,,citation,"We consider the problem of using a large unlabeled sample to boost performance of a learning algorit,hrn when only a small set of labeled examples is available. In particular, we consider a problem setting motivated by the task of learning to classify web pages, in which the description of each example can be partitioned into two distinct views. For example, the description of a web page can be partitioned into the words occurring on that page, and the words occurring in hyperlinks t,hat point to that page. We assume that either view of the example would be sufficient for learning if we had enough labeled data, but our goal is to use both views together to allow inexpensive unlabeled data to augment, a much smaller set of labeled examples. Specifically, the presence of two distinct views of each example suggests strategies in which two learning algorithms are trained separately on each view, and then each algorithm’s predictions on new unlabeled examples are used to enlarge the training set of the other. Our goal in this paper is to provide a PAC-style analysis for this setting, and, more broadly, a PAC-style framework for the general problem of learning from both labeled and unlabeled data. We also provide empirical results on real web-page data indicating that this use of unlabeled examples can lead to significant improvement of hypotheses in practice. *This research was supported in part by the DARPA HPKB program under contract F30602-97-1-0215 and by NSF National Young investigator grant CCR-9357793. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. TO copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. COLT 98 Madison WI USA Copyright ACM 1998 l-58113-057--0/98/ 7...%5.00 92 Tom Mitchell School of Computer Science Carnegie Mellon University Pittsburgh, PA 15213-3891 mitchell+@cs.cmu.edu","[{'name': 'Avrim Blum', 'org': 'School of Computer Science Carnegie Mellon University Pittsburgh, PA', 'id': 2137000917}, {'name': 'Tom Mitchell', 'org': 'School of Computer Science Carnegie Mellon University Pittsburgh, PA', 'id': 2151014374}]"
1991564165,Lifelong Robot Learning,1993,2,,,citation,"Learning provides a useful tool for the automatic design of autonomous robots. Recent research on learning robot control has predominantly focussed on learning single tasks that were studied in isolation. If robots encounter a multitude of control learning tasks over their entire lifetime there is an opportunity to transfer knowledge between them. In order to do so, robots may learn the invariants and the regularities of their individual tasks and environments. This task-independent knowledge can be employed to bias generalization when learning control, which reduces the need for real-world experimentation. We argue that knowledge transfer is essential if robots are to learn control with moderate learning times in complex scenarios. Two approaches to lifelong robot learning which both capture invariant knowledge about the robot and its environments are presented. Both approaches have been evaluated using a HERO-2000 mobile robot. Learning tasks included navigation in unknown indoor environments and a simple find-and-fetch task.","[{'name': 'Sebastian B. Thrun', 'org': '""University of Bonn""', 'id': 2075956027}, {'name': 'Tom M. Mitchell', 'org': 'Carnegie - Mellon University#TAB#', 'id': 2151014374}]"
1964763677,NEIL: Extracting Visual Knowledge from Web Data,2013,2,,,citation,"We propose NEIL (Never Ending Image Learner), a computer program that runs 24 hours per day and 7 days per week to automatically extract visual knowledge from Internet data. NEIL uses a semi-supervised learning algorithm that jointly discovers common sense relationships (e.g., ""Corolla is a kind of/looks similar to Car"", ""Wheel is a part of Car"") and labels instances of the given visual categories. It is an attempt to develop the worldu0027s largest visual structured knowledge base with minimum human labeling effort. As of 10th October 2013, NEIL has been continuously running for 2.5 months on 200 core cluster (more than 350K CPU hours) and has an ontology of 1152 object categories, 1034 scene categories and 87 attributes. During this period, NEIL has discovered more than 1700 relationships and has labeled more than 400K visual instances.","[{'name': 'Xinlei Chen', 'id': 2883814010}, {'name': 'Abhinav Shrivastava', 'id': 2116029713}, {'name': 'Abhinav Gupta', 'id': 2099263982}]"
1942169943,Knowledge Graph Identification,2013,2,,,citation,"Large-scale information processing systems are able to extract massive collections of interrelated facts, but unfortunately transforming these candidate facts into useful knowledge is a formidable challenge. In this paper, we show how uncertain extractions about entities and their relations can be transformed into a knowledge graph. The extractions form an extraction graph and we refer to the task of removing noise, inferring missing information, and determining which candidate facts should be included into a knowledge graph as knowledge graph identification. In order to perform this task, we must reason jointly about candidate facts and their associated extraction confidences, identify co-referent entities, and incorporate ontological constraints. Our proposed approach uses probabilistic soft logic (PSL), a recently introduced probabilistic modeling framework which easily scales to millions of facts. We demonstrate the power of our method on a synthetic Linked Data corpus derived from the MusicBrainz music community and a real-world set of extractions from the NELL project containing over 1M extractions and 70K ontological relations. We show that compared to existing methods, our approach is able to achieve improved AUC and F1 with significantly lower running time.","[{'name': 'Jay Pujara', 'org': 'Department of Computer Science, University of Maryland - College Park, USA', 'id': 704051514}, {'name': 'Hui Miao', 'org': 'Department of Computer Science, University of Maryland - College Park, USA', 'id': 2225773943}, {'name': 'Lise Getoor', 'org': 'Department of Computer Science, University of Maryland - College Park, USA', 'id': 1984940772}, {'name': 'William Cohen', 'org': 'Machine Learning Dept, Carnegie Mellon University, Pittsburgh, USA', 'id': 2115385359}]"
1822246767,A PAC-Style model for learning from labeled and unlabeled data,2005,2,,,citation,"There has been growing interest in practice in using unlabeled data together with labeled data in machine learning, and a number of different approaches have been developed. However, the assumptions these methods are based on are often quite distinct and not captured by standard theoretical models. In this paper we describe a PAC-style framework that can be used to model many of these assumptions, and analyze sample-complexity issues in this setting: that is, how much of each type of data one should expect to need in order to learn well, and what are the basic quantities that these numbers depend on. Our model can be viewed as an extension of the standard PAC model, where in addition to a concept class C, one also proposes a type of compatibility that one believes the target concept should have with the underlying distribution. In this view, unlabeled data can be helpful because it allows one to estimate compatibility over the space of hypotheses, and reduce the size of the search space to those that, according to oneu0027s assumptions, are a-priori reasonable with respect to the distribution. We discuss a number of technical issues that arise in this context, and provide sample-complexity bounds both for uniform convergence and e-cover based algorithms. We also consider algorithmic issues, and give an efficient algorithm for a special case of co-training.","[{'name': 'Maria-Florina Balcan', 'org': 'Computer Science Department, Carnegie Mellon University,', 'id': 2169342471}, {'name': 'Avrim Blum', 'org': 'Computer Science Department, Carnegie Mellon University,', 'id': 2137000917}]"
1541824660,Active learning for structure in Bayesian networks,2001,2,,,citation,"The task of causal structure discovery from empirical data is a fundamental problem in many areas. Experimental data is crucial for accomplishing this task. However, experiments are typically expensive, and must be selected with great care. This paper uses active learning to determine the experiments that are most informative towards uncovering the underlying structure. We formalize the causal learning task as that of learning the structure of a causal Bayesian network. We consider an active learner that is allowed to conduct experiments, where it intervenes in the domain by setting the values of certain variables. We provide a theoretical framework for the active learning problem, and an algorithm that actively chooses the experiments to perform based on the model learned so far. Experimental results show that active learning can substantially reduce the number of observations required to determine the structure of a domain.","[{'name': 'Simon Tong', 'org': 'Computer Science Dept. Stanford University,', 'id': 2068608856}, {'name': 'Daphne Koller', 'org': 'Computer Science Dept. Stanford University,', 'id': 2167404190}]"
1512387364,Toward an architecture for never-ending language learning,2010,2,,,citation,"We consider here the problem of building a never-ending language learner; that is, an intelligent computer agent that runs forever and that each day must (1) extract, or read, information from the web to populate a growing structured knowledge base, and (2) learn to perform this task better than on the previous day. In particular, we propose an approach and a set of design principles for such an agent, describe a partial implementation of such a system that has already learned to extract a knowledge base containing over 242,000 beliefs with an estimated precision of 74% after running for 67 days, and discuss lessons learned from this preliminary attempt to build a never-ending learning agent.","[{'name': 'Andrew Carlson', 'org': 'School of Computer Science Carnegie Mellon University Pittsburgh, PA', 'id': 2154786016}, {'name': 'Justin Betteridge', 'org': 'School of Computer Science Carnegie Mellon University Pittsburgh, PA', 'id': 2143543388}, {'name': 'Bryan Kisiel', 'org': 'School of Computer Science Carnegie Mellon University Pittsburgh, PA', 'id': 2494956587}, {'name': 'Burr Settles', 'org': 'School of Computer Science Carnegie Mellon University Pittsburgh, PA', 'id': 2911267484}, {'name': 'Estevam R. Hruschka', 'org': 'Federal University of Sao Carlos, Sao Carlos - SP, Brazil#TAB#', 'id': 2137503162}, {'name': 'Tom M. Mitchell', 'org': 'School of Computer Science Carnegie Mellon University Pittsburgh, PA', 'id': 2151014374}]"
1006028607,Estimating accuracy from unlabeled data,2014,2,,,citation,"We consider the question of how unlabeled data can be used to estimate the true accuracy of learned classifiers. This is an important question for any autonomous learning system that must estimate its accuracy without supervision, and also when classifiers trained from one data distribution must be applied to a new distribution (e.g., document classifiers trained on one text corpus are to be applied to a second corpus). We first show how to estimate error rates exactly from unlabeled data when given a collection of competing classifiers that make independent errors, based on the agreement rates between subsets of these classifiers. We further show that even when the competing classifiers do not make independent errors, both their accuracies and error dependencies can be estimated by making certain relaxed assumptions. Experiments on two data real-world data sets produce estimates within a few percent of the true accuracy, using solely un-labeled data. These results are of practical significance in situations where labeled data is scarce and shed light on the more general question of how the consistency among multiple functions is related to their true accuracies.","[{'name': 'Emmanouil Antonios Platanios', 'org': 'Machine Learning Department, Carnegie-Mellon University, Pittsburgh, PA#TAB#', 'id': 2011834717}, {'name': 'Avrim Blum', 'org': 'Computer Science Department, Carnegie-Mellon University, Pittsburgh, Pa.#TAB#', 'id': 2137000917}, {'name': 'Tom Mitchell', 'org': 'Machine Learning Department, Carnegie-Mellon University, Pittsburgh, PA#TAB#', 'id': 2151014374}]"
349683603,OpenEval: web information query evaluation,2013,2,,,citation,"In this paper, we investigate information validation tasks that are initiated as queries from either automated agents or humans. We introduce OpenEval, a new online information validation technique, which uses information on the web to automatically evaluate the truth of queries that are stated as multiargument predicate instances (e.g., DrugHasSideEffect(Aspirin, GI Bleeding))). OpenEval gets a small number of instances of a predicate as seed positive examples and automatically learns how to evaluate the truth of a new predicate instance by querying the web and processing the retrieved unstructured web pages. We show that OpenEval is able to respond to the queries within a limited amount of time while also achieving high F1 score. In addition, we show that the accuracy of responses provided by OpenEval is increased as more time is given for evaluation. We have extensively tested our model and shown empirical results that illustrate the effectiveness of our approach compared to related techniques.","[{'name': 'Mehdi Samadi', 'org': ', Computer Science Department, Carnegie Mellon University, Pittsburgh,', 'id': 2132903572}, {'name': 'Manuela Veloso', 'org': ', Computer Science Department, Carnegie Mellon University, Pittsburgh,', 'id': 2108671403}, {'name': 'Manuel Blum', 'org': ', Computer Science Department, Carnegie Mellon University, Pittsburgh,', 'id': 2163096604}]"
175897666,Incorporating Vector Space Similarity in Random Walk Inference over Knowledge Bases,2014,2,,,citation,"Much work in recent years has gone into the construction of large knowledge bases (KBs), such as Freebase, DBPedia, NELL, and YAGO. While these KBs are very large, they are still very incomplete, necessitating the use of inference to fill in gaps. Prior work has shown how to make use of a large text corpus to augment random walk inference over KBs. We present two improvements to the use of such large corpora to augment KB inference. First, we present a new technique for combining KB relations and surface text into a single graph representation that is much more compact than graphs used in prior work. Second, we describe how to incorporate vector space similarity into random walk inference over KBs, reducing the feature sparsity inherent in using surface text. This allows us to combine distributional similarity with symbolic logical inference in novel and effective ways. With experiments on many relations from two separate KBs, we show that our methods significantly outperform prior work on KB inference, both in the size of problem our methods can handle and in the quality of predictions made.","[{'name': 'Matt Gardner', 'id': 2133268498}, {'name': 'Partha Talukdar', 'id': 2407474466}, {'name': 'Jayant Krishnamurthy', 'id': 2137416177}, {'name': 'Tom Mitchell', 'id': 2151014374}]"
99485931,Learning to learn,1998,2,,,citation,"Preface. Part I: Overview Articles. 1. Learning to Learn: Introduction and Overview S. Thrun, L. Pratt. 2. A Survey of Connectionist Network Reuse Through Transfer L. Pratt, B. Jennings. 3. Transfer in Cognition A. Robins. Part II: Prediction. 4. Theoretical Models of Learning to Learn J. Baxter. 5. Multitask Learning R. Caruana. 6. Making a Low-Dimensional Representation Suitable for Diverse Tasks N. Intrator, S. Edelman. 7. The Canonical Distortion Measure for Vector Quantization and Function Approximation J. Baxter. 8. Lifelong Learning Algorithms S. Thrun. Part III: Relatedness. 9. The Parallel Transfer of Task Knowledge Using Dynamic Learning Rates Based on a Measure of Relatedness D.L. Silver, R.E. Mercer. 10. Clustering Learning Tasks and the Selective Cross-Task Transfer of Knowledge S. Thrun, J. Ou0027Sullivan. Part IV: Control. 11. CHILD: A First Step Towards Continual Learning M.B. Ring. 12. Reinforcement Learning with Self-Modifying Policies J. Schmidhuber, et al. 13. Creating Advice-Taking Reinforcement Learners R. Maclin, J.W. Shavlik. Contributing Authors. Index.","[{'name': 'Sebastian Thrun', 'org': 'Carnegie Mellon University, Pittsburgh Pa', 'id': 2075956027}, {'name': 'Lorien Pratt', 'org': 'Evolving Systems, Inc.#TAB#', 'id': 2672465314}]"
