pid,title,abstract,rank,justification
1990968493,Linguistic and semantic passage retrieval strategies for question answering,"Question Answering (QA) is the task of searching a large text collection for specific answers to questions posed in natural language. Though they often have access to rich linguistic and semantic analyses of their input questions, QA systems often rely on off-theshelf bag-of-words Information Retrieval (IR) solutions to retrieve passages matching a set of terms extracted from the question.   There is a fundamental disconnect between the capabilities of the bag-of-words retrieval model and the retrieval needs of the QA system. Bag-of-words IR retrieves documents matching a query, but the QA system really needs documents that contain answers. Through question analysis, the QA system has compiled a sophisticated information need representation for what constitutes an answer to the question. This representation is composed of a set of linguistic and semantic constraints satisfied by answer-bearing passages. Unfortunately, off-the-shelf IR libraries commonly used in QA systems can not, in general, check these types of constraints at query-time. Poor quality retrieval can cause a QA system to fail if no answer-bearing text is retrieved, if it is not ranked highly enough, or if it is outranked or overwhelmed by false positives, text that matches the query well, yet supports a wrong answer.   This thesis proposes two linguistic and semantic passage retrieval methods for QA, one based on structured retrieval and the other on rank-learning techniques. In addition, a methodology is proposed for mapping annotated text consisting of labeled spans and typed relations between them into an annotation graph representation. The annotation graph supports query-time linguistic and semantic constraint-checking, and serves as a unifying formalism for the QA systemu0027s information need and for retrieved passages. The proposed methods rely only on the relatively weak assumption that the QA systemu0027s information need can be represented as an annotation graph. The two approaches are shown to retrieve more answer-bearing text, more highly ranked, compared to a bag-of-words baseline for two different QA tasks. Linguistic and semantic passage retrieval methods are also shown to improve end-to-end QA system accuracy and answer MRR.   Available online at: http://www.cs.cmu.edu/~mbilotti/thesis.pdf.",1,"Ranked 1st. The paper proposes a novel approach to passage retrieval for question answering, which is highly relevant to the query's focus on semantic passage segmentation and question answering."
2901681178,Shallow and Deep Syntactic/Semantic Structures for Passage Reranking in Question-Answering Systems,"In this article, we extensively study the use of syntactic and semantic structures obtained with shallow and full syntactic parsers for answer passage reranking. We propose several dependency and constituent-based structures, also enriched with Linked Open Data (LD) knowledge to represent pairs of questions and answer passages. We encode such tree structures in learning-to-rank (L2R) algorithms using tree kernels, which can project them in tree substructure spaces, where each dimension represents a powerful syntactic/semantic feature. Additionally, since we define links between question and passage structures, our tree kernel spaces also include relational structural features. We carried out an extensive comparative experimentation of our models for automatic answer selection benchmarks on different TREC QA corpora as well as the newer Wikipedia-based dataset, namely WikiQA, which has been widely used to test sentence rerankers. The results consistently demonstrate that our structural semantic models achieve the state of the art in passage reranking. In particular, we derived the following important findings: (i) relational syntactic structures are essential to achieve superior results; (ii) models trained with dependency trees can outperform those trained with shallow trees, e.g., in case of sentence reranking; (iii) external knowledge automatically generated with focus and question classifiers is very effective; and (iv) the semantic information derived by LD and incorporated in syntactic structures can be used to replace the knowledge provided by the above-mentioned classifiers. This is a remarkable advantage as it enables our models to increase coverage and portability over new domains.",1,"Ranked 1st. The paper proposes several dependency and constituent-based structures, enriched with Linked Open Data (LD) knowledge, to represent pairs of questions and answer passages. This approach is highly relevant to the query's focus on semantic matching and passage reranking."
2175520418,Passage Retrieval Using Answer Type Profiles in Question Answering,"Retrieving answer containing passages is a challenging task in Question Answer- ing. In this paper, we describe a novel passage retrieval methodology using answer type profiles. Our methodology includes two steps: estimation and ranking. In the estimation step, answer type profiles are constructed from question-answer sentence pairs parallel cor- pus using a statistical alignment model. Each answer type profile consists of triples: the query word, the answering sentence word and the probability of translation. In the ranking step, answer type profiles are incorporated into the Language Modeling framework called Statistical Machine Translation models for Information Retrieval. Using this framework a set of relevant passages are retrieved, given a question. We conducted experiments on FACTOID questions from TREC 2002 to 2006 QA tracks. The experimental results showed signifi- cant improvements over different retrieval models including TFIDF, Okapi BM25, Indri and KL-divergence.",1,"Ranked 1st. The paper proposes a novel passage retrieval methodology using answer type profiles, which is highly relevant to the query's focus on passage retrieval and question answering."
1963863728,Question focus extraction and answer passage retrieval,"Question Analysis is an important task in Question Answering Systems (QAS). It consists generally in identifying the semantic type of the question and extracting the main focus of the question. The goal is to better specify the required information by the question. In this context and as part of a framework aiming to implement an Arabic opinion QAS for political debates, this paper addresses the problem of defining the focus of opinion questions and proposes particularly an approach for extracting the focus of attitude questions. The proposed approach is based on semi-automatically constructed lexico-syntactic patterns. Furthermore, the paper presents an adapted Vector Space Model (VSM) based method to retrieve candidate answer passages from a transcribed TV political show. Several experiments were carried out and showed that the focus extraction approach has achieved over 72% as F1 score for holder and target extraction, and has improved the baseline passage retrieval task by over than 25%.",2,"Ranked 2nd. The paper addresses the problem of defining the focus of opinion questions and proposes an approach for extracting the focus of attitude questions. While it touches on question analysis, its core domain is question focus extraction and answer passage retrieval, which is less directly aligned with the query's focus on semantic matching and passage reranking."
2144091323,Question Analysis and Answer Passage Retrieval for Opinion Question Answering Systems,"Question answering systems provide an elegant way for people to access an underlying knowledge base. However, people are interested in not only factual questions, but also opinions. This paper deals with question analysis and answer passage retrieval in opinion QA systems. For question analysis, six opinion question types are defined. A two-layered framework utilizing two question type classifiers is proposed. Algorithms for these two classifiers are described. The performance achieves 87.8% in general question classification and 92.5% in opinion question classification. The question focus is detected to form a query for the information retrieval system and the question polarity is detected to retain relevant sentences which have the same polarity as the question. For answer passage retrieval, three components are introduced. Relevant sentences retrieved are further identified as to whether the focus (Focus Detection) is in a scope of opinion (Opinion Scope Identification) or not, and, if yes, whether the polarity of the scope and the polarity of the question (Polarity Detection) match with each other. The best model achieves an F-measure of 40.59% by adopting partial match for relevance detection at the level of meaningful unit. With relevance issues removed, the F-measure of the best model boosts up to 84.96%.",2,"Ranked 2nd. The paper deals with question analysis and answer passage retrieval in opinion QA systems, which is related to the query's focus on passage retrieval and question answering."
2978160189,Distant Supervised Why-Question Generation with Passage Self-Matching Attention,"Question generation (QG) aims to create a fluent question from a passage and a target answer. State-of-the-art approaches are mainly based on encoder-decoder models to generate questions from the given passage and answer, which focus on using the information contained in a particular part of the passage for QG, but unaware of the clues hidden in other parts of the passage. Besides, the existing work on QG mainly focus on generating factoid questions, which are less suitable for generating non-factoid questions such as why-questions. In this paper, we propose to augment encoder-decoder framework with a pair-wise self-matching attention mechanism to dynamically collect inter-sentential evidence from the whole passage according to the current passage word and answer information. Besides, to let the model be more suitable for why-question generation, we also involve some causal features in the encoding process. Finally, to tackle the lack of why-question generation training data problem, we adopt a distant supervised method with an initial causal knowledge base to generate a large training data for why-question generation. Extensive experiments on several data sets show that our model significantly outperforms state-of-the-art question generation models not only on why-question generation tasks, but also on other types of question generation tasks.",2,"Ranked 2nd. The paper proposes a distant supervised method for why-question generation, which is moderately relevant to the query's focus on question answering and passage retrieval."
2407645726,Answer extraction from passage graph for question answering,"In question answering, answer extraction aims to pin-point the exact answer from passages. However, most previous methods perform such extraction on each passage separately, without considering clues provided in other passages. This paper presents a novel approach to extract answers by fully leveraging connections among different passages. Specially, extraction is performed on a Passage Graph which is built by adding links upon multiple passages. Different passages are connected by linking words with the same stem. We use the factor graph as our model for answer extraction. Experimental results on multiple QA data sets demonstrate that our method significantly improves the performance of answer extraction.",3,"Ranked 3rd. The paper proposes a passage graph-based approach for answer extraction, which is somewhat relevant to the query's focus on question answering and passage retrieval."
1489454174,Hot-spot passage retrieval in question answering,"Question Answering has been the recent focus of information retrieval research; many systems just incorporate a search engine as a black box and most effort has been devoted to the question analyzer and the answer identifier. In the context of QA, however, passage provides an ideal medium between the document collection and an exact answer. And passage retrieval is a finer-grain approach than the traditional document retrieval both for the answer identifier and a human reader. In this paper, distinctions are first made between document retrieval and passage retrieval. And the Hot-Spot Passage Retrieval algorithm, which takes into account the measures of blurred BM25, coverage and height, is examined in detail. For evaluation, an isolated test is conducted and the algorithm gains 18.3% better answer redundancy and 4.8% better coverage rate than Okapiu0027s original passage retrieval algorithm.",3,"Ranked 3rd. The paper examines the use of syntactic and semantic structures obtained with shallow and full syntactic parsers for answer passage reranking. While it discusses passage retrieval, its core domain is document retrieval, which is less directly aligned with the query's focus on semantic matching and passage reranking."
2963681593,WikiPassageQA: A Benchmark Collection for Research on Non-factoid Answer Passage Retrieval,"With the rise in mobile and voice search, answer passage retrieval acts as a critical component of an effective information retrieval system for open domain question answering. Currently, there are no comparable collections that address non-factoid question answering within larger documents while simultaneously providing enough examples sufficient to train a deep neural network. In this paper, we introduce a new Wikipedia based collection specific for non-factoid answer passage retrieval containing thousands of questions with annotated answers and show benchmark results on a variety of state of the art neural architectures and retrieval models. The experimental results demonstrate the unique challenges presented by answer passage retrieval within topically relevant documents for future research.",3,"Ranked 3rd. The paper introduces a new Wikipedia-based collection specific for non-factoid answer passage retrieval, which is relevant to the query's focus on passage retrieval and question answering."
2798526799,WikiPassageQA: A Benchmark Collection for Research on Non-factoid Answer Passage Retrieval,"With the rise in mobile and voice search, answer passage retrieval acts as a critical component of an effective information retrieval system for open domain question answering. Currently, there are no comparable collections that address non-factoid question answering within larger documents while simultaneously providing enough examples sufficient to train a deep neural network. In this paper, we introduce a new Wikipedia based collection specific for non-factoid answer passage retrieval containing thousands of questions with annotated answers and show benchmark results on a variety of state of the art neural architectures and retrieval models. The experimental results demonstrate the unique challenges presented by answer passage retrieval within topically relevant documents for future research.",4,"Ranked 4th. The paper introduces a new Wikipedia-based collection specific for non-factoid answer passage retrieval, which is relevant to the query's focus on passage retrieval and question answering."
