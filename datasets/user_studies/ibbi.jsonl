{"paragraph": "First-person shooter (FPS) games rely on sound design to complement visuals, providing players with critical feedback and spatial awareness. Gunfire, footsteps, and directional audio cues inform players of enemy positions and game events in ways that visuals alone cannot. Previous research has shown that well-designed audio cues, sounds that convey information about enemy location, distance, or movement, can enhance player performance and immersion. In FPS titles, such cues are often utilized for accurately detecting threats and navigating the environment. The sound design thus plays a critical role in gameplay: it directs attention and improves situational awareness in ways that are especially beneficial when visual information is limited. For visually impaired players (VIPs), audio is not just an enhancement but the primary source for experiencing games. A visually impaired gamer must rely on auditory feedback for navigation, targeting, and understanding the game. However, mainstream games remain largely inaccessible to this audience, as vital information is conveyed almost exclusively through visual graphics. This creates a substantial accessibility gap: VIPs are either excluded from gaming or forced to play in severely limited “audio-only” modes, often supported by ad-hoc sound cues that are insufficient for competitive play. Yet, the potential of advanced audio design to bridge this gap is evident in past studies, for instance, researchers have demonstrated that blind users can build mental maps of 3D spaces using only sound cues. Such findings underscore the importance of advanced sonification – the use of non-speech audio to convey information – techniques in improving gameplay for VIPs. Sound cues like spatial audio, and auditory icons can convey spatial layout and events, enabling VIPs to orient and react in virtual worlds. Furthermore, training with audio-only games has been shown to significantly improve blind players’ sound localization and navigation skills, reinforcing the promise that better sound design can translate to better play experiences for the visually impaired. Despite previous research in game accessibility and sonification proposing various auditory enhancements, a significant research gap remains at the intersection of accessibility and FPS games. Audio-only FPS games such as Shades of Doom and Terraformers demonstrate that FPS gameplay can rely entirely on sound through cues like sonar pings, spoken announcements, and directional audio. However, these solutions have primarily been evaluated informally, without rigorous, objective benchmarking. Although studies showed that audio cues could enhance spatial awareness for sighted players in FPS contexts, they did not investigate audio-exclusive gameplay or utilize AI-driven evaluations. Similarly, while some modern games feature blind-accessible audio modes, formal empirical assessments of their effectiveness remain sparse. This lack of empirical validation highlights a clear gap in accessible FPS game research. In this study, we take a step forward in addressing the abovementioned gaps by introducing and evaluating Sonic Doom, an enhanced auditory system for the ViZDoom FPS platform. We integrate accessible sound and game design principles into the ViZDoom platform, building on previous research on games for VIPs and best practices in audio game design. Our key contributions include: 1) We proposed a novel evaluation framework for FPS games using a Blind AI agent, an agent that plays the game solely through the audio sensory channel, as part of sound design evaluation. 2) We are the first to empirically evaluate the accessible sound and game design techniques in an FPS game using AI and humans. 3) Our approach enhances not only enjoyment and usability but also audio aesthetics for human players compared to the baseline while also improving the performance of the Blind AI agent.", "name": "ibbi", "number": "1"}
{"paragraph": "Video games are becoming more and more popular, with this growth being quick and constant. Artificial intelligence (AI) has been linked to video games for some time now. The study of AI in video games has contributed to numerous advances in AI. Video game designers are working to improve their games as the industry’s popularity soars, aiming to provide players with a favorable experience. These enhancements can take many different forms, such as adjustments to the gameplay, games with appealing visuals, or games with excellent music or sound effects. The ultimate objective, regardless of the kind of enhancement, is to improve the players’ overall experience. This study focuses on using music in video games to improve player experience by giving players more information about the game. An immersive gaming experience is aided by background music (BGM) or music. The target genre in this research is fighting games. In fighting games, players engage in one-on-one battles, utilizing various attacks and skills to defeat their opponent, whether it is another player or a computer-controlled character. Traditionally, fighting games are two-dimensional or two-and-a-halfdimensional, which means that the players can only move in two dimensions (left or right). In fighting games, BGM should be able to change in response to game situations, and doing this creates suspense and excitement as the players engage in combat. Commonly, a fighting game’s BGM is implemented using pre-composed songs that loop, which often falls short of accurately capturing the intensity of combat. A few examples of commercial fighting games are Street Fighters, Tekken, and Mortal Kombat. This research uses the DareFightingICE platform, which is a fighting game platform. It is an audio-enhanced version of the FightingICE platform and was used in the DareFightingICE Competition, which had two tracks: the Sound Design Track and the AI Track. The competition had been run at the IEEE Conference on Games from 2022 to 2024. More details about DareFightingICE will be given in a later section. Information below is given to better understand what is an adaptive BGM in this research. Adaptive Music reacts dynamically to in-game events and player actions, adjusting elements such as instrumental layers, tempo, and effects to match the intensity or atmosphere of the gameplay. In this research, the proposed adaptive music can be described as a system that allows the music’s loudness to be altered in real-time based on control inputs, such as player health and the distance between players. Static Music on the other hand, consists of pre-composed tracks that play consistently without changing in response to gameplay. In this research, static music refers to music whose loudness remains constant and is unaffected by external factors, such as the player’s health. The goal of this research is to create an adaptive BGM that gives players information about the state of the game. It is done by modifying the BGM of DareFightingICE. This research is an extension of a previous study, focusing on giving players with and without vision information about the state of the game through the context-aware BGM. We picked fighting games as it has been shown to be popular among VIPs. This research is the first one to use multiple instruments in the adaptation of BGM. The contributions of our work are as follows: 1. This is the first study to focus on adaptive music in fighting games and it is also the first to use multiple instruments in the adaptation of BGM. 2. Our approach demonstrates that adaptive BGM enhances the overall enjoyment of the game compared to static BGM. 3. Our adaptive BGM is not only more informative but also more aesthetic than its non-adaptive counterpart.", "name": "ibbi", "number": "2"}